<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>Occasional diary</title>
        <link>https://cofault.com</link>
        <description>Nikita Danilov, Occasional diary</description>
        <lastBuildDate>Tue, 15 Jul 2025 03:19:52 +0000</lastBuildDate>

        <item>
            <title>3-lisp: an infinite tower of meta-circular interpreters.</title>
            <id>3-lisp</id>
            <link>https://cofault.com/3-lisp.html#3-lisp</link>
            <pubDate>2022/08/22</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/3-lisp.html#3-lisp">
                     &lt;a href=&quot;https://github.com/nikitadanilov/3-lisp/blob/master/3-lisp.lisp#L259&quot;&gt;Source&lt;/a&gt;Précis3-LISP is a dialect of LISP designed and implemented by &lt;a href=&quot;https://en.wikipedia.org/wiki/Brian_Cantwell_Smith&quot;&gt;Brian C. Smith&lt;/a&gt; as part of his PhD. thesis &lt;a href=&quot;https://dspace.mit.edu/handle/1721.1/15961&quot;&gt;Procedural Reflection in Programming Languages&lt;/a&gt; (what this thesis refers to as &amp;quot;&lt;a href=&quot;https://en.wikipedia.org/wiki/Reflective_programming&quot;&gt;reflection&lt;/a&gt;&amp;quot; is nowadays more usually called &amp;quot;&lt;a href=&quot;https://en.wikipedia.org/wiki/Reification_(computer_science)&quot;&gt;reification&lt;/a&gt;&amp;quot;). A 3-LISP program is conceptually executed by an interpreter written in 3-LISP that is itself executed by an interpreter written in 3-LISP and so on &lt;i&gt;ad infinitum&lt;/i&gt;. This forms a (countably) infinite tower of meta-circular (&lt;i&gt;v.i.&lt;/i&gt;) interpreters. &lt;i&gt;reflective lambda&lt;/i&gt; is a function that is executed one tower level above its caller. Reflective lambdas provide a very general language extension mechanism.The code is &lt;a href=&quot;https://github.com/nikitadanilov/3-lisp&quot;&gt;here&lt;/a&gt;.Meta-circular interpretersAn &lt;a href=&quot;https://en.wikipedia.org/wiki/Interpreter_(computing)&quot;&gt;interpreter&lt;/a&gt; is a program that executes programs written in some programming language.A &lt;a href=&quot;https://en.wikipedia.org/wiki/Meta-circular_evaluator&quot;&gt;meta-circular interpreter&lt;/a&gt; is an interpreter for a programming language written in that language. Meta-circular interpreters can be used to clarify or define the semantics of the language by reducing the full language to a sub-language in which the interpreter is expressed.  Historically, such &lt;i&gt;definitional interpreters&lt;/i&gt; become popular within the functional programming community, see the classical &lt;a href=&quot;https://surface.syr.edu/cgi/viewcontent.cgi?article=1012&amp;amp;context=lcsmith_other&quot;&gt;Definitional interpreters for higher-order programming languages&lt;/a&gt;. Certain important techniques were classified and studied in the framework of meta-circular interpretation, for example, &lt;a href=&quot;https://en.wikipedia.org/wiki/Continuation-passing_style&quot;&gt;continuation passing style&lt;/a&gt; can be understood as a mechanism that makes meta-circular interpretation independent of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Evaluation_strategy&quot;&gt;evaluation strategy&lt;/a&gt;: it allows an eager meta-language to interpret a lazy object language and &lt;i&gt;vice versa&lt;/i&gt;. As a by-product, a &lt;a href=&quot;https://en.wikipedia.org/wiki/Continuation-passing_style&quot;&gt;continuation passing style&lt;/a&gt; interpreter is essentially a state machine and so can be implemented in hardware, see &lt;a href=&quot;https://dspace.mit.edu/handle/1721.1/6334&quot;&gt;The Scheme-79 chip&lt;/a&gt;. Similarly, &lt;a href=&quot;https://www.brics.dk/RS/08/4/BRICS-RS-08-4.pdf&quot;&gt;&lt;i&gt;de-functionalisation&lt;/i&gt;&lt;/a&gt; of languages with higher-order functions obtains for them first-order interpreters. But meta-circular interpreters occur in imperative contexts too, for example, the usual proof of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Structured_program_theorem&quot;&gt;Böhm–Jacopini theorem&lt;/a&gt; (interestingly, it was &lt;a href=&quot;https://en.wikipedia.org/wiki/Corrado_B%C3%B6hm&quot;&gt;Corrado Böhm&lt;/a&gt; who first introduced meta-circular interpreters in his 1954 PhD. thesis) constructs for an Algol-like language a meta-circular interpreter expressed in some goto-less subset of the language and then &lt;a href=&quot;https://en.wikipedia.org/wiki/Partial_evaluation&quot;&gt;specialises&lt;/a&gt; this interpreter for a particular program in the source language.Given a language with a meta-circular interpreter, suppose that the language is extended with a mechanism to &lt;i&gt;trap&lt;/i&gt; to the meta-level. For example, in a LISP-like language, that trap can be a new special form &lt;code class=&quot;inline&quot;&gt;(reflect FORM)&lt;/code&gt; that directly executes (rather than interprets) &lt;code class=&quot;inline&quot;&gt;FORM&lt;/code&gt; within the interpreter. Smith is mostly interested in reflective (&lt;i&gt;i.e.&lt;/i&gt;, reification) powers obtained this way, and it is clear that the meta-level trap provides a very general language extension method: one can add new primitives, data types, flow and sequencing control operators, &lt;i&gt;etc&lt;/i&gt;. But if you try to add &lt;code class=&quot;inline&quot;&gt;reflect&lt;/code&gt; to an existing LISP meta-circular interpreter (for example, see p. 13 of &lt;a href=&quot;https://www.softwarepreservation.org/projects/LISP/book/LISP%201.5%20Programmers%20Manual.pdf&quot;&gt;LISP 1.5 Programmers Manual&lt;/a&gt;) you&amp;#x27;d hit a problem: &lt;code class=&quot;inline&quot;&gt;FORM&lt;/code&gt; cannot be executed at the meta-level, because at this level it is not a form, but an &lt;a href=&quot;https://en.wikipedia.org/wiki/S-expression&quot;&gt;S-expression&lt;/a&gt;.Meta-interpreting machine codeTo understand the nature of the problem, consider a very simple case: the object language is the machine language (or equivalently the assembly language) of some processor. Suppose that the interpreter for the machine code is written in (or, more realistically, compiled to) the same machine language. The interpreter maintains the state of the simulated processor that is, among other things registers and memory. Say, the object (interpreted) code can access a register, &lt;code class=&quot;inline&quot;&gt;R0&lt;/code&gt;, then the interpreter has to keep the contents of this register somewhere, but typically not in &lt;i&gt;its&lt;/i&gt; (interpreter&amp;#x27;s) &lt;code class=&quot;inline&quot;&gt;R0&lt;/code&gt;. Similarly, a memory word visible to the interpreted code at an address &lt;code class=&quot;inline&quot;&gt;ADDR&lt;/code&gt; is stored by the interpreter at some, generally different, address &lt;code class=&quot;inline&quot;&gt;ADDR&amp;#x27;&lt;/code&gt; (although, by applying the &lt;a href=&quot;https://en.wikipedia.org/wiki/Banach_fixed-point_theorem&quot;&gt;contractive mapping theorem&lt;/a&gt; and a &lt;i&gt;lot&lt;/i&gt; of hand-waving one might argue that there will be at least one word stored at the same address at the object- and meta-levels). Suppose that the interpreted machine language has the usual sub-routine call-return instructions &lt;code class=&quot;inline&quot;&gt;call ADDR&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;return&lt;/code&gt; and is extended with a new instruction &lt;code class=&quot;inline&quot;&gt;reflect ADDR&lt;/code&gt; that forces the interpreter to call the sub-routine &lt;code class=&quot;inline&quot;&gt;ADDR&lt;/code&gt;. At the very least the interpreter needs to convert &lt;code class=&quot;inline&quot;&gt;ADDR&lt;/code&gt; to the matching &lt;code class=&quot;inline&quot;&gt;ADDR&amp;#x27;&lt;/code&gt;. This might not be enough because, for example, the object-level sub-routine &lt;code class=&quot;inline&quot;&gt;ADDR&lt;/code&gt; might not be contiguous at the meta-level, &lt;i&gt;i.e.&lt;/i&gt;, it is not guaranteed that if &lt;code class=&quot;inline&quot;&gt;ADDR&lt;/code&gt; maps to &lt;code class=&quot;inline&quot;&gt;ADDR&amp;#x27;&lt;/code&gt; then &lt;code class=&quot;inline&quot;&gt;(ADDR + 1)&lt;/code&gt; maps &lt;code class=&quot;inline&quot;&gt;(ADDR&amp;#x27; + 1)&lt;/code&gt;. This example demonstrates that a reflective interpreter needs a systematic and efficient way of converting or translating between object- and meta-level representations. If such a method is somehow provided, &lt;code class=&quot;inline&quot;&gt;reflect&lt;/code&gt; is a very powerful mechanism: by modifying interpreter state and code it can add new instructions, addressing modes, condition bits, branch predictors, &lt;i&gt;etc&lt;/i&gt;.N-LISP for a suitable value of NIn his thesis Prof. Smith analyses what would it take to construct a dialect of LISP for which a faithful reflective meta-circular interpreter is possible. He starts by defining a formal model of computation with an (extremely) rigorous distinction between meta- and object- levels (and, hence, between &lt;a href=&quot;https://en.wikipedia.org/wiki/Use%E2%80%93mention_distinction&quot;&gt;use and mention&lt;/a&gt;). It is then determined that this model can not be satisfactorily applied to the &lt;i&gt;traditional&lt;/i&gt; LISP (which is called 1-LISP in the thesis and is mostly based on &lt;a href=&quot;https://en.wikipedia.org/wiki/Maclisp&quot;&gt;Maclisp&lt;/a&gt;). The reason is that LISP&amp;#x27;s notion of &lt;a href=&quot;https://en.wikipedia.org/wiki/Eval#Lisp&quot;&gt;evaluation&lt;/a&gt; conflates two operations: &lt;a href=&quot;https://en.wikipedia.org/wiki/Normal_form_(abstract_rewriting)&quot;&gt;normalisation&lt;/a&gt; that operates within the level and &lt;a href=&quot;https://en.wikipedia.org/wiki/Referent&quot;&gt;reference&lt;/a&gt; that moves one level down. A dialect of LISP that consistently separates normalisation and reference is called 2-LISP (the then new &lt;a href=&quot;https://en.wikipedia.org/wiki/Scheme_(programming_language)&quot;&gt;Scheme&lt;/a&gt; is called 1.75-LISP). Definition of 2-LISP occupies the bulk of the thesis, which the curious reader should consult for (exciting, believe me) details.Once 2-LISP is constructed, adding the reflective capability to it is relatively straightforward. Meta-level trap takes the form of a special &lt;a href=&quot;https://en.wikipedia.org/wiki/Anonymous_function#Lisp&quot;&gt;lambda expression&lt;/a&gt;:(lambda reflect [ARGS ENV CONT] BODY)When this lambda function is applied (at the object level), the body is directly executed (not interpreted) at the meta-level with &lt;code class=&quot;inline&quot;&gt;ARGS&lt;/code&gt; bound to the meta-level representation of the actual parameters, &lt;code class=&quot;inline&quot;&gt;ENV&lt;/code&gt; bound to the &lt;i&gt;environment&lt;/i&gt; (basically, the list of identifiers and the values they are bound to) and &lt;code class=&quot;inline&quot;&gt;CONT&lt;/code&gt; bound to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Continuation&quot;&gt;continuation&lt;/a&gt;. Environment and continuation together represent the 3-LISP interpreter state (much like registers and memory represent the machine language interpreter state), this representation goes all the way back to &lt;a href=&quot;https://en.wikipedia.org/wiki/SECD_machine&quot;&gt;SECD machine&lt;/a&gt;, see &lt;a href=&quot;https://doi.org/10.1093%2Fcomjnl%2F6.4.308&quot;&gt;The Mechanical Evaluation of Expressions&lt;/a&gt;.Here is the &lt;a href=&quot;https://github.com/nikitadanilov/3-lisp/blob/master/3-lisp.lisp#L1570&quot;&gt;fragment&lt;/a&gt; of 3-LISP meta-circular interpreter code that handles &lt;code class=&quot;inline&quot;&gt;lambda reflect&lt;/code&gt; (together with &amp;quot;ordinary&amp;quot; lambda-s, denoted by &lt;code class=&quot;inline&quot;&gt;lambda simple&lt;/code&gt;):ImplementationIt is of course not possible to run an infinite tower of interpreters directly.3-LISP implementation creates a meta-level on demand, when a reflective lambda is invoked. At that moment the state of the meta-level interpreter is synthesised (&lt;i&gt;e.g.&lt;/i&gt;, see &lt;a href=&quot;https://github.com/nikitadanilov/3-lisp/blob/master/3-lisp.lisp#L1586&quot;&gt;&lt;code class=&quot;inline&quot;&gt;make-c1&lt;/code&gt;&lt;/a&gt; in the listing above). The implementation takes pain to detect when it can drop down to a lower level, which is not entirely simple because a reflective lambda can, instead of returning (that is, invoking the supplied continuation), run a potentially modified version of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop&quot;&gt;read-eval-loop&lt;/a&gt; (called &lt;a href=&quot;https://github.com/nikitadanilov/3-lisp/blob/master/3-lisp.lisp#L1563&quot;&gt;&lt;code class=&quot;inline&quot;&gt;READ-NORMALISE-PRINT&lt;/code&gt;&lt;/a&gt; in 3-LISP) which does not return. There is a lot of non-trivial machinery operating behind the scenes and though the implementation modestly proclaims itself &lt;a href=&quot;https://github.com/nikitadanilov/3-lisp/blob/master/3-lisp.lisp#L33&quot;&gt;&lt;i&gt;extremely inefficient&lt;/i&gt;&lt;/a&gt; it is, in fact, remarkably fast.PortingI was unable to find a digital copy of the 3-LISP sources and so manually retyped the sources from the appendix of the thesis. The transcription in &lt;a href=&quot;https://github.com/nikitadanilov/3-lisp/blob/master/3-lisp.lisp&quot;&gt;3-lisp.lisp&lt;/a&gt; (2003 lines, 200K characters) preserves the original pagination and character set, see the comments at the top of the file. Transcription was mostly straightforward except for a few places where the PDF is illegible (for example, &lt;a href=&quot;https://github.com/nikitadanilov/3-lisp/blob/master/3-lisp.lisp#L396&quot;&gt;see here&lt;/a&gt;) all of which fortunately are within comment blocks.The sources are in &lt;a href=&quot;https://dspace.mit.edu/handle/1721.1/5718&quot;&gt;CADR machine&lt;/a&gt; dialect of LISP, which, save for some minimal and no longer relevant details, is equivalent to Maclisp.3-LISP implementation does not have its own parser or interpreter. Instead, it uses flexibility built in a LISP reader (see, &lt;a href=&quot;https://www.cs.cmu.edu/Groups/AI/html/cltl/clm/node192.html&quot;&gt;readtables&lt;/a&gt;) to parse, interpret and even compile 3-LISP with a very small amount of additional code. Amazingly, this more than 40 years old code, which uses arcane features like readtable customisation, runs on a modern &lt;a href=&quot;https://en.wikipedia.org/wiki/Common_Lisp&quot;&gt;Common Lisp&lt;/a&gt; platform after a very small set of changes: some functions got renamed (&lt;code class=&quot;inline&quot;&gt;CASEQ&lt;/code&gt; to &lt;code class=&quot;inline&quot;&gt;CASE&lt;/code&gt;, &lt;code class=&quot;inline&quot;&gt;*CATCH&lt;/code&gt; to &lt;code class=&quot;inline&quot;&gt;CATCH&lt;/code&gt;, &lt;i&gt;etc&lt;/i&gt;.), some functions are missing (&lt;code class=&quot;inline&quot;&gt;MEMQ&lt;/code&gt;, &lt;code class=&quot;inline&quot;&gt;FIXP&lt;/code&gt;), some signatures changed (&lt;code class=&quot;inline&quot;&gt;TYPEP&lt;/code&gt;, &lt;code class=&quot;inline&quot;&gt;BREAK&lt;/code&gt;, &lt;code class=&quot;inline&quot;&gt;IF&lt;/code&gt;). See &lt;a href=&quot;https://github.com/nikitadanilov/3-lisp/blob/master/3-lisp.cl&quot;&gt;3-lisp.cl&lt;/a&gt; for details.Unfortunately, the port does not run on &lt;i&gt;all&lt;/i&gt; modern Common Lisp implementations, because it relies on the proper support for &lt;a href=&quot;https://www.gnu.org/software/emacs/manual/html_node/elisp/Backquote.html&quot;&gt;backquotes&lt;/a&gt; across recursive reader &lt;a href=&quot;https://github.com/nikitadanilov/3-lisp/blob/master/3-lisp.cl#L92&quot;&gt;invocations&lt;/a&gt;:;;     Maclisp maintains backquote context across recursive parser
;;     invocations. For example in the expression (which happens within defun
;;     3-EXPAND-PAIR)
;;
;;         `\(PCONS ~,a ~,d)
;;
;;     the backquote is consumed by the top-level activation of READ. Backslash
;;     forces the switch to 3-lisp readtable and call to 3-READ to handle the
;;     rest of the expression. Within this 3-READ activation, the tilde forces
;;     switch back to L=READTABLE and a call to READ to handle &amp;quot;,a&amp;quot;. In Maclisp,
;;     this second READ activation re-uses the backquote context established by
;;     the top-level READ activation. Of all Common Lisp implementations that I
;;     tried, only sbcl correctly handles this situation. Lisp Works and clisp
;;     complain about &amp;quot;comma outside of backquote&amp;quot;. In clisp,
;;     clisp-2.49/src/io.d:read_top() explicitly binds BACKQUOTE-LEVEL to nil.Among Common Lisp implementations I tried, only &lt;a href=&quot;https://www.sbcl.org/&quot;&gt;sbcl&lt;/a&gt; supports it properly. After reading Common Lisp &lt;a href=&quot;http://www.lispworks.com/documentation/common-lisp.html&quot;&gt;Hyperspec&lt;/a&gt;, I believe that it is Maclisp and &lt;a href=&quot;https://www.sbcl.org/&quot;&gt;sbcl&lt;/a&gt; that implement the specification correctly and other implementations are faulty.ConclusionProcedural Reflection in Programming Languages is, in spite of its age, a very interesting read. Not only does it contain an implementation of a refreshingly new and bold idea (it is not even immediately obvious that infinite reflective towers can at all be implemented, not to say with any reasonable degree of efficiency), it is based on an interplay between mathematics and programming: the model of computation is proposed and afterward implemented in 3-LISP. Because the model is implemented in an actual running program, it has to be specified with extreme precision (which would make &lt;a href=&quot;https://en.wikipedia.org/wiki/Alfred_Tarski&quot;&gt;Tarski&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Jan_%C5%81ukasiewicz&quot;&gt;Łukasiewicz&lt;/a&gt; tremble), and any execution of the 3-LISP interpreter validates the model.</content>
        </item>

        <item>
            <title>adaptive replacement</title>
            <id>adaptive-replacement</id>
            <link>https://cofault.com/adaptive-replacement.html#adaptive-replacement</link>
            <pubDate>2003/12/23</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/adaptive-replacement.html#adaptive-replacement">
                     „&lt;a href=&quot;http://groups.google.com/groups?hl=ru&amp;amp;lr=&amp;amp;ie=UTF-8&amp;amp;oe=UTF-8&amp;amp;threadm=8950%40saturn.ucsc.edu&amp;amp;rnum=1&amp;amp;prev=/groups%3Fq%3Dvm%2Breplacement%2Bgroup:comp.os.*%26hl%3Dru%26lr%3D%26ie%3DUTF-8%26oe%3DUTF-8%26selm%3D8950%2540saturn.ucsc.edu%26rnum%3D1&quot;&gt;adaptive replacement better than Working Set&lt;/a&gt;?“ has (an implicit) idea: VM page replacement should keep a &lt;i&gt;spectrum&lt;/i&gt; of accesses to a given page. Too high and too low frequences should be filtered out, because they:represent correlated references, andirrelevant,respectively.</content>
        </item>

        <item>
            <title>Weekend affinity.</title>
            <id>affinity</id>
            <link>https://cofault.com/affinity.html#affinity</link>
            <pubDate>2013/01/19</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/affinity.html#affinity">
                     Groups usually come with &lt;a href=&quot;http://en.wikipedia.org/wiki/Group_(mathematics)&quot;&gt;homomorphisms&lt;/a&gt;, defined as mappings preserving multiplication:f(a\cdot b) = f(a)\cdot f(b)From this definition, notions of subgroup (monomorphism), &lt;a href=&quot;http://en.wikipedia.org/wiki/Quotient_group&quot;&gt;quotient group&lt;/a&gt; (epimorphism, &lt;a href=&quot;http://en.wikipedia.org/wiki/Normal_subgroup&quot;&gt;normal subgroup&lt;/a&gt;) and the famous &lt;a href=&quot;http://en.wikipedia.org/wiki/Isomorphism_theorem#First_isomorphism_theorem&quot;&gt;isomorphism theorem&lt;/a&gt; follow naturally. The &lt;a href=&quot;http://en.wikipedia.org/wiki/Category_of_groups&quot;&gt;category of groups&lt;/a&gt; with homomorphisms as arrows has products and sums, equalizers and coequalizers all well-known and with nice properties.Consider, instead, &lt;i&gt;affine morphism&lt;/i&gt;, that can be defined by the following equivalent conditions:1. \(f(a \cdot b^{-1} \cdot c) = f(a) \cdot f^{-1}(b) \cdot f(c)\)2. \(f(a \cdot b) = f(a) \cdot f^{-1}(e) \cdot f(b)\)3. \(\exists t. f(a \cdot b) = f(a) \cdot t \cdot f(b)\)The motivation for this definition is slightly roundabout.The difference between homomorphism and affine morphism is similar to the difference between a &lt;a href=&quot;http://en.wikipedia.org/wiki/Vector_subspace&quot;&gt;vector subspace&lt;/a&gt; and an &lt;a href=&quot;http://en.wikipedia.org/wiki/Affine_space#Affine_subspaces&quot;&gt;affine subspace&lt;/a&gt; of a vector space. A &lt;a href=&quot;http://en.wikipedia.org/wiki/Vector_subspace&quot;&gt;vector subspace&lt;/a&gt; always goes through the origin (for a homomorphism \(f\), \(f(e) = e\)), whereas an &lt;a href=&quot;http://en.wikipedia.org/wiki/Affine_space#Affine_subspaces&quot;&gt;affine subspace&lt;/a&gt; is translated from the origin (\(f(e) \neq e\) is possible for an affine morphism).Take points \(f(a)\) and \(f(b)\) in the image of an affine morphism, translate them back to the corresponding &amp;quot;vector subspace&amp;quot; to obtain \(f(a) \cdot f^{-1}(e)\) and \(f(b) \cdot f^{-1}(e)\). If translated points are multiplied and the result is translated back to the affine image, the resulting point should be the same as \(f(a \cdot b)\):f(a \cdot b) = (f(a) \cdot f^{-1}(e)) \cdot (f(b) \cdot f^{-1}(e)) \cdot f(e) = f(a) \cdot f^{-1}(e) \cdot f(b)which gives the definition (2).(1) =&amp;gt; (2) immediately follows by substituting \(e\) for \(b\).(2) =&amp;gt; (3) by substituting \(f^{-1}(e)\) for \(t\).(3) =&amp;gt; (2) by substituting \(e\) for \(a\) and \(b\).(2) =&amp;gt; (1)\begin{array}{r@{\;}c@{\;}l@{\quad}l@{\quad}}
f(a \cdot b^{-1} \cdot c) &amp;amp;\;=\;&amp;amp;                                              &amp;amp; \\
                          &amp;amp;\;=\;&amp;amp; f(a) \cdot f^{-1}(e) \cdot f(b^{-1} \cdot c) &amp;amp; \text{\{(2) for \(a \cdot (b^{-1} \cdot c)\)\}} \\
                          &amp;amp;\;=\;&amp;amp; f(a) \cdot f^{-1}(e) \cdot f(b^{-1}) \cdot f^{-1}(e) \cdot f(c) &amp;amp; \text{\{(2) for \(b^{-1} \cdot c\)\}} \\
                          &amp;amp;\;=\;&amp;amp; f(a) \cdot f^{-1}(e) \cdot f(b^{-1}) \cdot f^{-1}(e) \cdot f(b) \cdot f^{-1}(b) \cdot f(c) &amp;amp; \text{\{\(e = f(b) \cdot f^{-1}(b)\), working toward } \\
                          &amp;amp;     &amp;amp;                                  &amp;amp; \text{creating a sub-expression that can be collapsed by (2)\}} \\
                          &amp;amp;\;=\;&amp;amp; f(a) \cdot f^{-1}(e) \cdot f(b^{-1} \cdot b) \cdot f^{-1}(b) \cdot f(c) &amp;amp; \text{\{collapsing \(f(b^{-1}) \cdot f^{-1}(e) \cdot f(b)\) by (2)\}} \\
                          &amp;amp;\;=\;&amp;amp; f(a) \cdot f^{-1}(e) \cdot f(e) \cdot f^{-1}(b) \cdot f(c) &amp;amp; \text{\{\(b^{-1} \cdot b = e\)\}} \\
                          &amp;amp;\;=\;&amp;amp; f(a) \cdot f^{-1}(b) \cdot f(c) &amp;amp; \text{\{\(f^{-1}(e) \cdot f(e) = e\)\}}
\end{array}It is easy to check that each homomorphism is an affine morphism (specifically, homomorphisms are exactly affine morphisms with \(f(e) = e\)).Composition of affine morphisms is affine and hence groups with affine morphisms form a category \(\mathbb{Aff}\).A subset of a group \(G\) is called an &lt;i&gt;affine subgroup&lt;/i&gt; of \(G\) if one of the following equivalent conditions holds:1. \(\exists h \in G:\forall p, q \in H \rightarrow (p \cdot h^{-1} \cdot q \in H \wedge h \cdot p^{-1} \cdot h \in H)\)2. \(\forall p, q, h \in H \rightarrow (p \cdot h^{-1} \cdot q \in H \wedge h \cdot p^{-1} \cdot h \in H)\)The equivalence (with a proof left as an exercise) means that if any \(h\) &amp;quot;translating&amp;quot; affine subgroup to a subgroup exists, then any member of the affine subgroup can be used for translation. In fact, any \(h\) that satisfies (1) belongs to \(H\) (prove). This matches the situation with affine and vector subspaces: any vector from an affine subspace translates this subspace to the subspace passing through the origin.Finally for to-day, consider an affine morphism \(f:G_0\rightarrow G_1\). For \(t\in G_0\) define &lt;i&gt;kernel&lt;/i&gt;:ker_t f = \{g\in G_0 | f(g) = f(t)\}It&amp;#x27;s easy to check that a kernel is affine subgroup (take \(t\) as \(h\)). Note that in \(\mathbb{Aff}\) a whole family of subobjects corresponds to a morphism, whereas there is &lt;i&gt;the&lt;/i&gt; kernel in \(\mathbb{Grp}\).To be continued: affine quotients, products, sums, free affine groups.</content>
        </item>

        <item>
            <title>How the tables have turned.</title>
            <id>ai-early</id>
            <link>https://cofault.com/ai-early.html#ai-early</link>
            <pubDate>2025/05/22</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/ai-early.html#ai-early">
                     Already in 1956 it was clear that one had to work with symbolic expressions to reach the goal of artifical intelligence. As the researchers already understood numerical computation would not have much importance.&lt;span class=&quot;align-right&quot;&gt;-- &lt;a href=&quot;https://dl.acm.org/doi/pdf/10.1145/800055.802047&quot;&gt;Early LISP History&lt;/a&gt; (1956 - 1959)&lt;/span&gt;</content>
        </item>

        <item>
            <title>An exercise</title>
            <id>an-exercise</id>
            <link>https://cofault.com/an-exercise.html#an-exercise</link>
            <pubDate>2005/11/12</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/an-exercise.html#an-exercise">
                     Here is a little problem. Given an array \(A\) of \(N\) integers, find a sub-array (determined by a pair of indices within \(A\)) such that sum of elements in that sub-array is maximal among all sub-arrays of \(A\).Sounds pretty easy? It is, but just to set a little standard for solutions: there is a way (shown to me by a 15-year-old boy) to do this in one pass over \(A\) and without using any additional storage except for few integer variables.So much for dynamic programming...updateThat exercise is interesting, because while superfluously similar to the well-known tasks like finding longest common substring, &lt;i&gt;etc&lt;/i&gt;. it can be solved in one pass.Indeed Matti &lt;a href=&quot;http://nikitadanilov.blogspot.com/2005/11/exercise.html#113183576990722370&quot;&gt;presented&lt;/a&gt; exactly the same solution that I had in mind. And it is possible (and instructive) to get a rigorous proof that this algorithm solves the problem.&lt;i&gt;Definition 0&lt;/i&gt;. Let \(A = (i, j)\) be a sub-array \((i &amp;lt;= j)\), then \(S(A) =  S(i, j)\) denotes a sum of elements in \(A\). \(S(A)\) will be called &lt;i&gt;sum of  \(A\)&lt;/i&gt;.&lt;i&gt;Definition 1&lt;/i&gt;. Let \(A = (i, j)\) be a sub-array \((i &amp;lt;= j)\), then for any0 &amp;lt;= p &amp;lt; i &amp;lt; q &amp;lt; j &amp;lt; r &amp;lt; Nsub-array \((p, i - 1)\) is called left outfix of \(A\), \((i, q)\) --- left  infix of \(A\), \((q + 1, j)\) --- right infix of \(A\), and \((j + 1, r)\) ---  right outfix of \(A\).&lt;i&gt;Definition 2&lt;/i&gt;. A sub-array is called &lt;i&gt;optimal&lt;/i&gt; if all its infixes have  positive sums, and all its outfixes have negative sums.It&amp;#x27;s easy to prove the following:&lt;i&gt;Statement 0&lt;/i&gt;. A sub-array with the maximal sum is optimal.Indeed, any non-optimal sub-array by definition has either negative infix, or  positive outfix, and, hence, can be shrunken or expanded to another sub-array  that has larger sum.As an obvious corollary we get:&lt;i&gt;Statement 1&lt;/i&gt;. To find a sub-array with the maximal sum it&amp;#x27;s enough to find a  sub-array with the maximal sum among all optimal sub-arrays.The key fact that explains why our problem can be solved in one pass is captured in the following:&lt;i&gt;Statement 2&lt;/i&gt;. Optimal sub-arrays are not overlapping.Also easily proved by observing that when two sub-arrays \(A\) and \(B\)  overlap there always is an sub-array \(C\) that is an infix of \(A\) and an  outfix of \(B\).And, now the only thing left to do is to prove that Matti&amp;#x27;s algorithm calculates sums of (at least) all optimal sub-arrays. Which is easy to do:first prove that possibly except for the initial value, &lt;code class=&quot;inline&quot;&gt;new_start&lt;/code&gt; always  points to the index at which at least one (and, therefore, exactly one) optimal  array starts. This is easily proved by induction.then prove that once particular value of &lt;code class=&quot;inline&quot;&gt;new_start&lt;/code&gt; has been reached,  &lt;code class=&quot;inline&quot;&gt;new_start&lt;/code&gt; is not modified until &lt;code class=&quot;inline&quot;&gt;i&lt;/code&gt; reaches upper index of optimal array  starting at &lt;code class=&quot;inline&quot;&gt;new_start&lt;/code&gt;. This follows directly from the definition of optimal  sub-array, because all its left infixes have positive sums.this means that for any optimal sub-array \((p, q)\) there is an iteration of  the loop at whichnew\_start == p \quad\text{and}\quad i == qAs algorithm finds maximal sum among all \((new\_start, i)\) sub-arrays, it  finds maximal sum among all optimal arrays, and, by &lt;i&gt;Statement 1&lt;/i&gt;, maximal sum  among all sub-arrays.</content>
        </item>

        <item>
            <title>What is cosh(List(Bool))? Or beyond algebra: analysis of data types.</title>
            <id>aodt</id>
            <link>https://cofault.com/aodt.html#aodt</link>
            <pubDate>2025/04/16</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/aodt.html#aodt">
                     There is that curious idea that you can think of a &lt;a href=&quot;https://en.wikipedia.org/wiki/Data_type&quot;&gt;type&lt;/a&gt; in a programming language as a kind of &lt;a href=&quot;https://en.wikipedia.org/wiki/Algebraic_data_type&quot;&gt;algebraic object&lt;/a&gt;. Take (homogeneous) lists for example. A list of integers is either an empty list (&lt;i&gt;i.e.&lt;/i&gt;, &lt;code class=&quot;inline&quot;&gt;nil&lt;/code&gt;) or a pair of an integer (the head of the list) and another list (the tail of the list). You can symbolically write this as\List(\integer) = 1 + \integer \cdot \List(\integer)Here \(1\) is the &lt;i&gt;unit type&lt;/i&gt; with one element, it does not matter what this element is exactly. \(A + B\) is a &lt;a href=&quot;https://en.wikipedia.org/wiki/Disjoint_union&quot;&gt;&lt;i&gt;disjoint sum&lt;/i&gt;&lt;/a&gt; of \(A\) and \(B\). It is a &lt;a href=&quot;https://en.wikipedia.org/wiki/Tagged_union&quot;&gt;tagged union&lt;/a&gt; type, whose values are values of \(A\) or \(B\) marked as such. \(A \cdot B\) is the &lt;a href=&quot;https://en.wikipedia.org/wiki/Product_type&quot;&gt;product type&lt;/a&gt;. Its values are pairs of values of \(A\) and \(B\).In &lt;span class=&quot;annotation&quot; data-uid=&quot;4&quot;&gt;general&lt;/span&gt;, we have\List(x) = 1 + x \cdot \List(x)In Haskell this is written asdata List x = Nil | Cons x (List x)Similarly, a binary tree with values of type \(x\) at the nodes can be written as\BT(x) = 1 + x\cdot \BT(x) \cdot \BT(x)That is, a binary tree is either empty or a triple of the root, the left sub-tree and the right sub-tree. If we are only interested in the &amp;quot;shapes&amp;quot; of the binary trees we need\B = \BT(1) = 1 + \B^2Nothing too controversial so far. Now, apply some trivial algebra:\begin{array}{r@{\;}c@{\;}l@{\quad}}
        \List(x) &amp;amp;\;=\;&amp;amp; 1 + x \cdot \List(x)       \\
        \List(x) - x \cdot \List(x) &amp;amp;\;=\;&amp;amp; 1       \\
        \List(x) \cdot (1 - x) &amp;amp;\;=\;&amp;amp; 1            \\
        \List(x) &amp;amp;\;=\;&amp;amp; \frac{1}{1 - x}            \\
        \List(x) &amp;amp;\;=\;&amp;amp; 1 + x + x^2 + x^3 + \cdots
\end{array}Going from \(\List(x) - x \cdot \List(x)\) to \(\List(x) \cdot (1 - x)\) in the middle step arguably makes &lt;i&gt;some&lt;/i&gt; sense: product of sets and types distributes over sum, much like it does for integers. But the rest is difficult to justify or even interpret. What is the difference of types or their infinite series?The last equation, however, is perfectly valid: an element of \(\List(x)\) is either &lt;code class=&quot;inline&quot;&gt;nil&lt;/code&gt;, or a singleton element of \(x\), or a pair of elements of \(x\) or a triple, &lt;i&gt;etc&lt;/i&gt;. This is somewhat similar to the cavalier methods of eighteenth-century mathematicians like Euler and the Bernoulli brothers, who would boldly go where no series converged before and through a sequence of meaningless intermediate steps arrive to a correct result.One can apply all kinds of usual algebraic transformations to \(\List(x) = (1 - x)^{-1}\). For example,\begin{array}{r@{\;}c@{\;}l@{\quad}l@{\quad}}
        \List(a + b)         &amp;amp;\;=\;&amp;amp;    \frac{1}{1 - a - b} \\
                             &amp;amp;\;=\;&amp;amp;    \frac{1}{1 - a}\cdot\frac{1}{1 - \frac{b}{1 - a}} \\
                             &amp;amp;\;=\;&amp;amp;    \List(a)\cdot\List(\frac{b}{1 - a}) \\
                             &amp;amp;\;=\;&amp;amp;    \List(a)\cdot\List(b\cdot\List(a))
\end{array}This corresponds to the regular expressions identity \((a|b)^* = a^*(ba^*)^*\).Apply the same trick to binary trees:\begin{array}{r@{\;}c@{\;}l@{\quad}l@{\quad}}
        \BT                        &amp;amp;\;=\;&amp;amp;    1 + \BT^2 \cdot x          &amp;amp;     \\
        \BT^2 \cdot x - \BT + 1    &amp;amp;\;=\;&amp;amp;    0                          &amp;amp; \text{(Solve the quadratic equation.)}  \\
        \BT                        &amp;amp;\;=\;&amp;amp;    \frac{1\pm\sqrt{1-4\cdot x}}{2\cdot x} &amp;amp; \text{(Use binomial theorem)} \\
        \sqrt{1-4\cdot x}          &amp;amp;\;=\;&amp;amp;    \sum_{k=0}^\infty \binom{\tfrac12}{k}(-4\cdot x)^k &amp;amp; \\
        \BT(x)                     &amp;amp;\;=\;&amp;amp;    1 + x + 2\cdot x^2 + 5\cdot x^3 + 14\cdot x^4 + 42\cdot x^5 + \cdots &amp;amp; \\
                                   &amp;amp;\;=\;&amp;amp;    \sum_{n=0}^\infty C_n\cdot x^n, &amp;amp;
\end{array}Where \(C_n=\frac{1}{n+1}\binom{2\cdot n}{n}\)—the \(n\)-th &lt;a href=&quot;https://en.wikipedia.org/wiki/Catalan_number&quot;&gt;Catalan number&lt;/a&gt;, that is the number of binary trees with \(n\) nodes. To understand the last series we need to decide what \(n\cdot x\) is, where \(n\) is a non-negative integer and \(x\) is a type. Two natural interpretations aren \cdot x = x + x + \cdots = \sum_0^{n - 1} xandn \cdot x = \{0, \ldots, n - 1\} \cdot xwhich both mean the same: an element of \(n\cdot x\) is an element of \(x\) marked with one of \(n\) &amp;quot;branches&amp;quot;, and this is the same as a pair \((i, t)\) where \(0 &amp;lt;= i &amp;lt; n\) and \(t\) is an element of \(x\).The final series then shows that a binary tree is either an empty tree (\(1\)) or an \(n\)-tuple of \(x\)-es associated with one of \(C_n\) shapes of binary trees with \(n\) nodes. It worked again!Now, watch carefully. Take simple unmarked binary trees: \(\B = \BT(1) = 1 + \B^2\). In this case, we can &amp;quot;calculate&amp;quot; the solution exactly:\B^2 - \B + 1 = 0hence\B = \frac{1 \pm \sqrt{1 - 4}}{2} = \frac{1}{2} \pm i\cdot\frac{3}{2} = e^{\pm i\cdot\frac{\pi}{3}}Both solutions are sixth-degree roots of \(1\): \(\B^6 = 1\). OK, this is still completely meaningless, right? Yes, but it also means that \(\B^7 = \B\), which --if correct-- would imply that there is a bijection between the set of all binary trees and the set of all 7-tuples of binary trees. Haha, clearly impossible... Actually, it&amp;#x27;s a more or less well-known &lt;a href=&quot;https://arxiv.org/pdf/math/9405205&quot;&gt;fact&lt;/a&gt;.A note is in order. All &amp;quot;sets&amp;quot; and &amp;quot;types&amp;quot; that we talked about so far are at most countably infinite so, of course, there exists a bijection between \(\B\) and \(\B^7\) simply because both of these sets are countable. What is interesting, and what the paper linked to above explicitly establishes, is that there is as they call it &amp;quot;a very explicit&amp;quot; bijection between these sets, that is a &amp;quot;structural&amp;quot; bijection that does not look arbitrarily deep into its argument trees. For example, in a functional programming language, such a bijection can be coded through pattern matching &lt;i&gt;without&lt;/i&gt; recursion.Here is another neat example. A &lt;a href=&quot;https://en.wikipedia.org/wiki/Rose_tree&quot;&gt;rose tree&lt;/a&gt; is a kind of tree datatype where a node has an arbitrary list of children:\R(x) = x\cdot\List(\R(x))Substituting \(\List(x) = (1 - x)^{-1}\) we get\R(x) = \frac{x}{1 - R(x)}or\R^2(x) - \R(x) + x = 0Hence \(\R = \R(1)\) is defined by the same equation as \(\B = \BT(1)\): \(\R^2 - \R + 1 = 0\). So, there must be a bijection between \(\R\) and \(\B\), and of course there is: one of the first things LISP hackers realised in the late 1950s is that an arbitrary tree can be encoded with &lt;a href=&quot;https://en.wikipedia.org/wiki/Cons&quot;&gt;cons&lt;/a&gt; cells.All this is, by the way, is equally applicable to &lt;span class=&quot;annotation&quot; data-uid=&quot;5&quot;&gt;infinite datatypes&lt;/span&gt; (that is, streams, branching transition systems, &lt;i&gt;etc&lt;/i&gt;.)That was pure algebra, there is nothing &amp;quot;analytical&amp;quot; here. Analysis historically started with the notion of derivative. And sure, you can define and &lt;a href=&quot;https://www.cs.le.ac.uk/people/ma139/docs/derivative.pdf&quot;&gt;calculate derivatives&lt;/a&gt; of data type constructors like \(\List\) and \(\BT\). These derivatives are generalisations of &lt;a href=&quot;https://en.wikipedia.org/wiki/Zipper_(data_structure)&quot;&gt;zipper&lt;/a&gt;-like structures: they represent &amp;quot;holes&amp;quot; in the data-type, that can be filled by an instance of the type-parameter.For example, suppose you have a list \((x_0, \ldots, x_k, \ldots, x_{n - 1})\) of type \(\List(x)\) then a hole is obtained by cutting out the element \(x_k\) that is \((x_0, \ldots, x_{k-1}, \blacksquare, x_{k+1}, \ldots, x_{n - 1})\) and is fully determined by the part of the list to the left of the hole \((x_0, \ldots, x_{k - 1})\) and the part to the right \((x_{k+1}, \ldots, x_{n - 1})\). Both of these can be arbitrary lists (including empty), so a hole is determined by a pair of lists and we would expect \(\d \List(x) = \List^2(x)\). But Euler would have told us this immediately, because \(\List(x) = (1 - x)^{-1}\) hence\d \List(x) = \d (1 - x)^{-1} = (1 - x)^{-2} = \List^2(x)In general the derivative of a type constructor (of a &amp;quot;function&amp;quot; analytically speaking) \(T(x)\) comes with a &amp;quot;very explicit&amp;quot; surjective function\plug : \d T(x) \cdot x \to T(x)injective on each of its arguments, and has the usual properties of a derivative, among others:\begin{array}{r@{\;}c@{\;}l@{\quad}}
        \d (A + B)     &amp;amp;\;=\;&amp;amp;  \d A + \d B \\
        \d (A \cdot B) &amp;amp;\;=\;&amp;amp;  \d A \cdot B + A \cdot \d B \\
        \d_x A(B(x))   &amp;amp;\;=\;&amp;amp;  \d_B A(B) \cdot \d_x B(x) \\
        \d  x          &amp;amp;\;=\;&amp;amp;  1 \\
        \d  x^n        &amp;amp;\;=\;&amp;amp;  n\cdot x^{n-1} \\
        \d  n          &amp;amp;\;=\;&amp;amp;  0
\end{array}For binary trees we get\begin{array}{r@{\;}c@{\;}l@{\quad}}
        \d \BT(x)   &amp;amp;\;=\;&amp;amp;   \d (1 + x\cdot \BT^2(x)) \\
                          &amp;amp;\;=\;&amp;amp;   0 + \BT^2(x) + 2\cdot x\cdot \BT(x) \cdot \d \BT(x) \\
                          &amp;amp;\;=\;&amp;amp;   \BT^2(x) / (1 - 2\cdot x\cdot \BT(x)) \\
                          &amp;amp;\;=\;&amp;amp;   \BT^2(x) \cdot \List(2\cdot x\cdot \BT(x)) \\
                          &amp;amp;\;=\;&amp;amp;   \BT^2(x) \cdot \Zipper_2(x)
\end{array}Here \(\Zipper_2(x) = \List(2\cdot x\cdot \BT(x))\) is the &lt;a href=&quot;https://www.st.cs.uni-saarland.de/edu/seminare/2005/advanced-fp/docs/huet-zipper.pdf&quot;&gt;classical Huet&amp;#x27;s zipper&lt;/a&gt; for binary trees. We have an additional \(\BT^2(x)\) multiplier, because Huet&amp;#x27;s zipper plugs an entire sub-tree, that is, it&amp;#x27;s a \(\BT(x)\)-sized hole, whereas our derivative is an \(x\)-sized hole.For \(n\)-ary trees \(\T = 1 + x\cdot \T^n(x)\) we similarly have\begin{array}{r@{\;}c@{\;}l@{\quad}}
          \d \T(x)  &amp;amp;\;=\;&amp;amp;   \d (1 + x\cdot \T^n(x)) \\
                          &amp;amp;\;=\;&amp;amp;   0 + \T^n(x) + n\cdot x\cdot \T^{n-1}(x) \cdot \d \T(x) \\
                          &amp;amp;\;=\;&amp;amp;   \T^n(x) / (1 - n\cdot x\cdot \T^{n -1}(x)) \\
                          &amp;amp;\;=\;&amp;amp;   \T^n(x) \cdot \List(n\cdot x\cdot \T^{n - 1}(x)) \\
                          &amp;amp;\;=\;&amp;amp;   \T^n(x) \cdot \Zipper_n(x)
\end{array}At this point we have basic type constructors for arrays (\(x^n\)), lists and variously shaped trees, which we can combine and compute their derivatives. We can also try constructors with multiple type parameters (&lt;i&gt;e.g.&lt;/i&gt;, trees with different types at the leaves and internal nodes) and verify that the usual partial-differentiation rules apply. But your inner Euler must be jumping up and down: much more is possible!Indeed it is. Recall the &amp;quot;&lt;a href=&quot;https://en.wikipedia.org/wiki/Graded_structure&quot;&gt;graded&lt;/a&gt;&amp;quot; representation of \(\List(x)\):\List(x) = 1 + x + x^2 + x^3 + \cdotsThis formula says that there is one (i.e, \(|x|^0\)) list of length \(0\), one list (of length \(1\)) for each element of \(x\), one list for each ordered pair of elements of \(x\), for each ordered triple, &lt;i&gt;etc&lt;/i&gt;. What if we forget the order of \(n\)-tuples? Then, by identifying each of the possible \(n!\) permutations, we would get, instead of lists with \(n\) elements, &lt;a href=&quot;https://en.wikipedia.org/wiki/Multiset&quot;&gt;multisets&lt;/a&gt; (bags) with \(n\) elements.\Bag(x) = \frac{1}{0!} + \frac{x}{1!} + \frac{x^2}{2!} + \cdots + \frac{x^k}{k!} + \cdots = e^xThis counting argument, taken &lt;span class=&quot;linktarget&quot; data-uid=&quot;0&quot;&gt;&lt;span class=&quot;annotation&quot; data-uid=&quot;1&quot;&gt;literally&lt;/span&gt;&lt;/span&gt;, does not hold water. For one thing, it implies that every term in \(e^x\) series is an integer (hint: there are no \(n!\) \(n\)-tuples belonging to the same class as \((t, t, \ldots, t)\)). But it drives the intuition in the right direction and \(\Bag(x)\) does have the same properties as the exponent. Before we demonstrate this, let&amp;#x27;s look at another example.A list of \(n\) elements is one of \(|x|^n\) \(n\)-tuples of elements of \(x\). A bag with \(n\) elements is one of such tuples, considered up to a permutation. A &lt;i&gt;set&lt;/i&gt; with \(n\) elements is an \(n\)-tuple of &lt;i&gt;different&lt;/i&gt; elements considered up to a permutation. Hence, where for lists and bags we have \(x^n\), sets have \(x\cdot(x - 1)\cdot\cdots\cdot(x - n + 1)\) by the standard combinatorial argument: there are \(x\) options for the first element, \(x - 1\) options for the second element and so on.That is,\begin{array}{r@{\;}c@{\;}l@{\quad}}
\Set(x) &amp;amp;\;=\;&amp;amp; 1 + \frac{x}{1!} + \frac{x\cdot(x - 1)}{2!} + \frac{x\cdot(x - 1)\cdot(x - 2)}{3!} + \cdots + \frac{x\cdot(x - 1)\cdot\cdots\cdot(x - k + 1)}{k!} + \cdots \\
        &amp;amp;\;=\;&amp;amp; (1 + 1)^x \;\;\;\;\text{(By binomial)} \\
        &amp;amp;\;=\;&amp;amp; 2^x
\end{array}OK, we have \(\Bag(x) = e^x\) and \(\Set(x) = 2^x\). The latter makes sense from the cardinality point of view: there are \(2^x\) subsets of set \(x\) (even when \(x\) is infinite). Moreover, both \(\Set\) and \(\Bag\) satisfy the basic exponential identity \(\alpha^{x + y} = \alpha^x\cdot\alpha^y\). Indeed a bag of integers and Booleans can be uniquely and unambiguously separated into the bag of integers and the bag of Booleans, that can be poured back together to produce the original bag, and the same for sets. This does not work for lists: you can separate a list of integers and Booleans into two lists, but there is no way to restore the original list from the parts. This provides a roundabout argument, if you ever need one, that function \((1 - x)^{-1}\) does not have form \(\alpha^x\) for any \(\alpha\).Next, \(\alpha^x\) is the type of functions from \(x\) to \(\alpha\), \(\alpha^x = [x \to \alpha]\). For sets this means that an element of \(\Set(x)\), say \(U\), can be thought of as the &lt;a href=&quot;https://en.wikipedia.org/wiki/Indicator_function&quot;&gt;characteristic function&lt;/a&gt; \(U : x \to \{0, 1\}\)U(t) =
\begin{cases}
  1, &amp;amp; t \in U,\\
  0, &amp;amp; t \notin U.
\end{cases}For \(\Bag(x)\) we want to identify a bag \(V\) with a function \(V : x \to e\). What is \(e\)? By an easy sleight of hand we get:e = e^1 = \Bag(1) = \{ 0, 1, \ldots \} = \nat(Because for the one-element unit type \(1\), a bag from \(\Bag(1)\) is fully determined by the (non-negative) number of times the only element of \(1\) is present in the bag.)Hence, we have \(\Bag(x) = \nat^x = [x \to \nat]\), which looks surprisingly reasonable: a bag of \(x\)-es can be identified with the function that for each element of \(x\) gives the number of occurrences of this element in the bag. (Finite) bags are technically &amp;quot;&lt;a href=&quot;https://en.wikipedia.org/wiki/Free_monoid#The_free_commutative_monoid&quot;&gt;free commutative monoids&lt;/a&gt;&amp;quot; generated by \(x\).Moreover, the most famous property of \(e^x\) is that it is its own derivative, so we would expect\d \Bag(x) = \Bag(x)And it is: if you take a bag and make a hole in it, by removing one of its elements, you get nothing more and nothing less than another bag. The &amp;quot;plug&amp;quot; function \(\plug : \Bag(x)\cdot x \to \Bag(x)\) is just multiset union:\plug (V, t) = V \cup \{t\},which is clearly &amp;quot;very explicit&amp;quot; and possesses the required properties of injectivity and surjectivity. This works neither for lists, trees and arrays (because you have to specify where the new element is to be added) nor for sets (because if you add an element already in the set, the plug-map is not injective).The central rôle of \(e^x\) in analysis indicates that perhaps it is multiset, rather than list, that is the most important datastructure.If we try to calculate the derivative of \(\Set(x)\) we would get \(\d\Set(x) = \d(2^x) = \d e^{\ln(2)\cdot x} = \ln(2)\cdot 2^x = \ln(2)\cdot\Set(x)\), of which we cannot make much sense (yet!), but we can calculate\Bag(\d\Set(x)) = e^{\d\Set(x)} = e^{\ln(2)\cdot\Set(x)} = 2^{Set(x)} = \Set(\Set(x))Nice. Whatever the derivative of \(\Set(x)\) is, a bag of them is a set of sets of \(x\).Thinking about a type constructor \(T(x) = \sum_{i&amp;gt;0} a_i\cdot x^i\) as an non-empty (\(i &amp;gt; 0\)) container, we can consider its &lt;a href=&quot;https://en.wikipedia.org/wiki/Pointed_set&quot;&gt;pointed&lt;/a&gt; version, where a particular element in the container is marked:\begin{array}{r@{\;}c@{\;}l@{\quad}}
\Punct(T(x)) &amp;amp;\;=\;&amp;amp; \sum_{i&amp;gt;0} i\cdot a_i\cdot x^i \\
             &amp;amp;\;=\;&amp;amp; x\cdot \sum_{i&amp;gt;0} i\cdot a_i\cdot x^{i-1} \\
             &amp;amp;\;=\;&amp;amp; x\cdot \sum_{i&amp;gt;0} a_i\cdot \d x^i \\
             &amp;amp;\;=\;&amp;amp; x\cdot \d \sum_{i&amp;gt;0} a_i\cdot x^i \\
             &amp;amp;\;=\;&amp;amp; x\cdot \d T(x)
\end{array}This has clear intuitive explanation: if you cut a hole in a container and kept the removed element aside, you, in effect, marked the removed element.The next logical step is to try to recall as many Taylor expansions as one can to see what types they correspond to. Start with the easy ones: &lt;span class=&quot;annotation&quot; data-uid=&quot;4&quot;&gt;hyperbolic functions&lt;/span&gt;\cosh(x) = 1 + \frac{x^2}{2!} + \frac{x^4}{4!} + \cdotsand\sinh(x) = x + \frac{x^3}{3!} + \frac{x^5}{5!} + \cdots\(\cosh(x)\) is the type of bags of \(x\) with an even number of elements and \(\sinh(x)\) is the type of bags of \(x\) with an odd number of elements. Of course, \(\cosh\) and \(\sinh\) happen to be &lt;a href=&quot;https://en.wikipedia.org/wiki/Even_and_odd_functions&quot;&gt;an even and an odd function&lt;/a&gt; respectively. So to answer the question in the title: \(\cosh(\List(\Bool))\) is the type of bags of even number of lists of Booleans. It is easy to check that all usual hyperbolic trigonometry identities hold.We can also write down a general function type \([ x \to (1 + y) ]\):[ x \to (1 + y) ] = (1 + y)^x = 1 + y\cdot x + y^2\cdot\frac{x\cdot(x - 1)}{2!} + y^3\cdot\frac{x\cdot(x-1)\cdot(x-2)}{3!} + \cdotsCombinatorial interpretation(s) (there are at least two of them!) are left to the curious reader.We have by now seen the series with the terms of the form \(n_k\cdot x^k\) (\(n_k \in \nat\)) corresponding to various tree-list types, the series with the terms \(n_k\cdot\frac{x^k}{k!}\) corresponding to function-exponent types. What about &amp;quot;logarithm&amp;quot;-like series with terms of the form \(n_k\cdot\frac{x^k}{k}\)? Similarly to the exponential case, we try to interpret them as types where groups of \(n\) \(n\)-tuples are identified. The obvious candidates for such groups are all possible &lt;i&gt;rotations&lt;/i&gt; of an \(n\)-tuple. The learned name for \(n\)-tuples identified up to a rotation is &amp;quot;an (aperiodic) &lt;a href=&quot;https://en.wikipedia.org/wiki/Necklace_(combinatorics)#Aperiodic_necklaces&quot;&gt;necklace&lt;/a&gt;&amp;quot;, we will call it a ring. The type of non-empty rings of elements of \(x\) is given by\Ring(x) = x + \frac{x^2}{2} + \frac{x^3}{3} + \cdotsCompare with:\begin{array}{r@{\;}c@{\;}l@{\quad}}
\ln(1 + x) &amp;amp;\;=\;&amp;amp; x - \frac{x^2}{2} + \frac{x^3}{3} - \frac{x^4}{4} + \cdots \\
\ln(1 - x) &amp;amp;\;=\;&amp;amp; - x - \frac{x^2}{2} - \frac{x^3}{3} - \frac{x^4}{4} - \cdots \\
- \ln(1 - x) &amp;amp;\;=\;&amp;amp; x + \frac{x^2}{2} + \frac{x^3}{3} + \frac{x^4}{4} + \cdots \\
             &amp;amp;\;=\;&amp;amp; \Ring(x)
\end{array}Now comes the cool part:\Bag(\Ring(x)) = e^{\Ring(x)} = e^{- \ln(1 - x)} = (1 - x)^{-1} = \List(x)We are led to believe that for any type there is a &amp;quot;very explicit&amp;quot; bijection between bags of rings and lists. That is, it is possible to decompose any list to a multiset of rings (containing the same elements, because &lt;i&gt;nothing&lt;/i&gt; about \(x\) is given) in such a way that the original list can be unambiguously recovered from the multiset.Sounds pretty far-fetched? It is called &lt;a href=&quot;https://en.wikipedia.org/wiki/Monoid_factorisation#Chen%E2%80%93Fox%E2%80%93Lyndon_theorem&quot;&gt;Chen–Fox–Lyndon theorem&lt;/a&gt;, by the way. This theorem has a curious history. The most accessible exposition is in De Bruijn, Klarner, &lt;a href=&quot;https://pure.tue.nl/ws/files/1674487/597568.pdf&quot;&gt;Multisets of aperiodic cycles&lt;/a&gt; (1982). The &amp;quot;&lt;a href=&quot;https://en.wikipedia.org/wiki/Lyndon_word&quot;&gt;Lyndon words&lt;/a&gt;&amp;quot; term is after Lyndon, &lt;a href=&quot;https://www.ams.org/journals/tran/1954-077-02/S0002-9947-1954-0064049-X/S0002-9947-1954-0064049-X.pdf&quot;&gt;On Burnside&amp;#x27;s Problem&lt;/a&gt; (1954). The original result is in Ширшов, &lt;a href=&quot;https://www.mathnet.ru/links/b8bccc0594081ab6fad538ff3448ac8f/sm5381.pdf&quot;&gt;Подалгебры свободных лиевых алгебр&lt;/a&gt; (1953), where it is used to estimate dimensions of sub-algebras of free Lie algebras. See also I.57 (p. 85) in &lt;a href=&quot;https://algo.inria.fr/flajolet/Publications/book.pdf&quot;&gt;Analytic Combinatorics&lt;/a&gt; by Flajolet and Sedgewick.If you are still not convinced that \(\Ring(x) = -\ln(1 - x)\), consider\d\Ring(x) = -\d\ln(1 - x) = (1 - x)^{-1} = \List(x)If you cut a hole in a ring, you get a list!We still have no interpretation for alternating series like \(\ln(1 + x) = x - x^2/2 + x^3/3 - x^4/4 + \cdots\). Fortunately, our good old friend \(\List(x) = (1 - x)^{-1}\) gives us\List(2) = -1which, together with the &lt;a href=&quot;https://en.wikipedia.org/wiki/Inclusion%E2%80%93exclusion_principle&quot;&gt;inclusion–exclusion principle&lt;/a&gt;, can be used to concoct plausibly looking explanations of types like \(\sin(x) = x - x^3/3! + x^5/5! + \cdots\), &lt;i&gt;etc&lt;/i&gt;.Of course, (almost) all here can be made formal and rigorous. Types under \(+\) and \(\cdot\) form a &lt;a href=&quot;https://en.wikipedia.org/wiki/Semiring&quot;&gt;semiring&lt;/a&gt;. The additive structure can be extended to an abelian group by the &lt;a href=&quot;https://en.wikipedia.org/wiki/Grothendieck_group&quot;&gt;Grothendieck group&lt;/a&gt; construction. The &lt;a href=&quot;https://en.wikipedia.org/wiki/Field_of_fractions&quot;&gt;field of fractions&lt;/a&gt; can be built. &lt;a href=&quot;https://en.wikipedia.org/wiki/Puiseux_series&quot;&gt;Puiseux&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Levi-Civita_field&quot;&gt;Levi-Civita&lt;/a&gt; series in this field provide &amp;quot;analysis&amp;quot; without the baggage of limits and topology.But they definitely had more fun back in the eighteenth century. Can we, instead of talking about &amp;quot;&lt;a href=&quot;https://en.wikipedia.org/wiki/Fiber_bundle&quot;&gt;fibre bundles&lt;/a&gt; over \(\Ring(\lambda t.t\cdot x)\)&amp;quot;, dream of Möbius strips of streams?</content>
        </item>

        <item>
            <title>BSD VM scanner</title>
            <id>bsd-vm</id>
            <link>https://cofault.com/bsd-vm.html#bsd-vm</link>
            <pubDate>2005/07/25</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/bsd-vm.html#bsd-vm">
                     BSD vm analyzes object reference counter in page scanner (&lt;code class=&quot;inline&quot;&gt;vm_pageout.c:vm_pageout_scan()&lt;/code&gt;):/*
 * If the object is not being used, we ignore previous 
 * references.
 */
if (m-&amp;gt;object-&amp;gt;ref_count == 0) {
        vm_page_flag_clear(m, PG_REFERENCED);
        pmap_clear_reference(m);
}
....
/*
 * Only if an object is currently being used, do we use the
 * page activation count stats.
 */
if (actcount &amp;amp;&amp;amp; (m-&amp;gt;object-&amp;gt;ref_count != 0)) {
        vm_pageq_requeue(m);
}
....</content>
        </item>

        <item>
            <title>Generating Catalan numbers.</title>
            <id>catalan</id>
            <link>https://cofault.com/catalan.html#catalan</link>
            <pubDate>2022/10/07</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/catalan.html#catalan">
                     Enumerate all binary trees with N nodes, C++20 way:#include &amp;lt;memory&amp;gt;
#include &amp;lt;string&amp;gt;
#include &amp;lt;cassert&amp;gt;
#include &amp;lt;iostream&amp;gt;
#include &amp;lt;coroutine&amp;gt;
#include &amp;lt;cppcoro/generator.hpp&amp;gt;

struct tnode;
using tree = std::shared_ptr&amp;lt;tnode&amp;gt;;
struct tnode {
	tree left;
	tree right;
	tnode() {};
	tnode(tree l, tree r) : left(l), right(r) {}
};

auto print(tree t) -&amp;gt; std::string {
	return  t ? (std::string{&amp;quot;[&amp;quot;} + print(t-&amp;gt;left) + &amp;quot; &amp;quot;
		     + print(t-&amp;gt;right) + &amp;quot;]&amp;quot;) : &amp;quot;*&amp;quot;;
}

cppcoro::generator&amp;lt;tree&amp;gt; gen(int n) {
	if (n == 0) {
		co_yield nullptr;
	} else {
		for (int i = 0; i &amp;lt; n; ++i) {
			for (auto left : gen(i)) {
				for (auto right : gen(n - i - 1)) {
					co_yield tree(new tnode(left, right));
				}
			}
		}
	}
}

int main(int argc, char **argv) {
	for (auto t : gen(std::atoi(argv[1]))) {
		std::cout &amp;lt;&amp;lt; print(t) &amp;lt;&amp;lt; std::endl;
	}
}Source: &lt;a href=&quot;https://github.com/nikitadanilov/bits/blob/master/gen.cpp&quot;&gt;gen.cpp&lt;/a&gt;.To generate &lt;a href=&quot;https://en.wikipedia.org/wiki/Catalan_number&quot;&gt;Catalan numbers&lt;/a&gt;, do:$ for i in $(seq 0 1000000) ;do ./gen $i | wc -l ;done
       1
       1
       2
       5
      14
      42
     132
     429
    1430
    4862
   16796
   58786
  208012
  742900</content>
        </item>

        <item>
            <title>Деревья по кругу.</title>
            <id>деревья</id>
            <link>https://cofault.com/деревья.html#деревья</link>
            <pubDate>2012/09/28</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/деревья.html#деревья">
                     &lt;i&gt;Abstract&lt;/i&gt;: orbits of an endomorphism of a finite set are represented as  connected components of a suitably defined graph. Their structure is  surprisingly simple: a collection of disjoint trees rooted on the vertices of a  unique cycle.Пусть \(f:X\rightarrow X\), произвольное отображение множества \(X\) в себя, т.е. &lt;a href=&quot;http://en.wikipedia.org/wiki/Endomorphism&quot;&gt;эндоморфизм&lt;/a&gt; \(X\). Известно, что если \(f\) является &lt;a href=&quot;http://en.wikipedia.org/wiki/Automorphism&quot;&gt;автоморфизмом&lt;/a&gt; (т.е. &lt;a href=&quot;http://en.wikipedia.org/wiki/Bijective_map&quot;&gt;биекцией&lt;/a&gt;), то оно разбивает \(X\) на непересекающиеся &lt;a href=&quot;http://en.wikipedia.org/wiki/Orbit_(group_theory)#Orbits_and_stabilizers&quot;&gt;орбиты&lt;/a&gt;. Каждая орбита состоит из точек\ldots f^{-2}(x), f^{-1}(x), x, f(x), f^2(x), \ldotsдля некоторого \(x\), где \(f^n\) означает \(n\)-кратное применение \(f\) (\(f^0(x) = x\), \(f^{n+1}(x) = f(f^n(x))\), \(f^{-n}(x) = (f^{-1})^n(x)\)). Если \(X\) конечно, то всякая орбита является &lt;i&gt;циклом&lt;/i&gt;, состоящим из конечного числа точек, и для некоторого \(n\) будет \(x = f^{n}(x)\). В случае бесконечного \(X\) могут существовать орбиты, состоящие из бесконечного (счетного) числа различных точек.Как выглядят аналоги орбит для произвольных эндоморфизмов конечных множеств?Обычное определение орбиты не дает интересного обобщения на эндоморфизмы, т.к. получающися множества пересекаются. Вместо этого, дадим следующее определение:Множество \(M\), \(M \subseteq X\), \(f\)-замкнуто, если \(x \in M\equiv  f(x)\in M\), т.е. \(f\)-замкнутое множество содержит вместе с каждой точкой  \(x\) ее образ \(f(x)\) и все прообразы \(f^{-1}(x)\).Очевидно, чтоПересечение \(f\)-замкнутых множеств \(M\) и \(N\) — \(f\)-замкнуто:\(x\in M \cap N\)\(\equiv\) { определение пересечения множеств }\(x\in M \wedge x\in N\)\(\equiv\){ определение \(f\)-замкнутости}\(f(x)\in M \wedge f(x)\in N\)\(\equiv\){ определение пересечения множеств }\(f(x)\in M \cap N\)Орбитой называется непустое минимальное \(f\)-замкнутое множество, т.е. \(f\)-замкнутое множество не имеющее собственных \(f\)-замкнутых подмножеств.  Для автоморфизмов это определение совпадает со стандартным.Очевидно, что орбиты не пересекаются (иначе их пересечение было бы их \(f\)-замкнутым подмножеством, в нарушение требования минимальности). Кроме этого, всякая точка принадлежит хотя бы одному \(f\)-замкнутому множеству, например всему \(X\). Это значит, что для всякой точки определено пересечение всех \(f\)-замкнутых множеств, содержащих эту точку. Такое пересечение будет орбитой. Следовательно \(X\) разбивается на непересекающиеся орбиты.ГрафОтображению \(f\) можно сопоставить ориентированный граф (который останется безымянным, как единственный, подлежащий рассмотрению), с множеством вершин \(X\) и множеством дуг \(\{(x, f(x)) | x \in X \}\).Этот граф обладает замечательным свойством: у каждой его вершины есть ровно одна исходящая дуга. Очевидно, что всякому графу, обладающему таким свойством соответствует эндоморфизм множества вершин.Мы будет также рассматривать неориентированную версию этого же графа (в которой забыты направление дуг) и будем в этом случае говорить о &amp;quot;ребрах&amp;quot; (а не дугах), неориентированнх путях и неориентированных циклах.Все пути и циклы предполагаются простыми, т.е. проходящими через данную дугу или вершину не более одного раза, если не оговорено противное.Переформулировав определение орбиты в терминах неориентированного графа, получаем, что пара связанных ребром вершин принадлежит одной и той же орбите. Отсюда следует, что орбиты это в точности &lt;a href=&quot;http://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D0%BC%D0%BF%D0%BE%D0%BD%D0%B5%D0%BD%D1%82%D0%B0_%D1%81%D0%B2%D1%8F%D0%B7%D0%BD%D0%BE%D1%81%D1%82%D0%B8_%D0%B3%D1%80%D0%B0%D1%84%D0%B0&quot;&gt;компоненты связности&lt;/a&gt; неориентированного графа.Рассмотрим дугу \(a\) из вершины \(x\) в вершину \(y\) (т.е. предположим, что \(y = f(x)\)). Для соответствующего ребра \(a\) определим\begin{array}{r@{\;}c@{\;}l@{\quad}}
       \sigma(x, a) &amp;amp;\;=\;&amp;amp;  0,\quad \text{если \(x = y\), иначе} \\
       \sigma(x, a) &amp;amp;\;=\;&amp;amp; +1 \\
       \sigma(y, a) &amp;amp;\;=\;&amp;amp; -1
\end{array}Таким образом, функция \(\sigma\) определена для любой вершины и смежного ей ребра и обладает следующими свойствами:Если ребро \(a\) соединяет вершины \(x\) и \(y\), то \(\sigma(x, a) + \sigma(y,  a) = 0\) (свойство (0))Если вершина \(x\) соединяет ребра \(a\) и \(b\), то \(\sigma(x, a) + \sigma(x,  b) \leq 0\) (свойство (1))Теперь мы может доказать простую лемму:Если \(a_0, ... a_n\) неориентированный путь между вершинами \(x\) и \(y\), то  \(\sigma(x, a_0) + \sigma(y, a_n) &amp;gt; -2\), т.е. крайние ребра пути не могут  быть одновременно входящими.Индукция по длине пути.\(n = 1\). Немедленно по свойству (0).\(n = k + 1\). Пусть \(a_0, ... a_k\) неориентированный путь между вершинами   \(x\) и \(z\), а ребро \(a_{k+1}\) соединяет \(z\) и \(y\).\begin{array}{r@{\;}l@{\quad}}
       &amp;amp; \sigma(x, a_0) + \sigma(y, a_{k+1}) \\
  \;=\;&amp;amp; \sigma(x, a_0) + \sigma(y, a_{k+1}) + \sigma(z, a_k) - \sigma(z, a_k) \\
  \;&amp;gt;\;&amp;amp; \text{ \{ по гипотезе индукции \(\sigma(x, a_0) + \sigma(z, a_k) &amp;gt; -2\) \} } \\
       &amp;amp; -2 + \sigma(y, a_{k+1}) - \sigma(z, a_k) \\
  \;=\;&amp;amp; -2 + \sigma(y, a_{k+1}) - \sigma(z, a_k) + \sigma(z, a_{k+1}) - \sigma(z, a_{k+1}) \\
  \;\geq\;&amp;amp; \text{ \{ по свойству (1) \(\sigma(z, a_k) + \sigma(z, a_{k+1}) \leq 0\) \} } \\
       &amp;amp; -2 + \sigma(y, a_{k+1}) + \sigma(z, a_{k+1}) \\
  \;=\;&amp;amp; \text{ \{ по свойству (0) \(\sigma(y, a_{k+1}) + \sigma(z, a_{k+1}) = 0\) \} } \\ 
  \;=\;&amp;amp; -2 \\
\end{array}ЦиклыРассмотрим ориентированные циклы в нашем графе. Для всякой вершины \(x\), лежащей на ориентированном цикле из \(n\) вершин \((x_i | 0 \leq i &amp;lt; n)\), имеем \(f^n(x) = x\). В частности, циклы длины 1 это в точности стационарные точки \(f\).  Обратно, множество вершин всякого ориентированного цикла длины \(n\) можно описать как\{f^i(x) | 0 \leq i &amp;lt; n\} = \{f^i(x) | 0 \leq i\} = \{x, f(x), \ldots, f^{n-1}(x)\}где за \(x\) можно принять любую вершину цикла.При помощи функции \(\sigma\) легко доказывается и следующий полезный факт:&lt;i&gt;Всякий цикл ориентирован&lt;/i&gt;.Рассмотрим неориентированный цикл из ребер \(a_i\), соединяющих вершины \(x_i\)  и \(x_{i+1}\), где \(0 \leq i &amp;lt; n\) и \(i+1\) понимается по модулю \(n\).  Составим суммуS = \sum_{0 \leq i &amp;lt; n}\sigma(x_i, a_i) + \sigma(x_{i+1}, a_i)По свойству (0), каждое слагаемое этой суммы равно 0. Перегруппировав слагаемые, получимS = \sum_{0 \leq i &amp;lt; n}\sigma(x_i, a_i) + \sigma(x_i, a_{i-1}) = 0По свойству (1), каждое слагаемое здесь не больше нуля. Так как сумма равно 0,  то каждое слагаемое равно 0:\sigma(x_i, a_i) + \sigma(x_i, a_{i-1}) = 0Т.е., в каждую вершину цикла входит и выходит одна дуга, то есть цикл  ориентирован.С этого момента не будет различать ориентированные и неориентированные циклы.Просто доказывается следующее свойство:&lt;i&gt;Циклы имеющие общую вершину совпадают&lt;/i&gt;.Действительно, пусть циклы \(\{f^i(x) | 0 \leq i\}\) и \(\{f^i(y) | 0 \leq i\}\) имеют общую точку. Т.е. \(f^p(x) = f^q(y)\). Для произвольной точки первого цикла имеем\begin{array}{r@{\;}l@{\quad}}
       &amp;amp; f^i(x) \\
  \;=\;&amp;amp; \text{ \{ для произвольного \(d\), так как \(f^n(x) = x\) \} } \\
       &amp;amp; f^{i+ d\cdot n}(x) \\
  \;\geq\;&amp;amp; \text{ \{ выберем \(d\) так, что \(i+ d\cdot n &amp;gt; p\) \} } \\
  \;=\;&amp;amp; f^{p + \Delta}(x) \\
  \;=\;&amp;amp; f^\Delta(f^p(x)) \\
  \;=\;&amp;amp; \text{ \{ \(f^p(x) = f^q(y)\) \} }\\
       &amp;amp; f^{q +\Delta}(y) \in \{f^i(y) | 0 \leq i\}
\end{array}Аналогично, всякая точка второго цикла принадлежит первому.Отсюда следует интересное свойство:Всякий неориентированный путь \(P\) между вершинами \(x\) и \(y\), лежащими на  циклах, полностью лежит в некотором цикле.Применим индукцию  по длине \(P\).\(n = 0\). Очевидно.\(n = k + 1\). По лемме, хотя бы одно из крайних ребер \(P\) —   исходящее. Пусть это ребро, исходящее из точки \(x\). Это ребро соединяет   \(x\) с вершиной \(f(x)\), также лежащей на цикле. Таким образом, путь \(f(x),   \ldots, y\) длины \(k\) соединяет точки, лежащие на циклах и следовательно (по   гипотезе индукции), полностью лежит в некотором цикле. Этот цикл имеет общую   точку \(f(x)\) с циклом в котором лежит точка \(x\) и, следовательно, эти   циклы совпадают. Таким образом, путь \(x, \ldots, y\) полностью лежит в цикле.Таким образом, два разных цикла не могут быть соединены путем. Следовательно, каждая орбита содержит не более одного цикла.Настало время использовать конечность \(X\).&lt;i&gt;Всякая орбита конечного множества содержит цикл&lt;/i&gt;.Действительно, орбита \(M\) не пуста по определению. Выберем в ней точку \(x\) и рассмотрим функцию \(\phi : \mathbb{N} \rightarrow M\), \(\phi(n) = f^n(x)\). Т.к. \(M\) конечно, \(\phi\) не может быть однозначным отображением и существуют натуральные числа \(p\) и \(q\), такие что \(f^p(x) = f^q(x)\). Следовательно, \(f^p(x)\) лежит на цикле длины не большей \(|p - q|\).Зафиксируем орбиту и ее единственный цикл.Рассмотрим &amp;quot;прореженный&amp;quot; граф, получающийся из орбиты уделением всех ребер цикла и выберем компоненту связности этого графа, содержащую произвольную вершину на цикле.Очевидно, чтоэто множество не содержит других точек цикла, так как по свойству,  установленному выше, всякий путь соединяющий точки цикла лежит в этом цикле, а  ребра цикла были удалены;это множество не содержит циклов, т.к. цикл в компоненте единственный и его  ребра удалены.Итак, компонента является связным (по построению) графом без циклов, т.е. &lt;a href=&quot;http://ru.wikipedia.org/wiki/%D0%94%D0%B5%D1%80%D0%B5%D0%B2%D0%BE_(%D1%82%D0%B5%D0%BE%D1%80%D0%B8%D1%8F_%D0%B3%D1%80%D0%B0%D1%84%D0%BE%D0%B2)&quot;&gt;деревом&lt;/a&gt;, пересекающимся с циклом ровно в одной точке, которую можно выбрать за корень. Каждой точке цикла соответствует такое дерево. Деревья, соответствующие разным точкам цикла не пересекаются (как компоненты связности).Докажем, что всякая точка \(x\) орбиты принадлежит такому дереву. Для этого достаточно показать, что \(x\) можно соединить с некоторой вершиной цикла неориентированным путем не проходящим через ребра цикла (т.е. неориентированным путем пролегающем в прореженном графе) Т.к. орбита связна, то существует неориентированный путь \(P\), соединяющий \(x\) с вершиной цикла. Если этот путь содержит ребро цикла \(a\), то он распадается в композицию путей \(P = P_0\cdot a\cdot Q_0\). \(P_0\) соединяет \(x\) с одной из точек, соединенных ребром \(a\), т.е. с некоторой точкой на цикле. Повторяя процесс этот процесс необходимое число раз мы получим путь \(P_n\), который не содержит ребер цикла (возможно вообще не содержит ребер).Итак, орбита эндоморфизма конечного множества распадается на непересекающиеся деверья, корни которых прикреплены к циклу.Под действием последовательного применения преобразования \(f\), всякая точка сначала движется по дереву, в направлении корня, сливаясь при этом с другими точками этого дерева. После достижения корня, точка начинает двигаться по циклу.БесконечностьВ случае бесконечного множества, орбита может быть устроена несколько сложнее.Вместо циклов, придется рассмотреть &lt;i&gt;траектории&lt;/i&gt;, определенные, как последовательности точек \((f^n(x) | n &amp;gt; 0)\). Цикл является частным случаем траектории.Так же как и в случае с циклами, неориентированный путь, соединяющий точки на траекториях, сам лежит в некоторой траектории. Однако траектории имеющие общую точку не обязаны совпадать. К счастью, имеется более слабое, но полезное свойство: если пересечение траекторий непусто, то оно является траекторией.Как и в конечном случае, рассмотрим компоненту связности. Возьмем пересечение всех содержащихся в ней траекторий. Предположим, что оно непусто. В таком случае, это перечение есть траектория. Образуем прореженный граф, удалив все ребра траектории-пересечения. Так как мы удалили как минимум по ребру из каждой траектории, то в рассматриваемой компоненте связности не осталось ни одной траектории, в частности, ни одного цикла. Неориентированная компонента связности прореженного графа является таким образом, связным ацикличным графом, т.е. деревом.Итак, в случае непустого пересечения траекторий, орбита распадается на непересекающиеся деревья, корни которых закреплены на траектории-пересечении.Остается рассмотреть случай пустого пересечения. Пример такой ситуации доставляет функцияf:\mathbb{N}\times\mathbb{N}\rightarrow\mathbb{N}\times\mathbb{N}f(x, y) = (\lfloor x/2^y\rfloor\cdot 2^y, y+1)\(f\) строит бесконечное &amp;quot;дерево&amp;quot;, начиная с листьев, склеивая \(2^y\) смежных узлов уровня \(y\) в один узел уровня \(y+1\).  Очевидно, что все множество \(\mathbb{N}\times\mathbb{N}\) является орбитой. Каждая траектория через конечное число шагов достигает оси \(x = 0\), следовательно все траектории пересекаются, но их пересечение пусто.Однако здесь бессоница отступает и авторы прекращают дозволенные речи.</content>
        </item>

        <item>
            <title>Cographs, cocounts and coconuts.</title>
            <id>cographs</id>
            <link>https://cofault.com/cographs.html#cographs</link>
            <pubDate>2018/03/09</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/cographs.html#cographs">
                     &lt;i&gt;Abstract&lt;/i&gt;: Dual of the familiar construction of the graph of a function is  considered. The symmetry between graphs and cographs can be extended to a  suprising degree.Given a function \(f : A \rightarrow B\), the &lt;i&gt;graph of f&lt;/i&gt; is defined asf^* = \{(x, f(x)) \mid x \in A\}.In fact, within &lt;a href=&quot;https://en.wikipedia.org/wiki/Zermelo%E2%80%93Fraenkel_set_theory&quot;&gt;ZFC&lt;/a&gt; framework, functions are &lt;i&gt;defined&lt;/i&gt; as graphs. A graph is a subset of the Cartesian product \(A \times B\). One might want to associate to \(f\) a dual &lt;i&gt;cograph&lt;/i&gt; object: a certain quotient set of the disjoint sum \(A \sqcup B\), which would uniquely identify the function. To understand the structure of the cograph, define the graph of a morphism \(f : A \rightarrow B\) in a &lt;a href=&quot;https://en.wikipedia.org/wiki/Category_(mathematics)&quot;&gt;category&lt;/a&gt; with suitable products as a fibred product:\begin{CD}
f^* @&amp;gt;\pi_2&amp;gt;&amp;gt; B\\
@V \pi_1 V V  @VV 1_B V\\
A @&amp;gt;&amp;gt;f&amp;gt; B
\end{CD}In the category of sets this gives the standard definition. The cograph can be defined by a dual construction as a push-out:\begin{CD}
A @&amp;gt;1_A&amp;gt;&amp;gt; A\\
@V f V V  @VV j_1 V\\
B @&amp;gt;&amp;gt;j_2&amp;gt; f_*
\end{CD}Expanding this in the category of sets gives the following definition:f_* = (A \sqcup B) / \pi_f,where \(\pi_f\) is the reflexive transitive closure of a relation \(\theta_f\) given by (assuming in the following, without loss of generality, that \(A\) and \(B\) are disjoint)x\overset{\theta_f}{\sim} y \equiv y = f(x)That is, \(A\) is partitioned by \(\pi_f\) into subsets which are inverse images of elements of \(B\) and to each such subset the element of \(B\) which is its image is glued. This is somewhat similar to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Mapping_cylinder&quot;&gt;mapping cylinder&lt;/a&gt; construction in topology. Some similarities between graphs and cographs are immediately obvious. For graphs:\forall x\in A\; \exists! y\in B\; (x, y)\in f^*f(x) = \pi_2((\{x\}\times B) \cap f^*)f(U) = \{y \mid y = f(x) \wedge x\in U \} = \pi_2((U\times B)\cap f^*)where \(x\in A\) and \(U\subseteq A\). Similarly, for cographs:\forall x\in A\; \exists! y\in B\; [x] = [y]f(x) = [x] \cap Bf(U) = (\bigcup [U])\cap Bwhere \([x]\) is the equivalance set of \(x\) w.r.t. \(\pi_f\) and \([U] = \{[x] \mid x \in U\}\). For inverse images:f^{-1}(y) = \pi_1((A \times \{y\}) \cap f^*) = [y] \cap Af^{-1}(S) = \pi_1((A \times S) \cap f^*) = (\bigcup [S])\cap Awhere \(y\in B\) and \(S\subseteq B\).A graph can be expressed asf^* = \bigcup_{x \in A}(x, f(x))To write out a similar representation of a cograph, we have to recall some elementary facts about &lt;a href=&quot;https://en.wikipedia.org/wiki/Equivalence_relation&quot;&gt;equivalence relations&lt;/a&gt;.Given a set \(A\), let \(Eq(A) \subseteq Rel(A) = P(A \times A)\) be the set of equivalence relations on \(A\). For a relation \(\pi \subseteq A \times A\), we have\pi \in Eq(A) \;\; \equiv \;\; \pi^0 = \Delta \subseteq \pi \; \wedge \; \pi^n = \pi, n \in \mathbb{Z}, n \neq 0.To each \(\pi\) corresponds a surjection \(A \twoheadrightarrow A/\pi\). Assuming axiom of choice (in the form &amp;quot;&lt;a href=&quot;https://math.stackexchange.com/questions/1206013/every-epimorphism-in-sets-is-split-why-is-it-equivalent-to-axiom-of-choice&quot;&gt;all epics split&lt;/a&gt;&amp;quot;), an endomorphism \(A \twoheadrightarrow A/\pi \rightarrowtail A\) can be assigned (non-uniquely) to \(\pi\). It is easy to check, that this gives \(Eq(A) = End(A) / Aut(A)\), where \(End(A)\) and \(Aut(A)\) are the monoid and the group of set endomorphisms and automorphisms respectively, with composition as the operation (\(Aut(A)\) is not, in general, normal in \(End(A)\), so \(Eq(A)\) does not inherit any useful operation from this quotient set representation.). In addition to the monoid structure (w.r.t. composition) that \(Eq(A)\) inherits from \(Rel(A)\), it is also a &lt;a href=&quot;https://en.wikipedia.org/wiki/Lattice_(order)&quot;&gt;lattice&lt;/a&gt; with infimum and supremum given by\pi \wedge \rho = \pi \cap \rho\pi \vee \rho = \mathtt{tr}(\pi \cup \rho) = \bigcup_{n \in \mathbb{N}}(\pi \cup \rho)^nFor a subset \(X\subseteq A\) define an equivalence relation \(e(X) = \Delta_A \cup (X\times X)\), so thatx\overset{e(X)}{\sim} y \equiv x = y \vee \{x, y\} \subseteq X(Intuitively, \(e(X)\) collapses \(X\) to one point.) It is easy to check thatf_* = \bigvee_{x \in A}e(\{x, f(x)\})which is the desired dual of the graph representation above.</content>
        </item>

        <item>
            <title>Blindsight spot.</title>
            <id>commutativity</id>
            <link>https://cofault.com/commutativity.html#commutativity</link>
            <pubDate>2014/10/16</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/commutativity.html#commutativity">
                     I just realised that in any unital ring commutativity of addition follows from distributivity:\begin{array}{r@{\;}c@{\;}l@{\quad}} a + b &amp;amp;\;=\;&amp;amp; -a + a + a + b + b - b \\       &amp;amp;\;=\;&amp;amp; -a + a\cdot(1 + 1) + b\cdot(1 + 1) - b \\       &amp;amp;\;=\;&amp;amp; -a + (a + b)\cdot(1 + 1) - b \\       &amp;amp;\;=\;&amp;amp; -a + (a + b)\cdot 1 + (a + b)\cdot 1 - b \\       &amp;amp;\;=\;&amp;amp; -a + a + b + a + b - b \\       &amp;amp;\;=\;&amp;amp;  b + a  \end{array}The same holds for unital modules, algebras, vector spaces, &lt;i&gt;&amp;amp;c&lt;/i&gt;. Note that multiplication doesn&amp;#x27;t even need to be associative. It&amp;#x27;s amazing how such things can pass unnoticed.</content>
        </item>

        <item>
            <title>__VA_ARGS__ + C99 compound literals = safe variadic functions</title>
            <id>compound-literals</id>
            <link>https://cofault.com/compound-literals.html#compound-literals</link>
            <pubDate>2005/07/30</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/compound-literals.html#compound-literals">
                     &lt;span class=&quot;linktarget&quot; data-uid=&quot;3&quot;&gt;I&lt;/span&gt;t occurred to me that new C features added by C99 standard can be used to implement &lt;i&gt;safe variadic functions&lt;/i&gt; that is, something syntactically looking like normal call of function with variable number of arguments, but in effect calling function with all arguments packed into array, and with array size explicitly supplied:#define sizeof_array(arr) ((sizeof (arr))/(sizeof (arr)[0]))

#define FOO(a, ...) \
       foo((a), (char *[]){ __VA_ARGS__, 0 }, sizeof_array(((char *[]){ __VA_ARGS__ })))

int foo(int x, char **str, int n) {
        printf(&amp;quot;%i %i\n&amp;quot;, x, n);
                while (n--)
        printf(&amp;quot;%s\n&amp;quot;, *(str++));
        printf(&amp;quot;last: %s\n&amp;quot;, *str);
}

int main(int argc, char **argv)
{
        FOO(1, &amp;quot;a&amp;quot;, &amp;quot;boo&amp;quot;, &amp;quot;cooo&amp;quot;, &amp;quot;dd&amp;quot;, argv[0]);
}this outputs1 5
a
boo
cooo
dd
./a.out
last: (null)Expect me to use this shortly somewhere.</content>
        </item>

        <item>
            <title>Concurrency Control and Recovery in Database Systems</title>
            <id>concurrency-and-recovery</id>
            <link>https://cofault.com/concurrency-and-recovery.html#concurrency-and-recovery</link>
            <pubDate>2005/07/25</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/concurrency-and-recovery.html#concurrency-and-recovery">
                     &lt;a href=&quot;http://research.microsoft.com/pubs/ccontrol/&quot;&gt;Concurrency Control and Recovery in Database Systems&lt;/a&gt; by Philip A. Bernstein, Vassos Hadzilacos, and Nathan Goodman.Delayed commit as an alternative to keeping &amp;quot;commit-time&amp;quot; locks: when transaction T1 is accessing a resource modified by active transaction T2, it just proceeds hoping that T2 will commit. If T1 tries to commit while T2 is still active, its commit is delayed until T2 commits or aborts. If T2 aborts, T1 has to abort too (and can be restarted). One can imagine &amp;quot;abort-rate&amp;quot; tracked for each resource, and delayed commits are used only if it is low enough.Pragmatically, this means that read locks can be released when the         transaction terminates (&lt;i&gt;i.e.&lt;/i&gt;, when the scheduler receives the         transaction&amp;#x27;s Commit or Abort), but write locks must be held until         after the transaction commits or aborts (&lt;i&gt;i.e.&lt;/i&gt;, after the DM processes         the transaction&amp;#x27;s Commit or Abort).This strategy (&amp;quot;Static 2PL scheduler&amp;quot;) generates strict histories. How it generalizes to other types of locks?Interesting section on thrashing:pure restart policy (abort transaction when it tries to acquire already held    lock) works well when data contention is high.a measure of thrashing:W = k \cdot k \cdot N / D,where\(N\) - multiprogramming level,\(k\) - number of locks required by transaction,\(D\) - number of lockable entities.thrashing starts when \(W &amp;gt;= 1.5\).Can be applied to resource (memory) trashing too.</content>
        </item>

        <item>
            <title>Confessions of Microsoft developer</title>
            <id>confessions-microsoft</id>
            <link>https://cofault.com/confessions-microsoft.html#confessions-microsoft</link>
            <pubDate>2005/08/02</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/confessions-microsoft.html#confessions-microsoft">
                     &lt;a href=&quot;http://blogs.msdn.com/larryosterman/archive/2004/08/12/213681.aspx&quot;&gt;As a simple example, when Windows started up&lt;/a&gt;, it increased the size of msdos&amp;#x27;s  internal file table (the &lt;code class=&quot;inline&quot;&gt;SFT&lt;/code&gt;, that&amp;#x27;s the table that was created by the  &lt;code class=&quot;inline&quot;&gt;FILES=&lt;/code&gt; line in &lt;code class=&quot;inline&quot;&gt;config.sys&lt;/code&gt;).  It did that to allow more than 20 files to be  opened on the windows system (a highly desirable goal for a multi-tasking  operating system).  But it did that by using an undocumented API call, which  returned a pointer to a set of “interesting” pointers in msdos. It then indexed  a known offset relative to that pointer, and replaced the value of the master  &lt;code class=&quot;inline&quot;&gt;SFT&lt;/code&gt; table with its own version of the &lt;code class=&quot;inline&quot;&gt;SFT&lt;/code&gt;.  When I was working on msdos  4.0, we needed to support Windows.  Well, it was relatively easy to guarantee  that our SFT was at the location that Windows was expecting.  But the problem  was that the msdos 4.0 &lt;code class=&quot;inline&quot;&gt;SFT&lt;/code&gt; was 2 bytes larger than the msdos 3.1 &lt;code class=&quot;inline&quot;&gt;SFT&lt;/code&gt;.  In  order to get Windows to work, I had to change the DOS loader to detect when  win.com was being loaded, and if it was being loaded, I looked at the code at  an offset relative to the base code segment, and if it was a &lt;code class=&quot;inline&quot;&gt;MOV&lt;/code&gt; instruction,  and the amount being moved was the old size of the &lt;code class=&quot;inline&quot;&gt;SFT&lt;/code&gt;, I patched the  instruction in memory to reflect the new size of the &lt;code class=&quot;inline&quot;&gt;SFT&lt;/code&gt;!  Yup, msdos 4.0  patched the running windows binary to make sure Windows would still continue to  work.And these are the people who &lt;i&gt;design&lt;/i&gt; and implement most widely used software in the world. Which is a scary place indeed.</content>
        </item>

        <item>
            <title>It could be done</title>
            <id>could-be-done</id>
            <link>https://cofault.com/could-be-done.html#could-be-done</link>
            <pubDate>2009/03/25</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/could-be-done.html#could-be-done">
                     &amp;quot;The late &lt;a href=&quot;http://www.multicians.org/andre.html&quot;&gt;André&lt;/a&gt; Bensoussan worked with me on the Multics .... We were working  on a major change to the file system ...André took on the job of design, implementation, and test of the VTOC  manager. He started by sitting at his desk and drawing a lot of diagrams. I was  the project coordinator, so I used to drop in on him and ask how things were  going. &amp;quot;Still designing,&amp;quot; he&amp;#x27;d say. He wanted the diagrams to look beautiful  and symmetrical as well as capturing all the state information. ... I was  glad when he finally began writing code. He wrote in pencil, at his desk,  instead of using a terminal. ...Finally André took his neat final pencil copy to a terminal and typed the whole  program in. His first compilation attempt failed; he corrected three typos,  tried again, and the code compiled. We bound it into the system and tried it  out, and it worked the first time.In fact, the VTOC manager worked perfectly from then on. ...How did André do this, with no tool but a pencil?Those people were programming operating system kernel that supported kernel level multi-threading and SMP (in 60s!), had most features UNIX kernels have now and some that no later operating system has, like transparent HSM. All under hardware constraints that would make modern washing machine to look like a super-computer. Of course they were thinking, &lt;i&gt;then&lt;/i&gt; typing.</content>
        </item>

        <item>
            <title>Cue a key</title>
            <id>cue</id>
            <link>https://cofault.com/cue.html#cue</link>
            <pubDate>2011/12/24</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/cue.html#cue">
                     There is a typical problem with &lt;a href=&quot;http://en.wikipedia.org/wiki/Emacs&quot;&gt;Emacs&lt;/a&gt; experienced by people frequently switching between different keyboard mappings, for example, to work with non ASCII languages: fundamental Emacs keyboard shortcuts (and one has to invoke them &lt;i&gt;a lot&lt;/i&gt; to use Emacs efficiently) all use ASCII keys. For example, when I want to save my work, while entering some Russian text, I have to do something like &lt;code class=&quot;inline&quot;&gt;Alt-Space&lt;/code&gt; (switch to the US keyboard layout) &lt;a href=&quot;http://www.gnu.org/software/emacs/manual/html_node/emacs/Save-Commands.html#index-C_002dx-s-845&quot;&gt;&lt;code class=&quot;inline&quot;&gt;Control-x-s&lt;/code&gt;&lt;/a&gt; (a Emacs shortcut to save buffers) &lt;code class=&quot;inline&quot;&gt;Alt-Space&lt;/code&gt; (shift back to the Cyrillic keyboard layout). Switching out and back to a keyboard layout only to tap a short key sequence is really annoying.Two solutions are usually proposed:Duplicate standard key sequences in other keyboard layouts. For example,(global-set-key [(control ?ч ?ы)] &amp;#x27;save-some-buffers)expression in &lt;code class=&quot;inline&quot;&gt;.emacs&lt;/code&gt; binds &lt;code class=&quot;inline&quot;&gt;Control-ч-ы&lt;/code&gt; to the same command as &lt;code class=&quot;inline&quot;&gt;Control-x-s&lt;/code&gt; is usually bound. This eliminates the need to switch layout, because &lt;code class=&quot;inline&quot;&gt;ч&lt;/code&gt;-`x` (and &lt;code class=&quot;inline&quot;&gt;ы&lt;/code&gt;-`s`) symbols are located on the same key (in &lt;a href=&quot;http://en.wikipedia.org/wiki/QWERTY&quot;&gt;QWERTY&lt;/a&gt; and &lt;a href=&quot;http://en.wikipedia.org/wiki/JCUKEN&quot;&gt;JCUKEN&lt;/a&gt; layouts respectively).Another solution employs the fact that Emacs is &lt;a href=&quot;https://www.google.com/search?q=Emacs+is+a+great+operating+system.+If+only+it+had+a+decent+text+editor&quot;&gt;a complete operating system&lt;/a&gt;  and, therefore, has its own keyboard layout switching mechanism (bound to  &lt;code class=&quot;inline&quot;&gt;Control-\&lt;/code&gt; by default). When this mechanism is used, Emacs re-interprets  normals keys according to its internal layout, so that typing &lt;code class=&quot;inline&quot;&gt;s&lt;/code&gt; inserts &lt;code class=&quot;inline&quot;&gt;ы&lt;/code&gt;  when in internal Russian mode, while all command sequences continue to work  independently of layout. The mere idea of having &lt;i&gt;two&lt;/i&gt; independent layout  switching mechanisms and two associated keyboard state indicators is clearly  ugly beyond words (except for people who use Emacs as their &lt;code class=&quot;inline&quot;&gt;/sbin/init&lt;/code&gt;).Fortunately, there is another way:; Map Modifier-CyrillicLetter to the underlying Modifier-LatinLetter, so that
; control sequences can be used when keyboard mapping is changed outside of
; Emacs.
;
; For this to work correctly, .emacs must be encoded in the default coding
; system.
;
(mapcar* 
 (lambda (r e) ; R and E are matching Russian and English keysyms
   ; iterate over modifiers
   (mapc (lambda (mod)
    (define-key input-decode-map 
      (vector (list mod r)) (vector (list mod e))))
  &amp;#x27;(control meta super hyper))
   ; finally, if Russian key maps nowhere, remap it to the English key without
   ; any modifiers
   (define-key local-function-key-map (vector r) (vector e)))
   &amp;quot;йцукенгшщзхъфывапролджэячсмитьбю&amp;quot;
   &amp;quot;qwertyuiop[]asdfghjkl;&amp;#x27;zxcvbnm,.&amp;quot;)(Inspired by a cryptic remark about &amp;quot;Translation Keymaps&amp;quot; in &lt;a href=&quot;http://vorotylo.livejournal.com/&quot;&gt;vvv&lt;/a&gt;&amp;#x27;s &lt;a href=&quot;https://github.com/vvv/dotfiles/blob/master/.emacs&quot;&gt;.emacs&lt;/a&gt;.)</content>
        </item>

        <item>
            <title>Translations.</title>
            <id>donne</id>
            <link>https://cofault.com/donne.html#donne</link>
            <pubDate>2017/09/22</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/donne.html#donne">
                     Licence my roving hands, and let them go,Before, behind, between, above, below.O my America! my new-found-land-- J. Donne, 1633.Блуждающим рукам моим дай разрешенье,Пусти вперед, назад, промеж, и вверх, и вниз,О дивный новый мир, Америка моя!Variant reading &lt;i&gt;reeing&lt;/i&gt; instead of &lt;i&gt;roving&lt;/i&gt; is even better. I hope that &amp;quot;О дивный новый мир&amp;quot; (O brave new world) is not entirely anachronistic.</content>
        </item>

        <item>
            <title>threads, contexts and doors.</title>
            <id>doors</id>
            <link>https://cofault.com/doors.html#doors</link>
            <pubDate>2013/12/16</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/doors.html#doors">
                     &lt;a href=&quot;https://plus.google.com/102766894085961969420/posts&quot;&gt;Paul Turner&lt;/a&gt; gave a &lt;a href=&quot;http://www.youtube.com/watch?v=KXuZi9aeGTw&quot;&gt;talk&lt;/a&gt; about new threading interface, designed by Google, at this year &lt;a href=&quot;http://www.linuxplumbersconf.org/2013/&quot;&gt;Linux Plumbers Conference&lt;/a&gt;:The idea is, very roughly, to implement the &lt;a href=&quot;http://pubs.opengroup.org/onlinepubs/7908799/xsh/ucontext.h.html&quot;&gt;ucontext&lt;/a&gt; interface with kernel support. This gives the benefits of kernel threads (&lt;i&gt;e.g.&lt;/i&gt;, SMP support), while retaining fast context switches of user threads. &lt;code class=&quot;inline&quot;&gt;switchto_switch(tid)&lt;/code&gt; call hands off control to the specified thread without going through the kernel scheduler. This is like &lt;code class=&quot;inline&quot;&gt;swapcontext(3)&lt;/code&gt;, except that kernel stack pointer is switched too. Of course, there is still an overhead of the system call and return, but it is not as important as it used to be: the cost of normal context switch is dominated by the scheduler invocation (with all the associated locking), plus, things like TLB flushes drive the difference between user and kernel context switching further down.I did something similar (but much more primitive) in 2001. The difference was that in that old implementation, one could switch context with a thread running in a different address space, so it was possible to make a &amp;quot;continuation call&amp;quot; to another process. This was done to implement &lt;a href=&quot;http://en.wikipedia.org/wiki/Doors_(computing)&quot;&gt;Solaris doors&lt;/a&gt; RPC mechanism on Linux. Because this is an RPC mechanism, arguments have to be passed, so each context switch also performed a little dance to copy arguments between address spaces.</content>
        </item>

        <item>
            <title>Euclid continuity</title>
            <id>euclid</id>
            <link>https://cofault.com/euclid.html#euclid</link>
            <pubDate>2024/05/07</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/euclid.html#euclid">
                     Let&amp;#x27;s talk about one of the simplest, if not trivial, subjects in the oldest and best-established branch of mathematics: rectangle area in elementary Euclid geometry. The story contains two twists and an anecdote.We all know that the area of a rectangle or a parallelogram is a product of its base and height, and the area of a triangle is half of that (areas of a parallelogram, a triangle and a rectangle can all be reduced to each other by a device invented by Euclid), but Euclid would not say that: the idea that measures such as lengths, areas or volumes can be multiplied is alien to him, as it still is to Galileo. There is a huge body of literature on the evolution that culminated with our modern notion of number, unifying disparate incompatible numbers and measures of the past mathematics, enough to say that before Newton-Leibniz time, ratios and fractions were not the same.Euclid instead says (Book VI, prop. I, hereinafter quotes from the Elements are given as &amp;lt;Greek | English | Russian&amp;gt;):&amp;lt;&lt;a href=&quot;https://www.perseus.tufts.edu/hopper/text?doc=Perseus%3Atext%3A1999.01.0085%3Abook%3D6%3Atype%3DProp%3Anumber%3D1&quot;&gt;τὰ τρίγωνα καὶ τὰ παραλληλόγραμμα, τὰ ὑπὸ τὸ αὐτὸ ὕψος ὄντα πρὸς ἄλληλά ἐστιν ὡς αἱ βάσεις&lt;/a&gt;. | &lt;a href=&quot;http://aleph0.clarku.edu/~djoyce/elements/bookVI/propVI1.html&quot;&gt;Triangles and parallelograms, which are under the same height are to one another as their bases&lt;/a&gt;. | &lt;a href=&quot;https://archive.org/details/1-6_euclid_elements/page/174/mode/1up&quot;&gt;Треугольники и параллелограммы под одной и той же высотой, [относятся] друг к другу как основания&lt;/a&gt;.&amp;gt;Given rectangles \(ABCD\) and \(AEFD\) with the same height \(AD\), we want to prove that the ratio of their areas is the same as of their bases: \(\Delta(ABCD)/\Delta(AEFD) = AB/AE\).First, consider a case where the bases are commensurable, that is, as we would say \(AB/AE = n/m\) for some integers \(n\) and \(m\), or as Euclid would say, there is a length \(AX\), such that \(AB = n \cdot AX\) (that is, the interval \(AB\) is equal to \(n\) times extended interval \(AX\)) and \(AE = m \cdot AX\). Then, \(ABCD\) can be divided into \(n\) equal rectangles \(AXYD\) with the height \(AD\) the base \(AX\) and the area \(\Delta_0\), and \(AEFD\) can be divided into \(m\) of them.Then,\begin{array}{lclclcl}
\Delta(ABCD) &amp;amp; = &amp;amp; \Delta(AXYD) &amp;amp; + &amp;amp; \Delta(XX&amp;#x27;Y&amp;#x27;Y) &amp;amp; + &amp;amp; \ldots\\
             &amp;amp; = &amp;amp; n \cdot \Delta_0, &amp;amp; &amp;amp; &amp;amp; &amp;amp;
\end{array}and\begin{array}{lclclcl}
\Delta(AEFD) &amp;amp; = &amp;amp; \Delta(AXYD) &amp;amp; + &amp;amp; \Delta(XX&amp;#x27;Y&amp;#x27;Y) &amp;amp; + &amp;amp; \ldots \\ 
             &amp;amp; = &amp;amp; m \cdot \Delta_0
\end{array}so that \(\Delta(ABCD)/\Delta(AEFD) = n/m = AB/AE\), as required.Starting from the early twentieth century, the rigorous proof of the remaining incommensurable case in a school-level exposition typically involves some form of a limit and is based on an implicit or explicit continuity axiom, usually equivalent to &lt;a href=&quot;https://en.wikipedia.org/wiki/Cavalieri%27s_principle&quot;&gt;Cavaliery principle&lt;/a&gt;.There is, however, a completely elementary, short and elegant proof, that requires no additional assumptions. This proof is used by &lt;a href=&quot;https://en.wikipedia.org/wiki/Adrien-Marie_Legendre&quot;&gt;Legendre&lt;/a&gt; (I don&amp;#x27;t know who is the original author) in &lt;i&gt;his&lt;/i&gt; Elements, &lt;a href=&quot;https://maa.org/press/periodicals/convergence/mathematical-treasure-adrien-marie-legendre-s-l-ments-de-g-om-trie&quot;&gt;&lt;i&gt;Éléments de géométrie&lt;/i&gt;&lt;/a&gt;. Depending on the edition, it is Proposition III in either Book III (&lt;a href=&quot;https://www.survivorlibrary.com/library/elements_of_geometry_1875.pdf&quot;&gt;p. 100&lt;/a&gt;) or Book IV (&lt;a href=&quot;https://upload.wikimedia.org/wikipedia/commons/6/60/Elements_of_geometry_and_trigonometry_from_the_works_of_A.M._Legendre_-_revised_and_adapted_to_the_course_of_mathematical_instruction_in_the_United_States_%28IA_elementsgeometr13legegoog%29.pdf&quot;&gt;page 90&lt;/a&gt;, some nineteenth-century editions, especially with &amp;quot;additions and modifications by M. A. Blanchet&amp;quot;, are butchered beyond recognition, be careful). The proof goes like this:For incommensurable \(AB\) and \(AE\) consider the ratio \(\Delta(ABCD)/\Delta(AEFD)\). If \(\Delta(ABCD)/\Delta(AEFD) = AB/AE\) we are done. If \(\Delta(ABCD)/\Delta(AEFD)\) is not equal to \(AB/AE\), it is instead equal to \(AB/AO\) and either \(AE &amp;lt; AO\) or \(AE &amp;gt; AO\).  Consider the first case (the other one is similar).The points at the base are in order \(A\), then \(B\), then \(E\), then \(O\).Divide \(AB\) into \(n\) equal intervals, each shorter that \(EO\). This requires what we now call the &lt;a href=&quot;https://encyclopediaofmath.org/wiki/Archimedean_axiom&quot;&gt;Archimedes-Eudoxus axiom&lt;/a&gt; and which is implied by Definition IV of Book V:&amp;lt;&lt;a href=&quot;https://www.perseus.tufts.edu/hopper/text?doc=Perseus%3Atext%3A1999.01.0085%3Abook%3D5%3Atype%3DDef%3Anumber%3D4&quot;&gt;λόγον ἔχειν πρὸς ἄλληλα μεγέθη λέγεται, ἃ δύναται πολλαπλασιαζόμενα ἀλλήλων ὑπερέχειν&lt;/a&gt;. | &lt;a href=&quot;http://aleph0.clarku.edu/~djoyce/elements/bookV/defV4.html&quot;&gt;Magnitudes are said to have a ratio to one another which can, when multiplied, exceed one another&lt;/a&gt;. | &lt;a href=&quot;https://archive.org/details/1-6_euclid_elements/page/142/mode/1up&quot;&gt;Величины имеют отношение между собой, если они взятые кратно могут превзойти друг друга&lt;/a&gt;.&amp;gt;Then continue dividing \(BE\), until we get to a point \(I\) outside of \(BE\), but within \(EO\) (because the interval is shorter than \(EO\)). The points are now in order \(A\), then \(B\), then \(E\), then \(I\), then \(O\).\(AB\) and \(AI\) are commensurable, so \(\Delta(ABCD)/\Delta(AIKD) = AB/AI\). Also, \(\Delta(ABCD)/\Delta(AEFD) = AB/AO\), so \(\Delta(AIKD)/\Delta(AEFD) = AI/AO\). By construction \(AI &amp;lt; AO\), hence \(\Delta(AIKD) &amp;lt; \Delta(AEFD)\), but \(AEFD\) is a proper part of \(AIKD\), so \(\Delta(AEFD) &amp;lt; \Delta(AIKD)\). Contradiction.Step back and look at the structure of these two proofs from the modern perspective. Fix the height and let \(\Delta(X)\) be the area of the rectangle with the base of length \(X\). By an assumption that we would call &amp;quot;additivity of measure&amp;quot; \(\Delta(X+Y) = \Delta(X) + \Delta(Y)\), that is, \(\Delta\) is an additive function. A general and easy-to-establish fact (mentioned with remarkable persistency on this blog [&lt;a href=&quot;iso.html#iso-start&quot;&gt;Unexpected isomorphism&lt;/a&gt;], [&lt;a href=&quot;hunt.1.html#hunt.1-start&quot;&gt;The Hunt for Addi(c)tive Monster&lt;/a&gt;]) is that any additive function is linear on rationals, that is, \(\Delta(n/m \cdot X) = n/m \cdot \Delta(X)\). This corresponds to the &amp;quot;commensurable&amp;quot; part of the proofs. To complete a proof we need linearity: \(\Delta(X) = X \cdot H\), where \(H = \Delta(1)\). But additive functions are &lt;i&gt;not&lt;/i&gt; necessarily linear. To obtain linearity, an additional condition is needed. The traditional proof uses continuity: a continuous (at least at one point) additive function is necessarily linear.Legendre&amp;#x27;s proof uses monotonicity: a monotonic additive function is always linear. This is clever, because monotonicity is not an additional assumption: it follows from the already assumed positivity of measure: If \(Y &amp;gt; X\), then \(\Delta(Y) = \Delta(X + (Y - X)) = \Delta(X) + \Delta(Y - X) &amp;gt; \Delta(X)\), as \(\Delta(Y - X) &amp;gt; 0\).How does the original Euclid&amp;#x27;s proof look like? (He proves the triangle version, which is similar to rectangles.)Wait... It is unbelievably short, especially given that the Elements use no notation and spell everything in words &lt;i&gt;and&lt;/i&gt; it covers both triangles and parallelograms. It definitely has no separate &amp;quot;commensurable&amp;quot; and &amp;quot;imcommensurable&amp;quot; parts. How is this possible?The trick is in the &lt;i&gt;definition&lt;/i&gt; of equal ratios, Def. V of Book V:&amp;lt;&lt;a href=&quot;https://www.perseus.tufts.edu/hopper/text?doc=Perseus%3Atext%3A1999.01.0085%3Abook%3D5%3Atype%3DDef%3Anumber%3D5&quot;&gt;ἐν τῷ αὐτῷ λόγῳ μεγέθη λέγεται εἶναι πρῶτον πρὸς δεύτερον καὶ τρίτον πρὸς τέταρτον, ὅταν τὰ τοῦ πρώτου καὶ τρίτου ἰσάκις πολλαπλάσια τῶν τοῦ δευτέρου καὶ τετάρτου ἰσάκις πολλαπλασίων καθ᾽ ὁποιονοῦν πολλαπλασιασμὸν ἑκάτερον ἑκατέρου ἢ ἅμα ὑπερέχῃ ἢ ἅμα ἴσα ᾖ ἢ ἅμα ἐλλείπῃ ληφθέντα κατάλληλα&lt;/a&gt;.| &lt;a href=&quot;http://aleph0.clarku.edu/~djoyce/elements/bookV/defV5.html&quot;&gt;Magnitudes are said to be in the same ratio, the first to the second and the third to the fourth, when, if any equimultiples whatever are taken of the first and third, and any equimultiples whatever of the second and fourth, the former equimultiples alike exceed, are alike equal to, or alike fall short of, the latter equimultiples respectively taken in corresponding order&lt;/a&gt;. | &lt;a href=&quot;https://archive.org/details/1-6_euclid_elements/page/142/mode/1up&quot;&gt;Говорят, что величины находятся в том же отношении: первая ко второй и третья к четвёртой, если равнократные первой и третьей одновременно больше, или одновременно равны, или одновременно меньше равнократных второй и четвёртой каждая каждой при какой бы то ни было кратности, если взять их в соответственном порядке&lt;/a&gt;&amp;gt;In modern notation this means that\Delta_1 / \Delta_2 = b_1 / b_2 \equiv (\forall n\in\mathbb{N}) (\forall m\in\mathbb{N}) (n\cdot\Delta_1 \gtreqqless m\cdot\Delta_2 = n\cdot b_1 \gtreqqless m\cdot b_2),where \(\gtreqqless\) is &amp;quot;FORTRAN &lt;a href=&quot;https://en.wikipedia.org/wiki/Three-way_comparison&quot;&gt;3-way comparison&lt;/a&gt; operator&amp;quot; (aka C++ &lt;a href=&quot;https://en.wikipedia.org/wiki/Three-way_comparison#Spaceship_operator&quot;&gt;spaceship operator&lt;/a&gt;):X \gtreqqless Y =  
\begin{cases}
    -1, &amp;amp; X &amp;lt; Y\\
     0, &amp;amp; X = Y\\
    +1, &amp;amp; X &amp;gt; Y
\end{cases}This looks like a rather artificial definition of ratio equality, but with it the proof of Proposition I and many other proofs in Books V and VI, become straightforward or even forced.The approach of selecting the definitions to streamline the proofs is characteristic of abstract twentieth-century mathematics and it is amazing to see it in full force in the earliest mathematical text we have.I&amp;#x27;ll conclude with the promised anecdote (unfortunately, I do not remember the source). An acquaintance of Newton having met him in the Cambridge library and found, on inquiry, that Newton is reading the Elements, remarked something to the effect of &amp;quot;But Sir Isaac, haven&amp;#x27;t your methods superseded and obsoleted Euclid?&amp;quot;. This is one of the two recorded cases when Newton laughed.</content>
        </item>

        <item>
            <title>a trivial exercise.</title>
            <id>exercise</id>
            <link>https://cofault.com/exercise.html#exercise</link>
            <pubDate>2009/08/21</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/exercise.html#exercise">
                     &lt;span class=&quot;linktarget&quot; data-uid=&quot;5&quot;&gt;Let&amp;#x27;s&lt;/span&gt; find a sum\sum_{n=1}^\infty {1\over{n(n+2)}}There is a well-know standard way, that I managed to recall eventually. Given that{1 \over n(n+2)} = {1 \over 2}\cdot \left({1\over n} - {1\over n+2}\right)the sum can be re-written as\sum_{n=1}^\infty {1\over{n(n+2)}} = \sum_{n=1}^\infty {1 \over 2}\left({1\over n} - {1\over n+2}\right) = {1\over 2}\left({1\over 1} - {1\over 3} + {1\over 2} - {1\over 4} + {1\over 3} - {1\over 5} + {1\over 4} - {1\over 6} \cdots\right)with almost all terms canceling each other, leaving\sum_{n=1}^\infty {1\over{n(n+2)}} = {1\over 2}\left(1 + {1\over 2}\right) = {3\over 4}While this is easy to check, very little help is given on understanding how to arrive to the solution in the first place. Indeed, the first (and crucial) step is a rabbit pulled &lt;i&gt;sans motif&lt;/i&gt; out of a conjurer hat. The solution, fortunately, can be found in a more systematic fashion, by a relatively generic method. Enter &lt;a href=&quot;http://en.wikipedia.org/wiki/Generating_function&quot;&gt;generating functions&lt;/a&gt;.First, introduce a functionf(t) = \sum_{n=1}^\infty {t^{n + 1}\over n}The series on the right converge absolutely when \(|t| &amp;lt; 1\), so one can defineg(t) = \int f(t) dt = \int \sum_{n=1}^\infty {t^{n + 1}\over n} = \sum_{n=1}^\infty \int {t^{n + 1}\over n} = \sum_{n=1}^\infty {t^{n + 2}\over {n(n+2)}} + Cwith the sum in question being\sum_{n=1}^\infty {1\over{n(n+2)}} = g(1) - C = g(1) - g(0)Definition of the \(g\) function follows immediately from the form of the original sum, and there is a limited set of operations (integration, differentiation, &lt;i&gt;etc&lt;/i&gt;.) applicable to \(g\) to produce \(f\).The rest is more or less automatic. Note that- ln(1 - t) = t + {t^2\over 2} + {t^3\over 3} + \cdotsso thatf(t) = t^2 + {t^3\over 2} + {t^4\over 3} + \cdots = - t \cdot ln(1-t)thereforeg(t) = - \int t \cdot ln(1-t) dt = \cdots = {1\over 4} (1 - t)^2 - {1\over 2} (1 - t)^2 ln(1 - t) + (1 - t) ln(1 - t) + t + Cwhere the integral is standard. Now,g(1) - g(0) = 1 - {1\over 4} = {3\over 4}&lt;i&gt;Voilà&lt;/i&gt;!And just to check that things are not too far askew, a sub-exercise in &lt;a href=&quot;http://en.wikipedia.org/wiki/Tacit_programming&quot;&gt;pointless programming&lt;/a&gt;:scala&amp;gt; (1 to 10000).map(x =&amp;gt; 1.0/(x*(x+2))).reduceLeft(_+_)
res0: Double = 0.749900014997506PS: of course this post is an exercise in &lt;a href=&quot;http://spiny.at.org/%7Ecola/tex2img&quot;&gt;tex2img&lt;/a&gt; usage.PPS: Ed. 2022: tex2img is gone, switch to mathjax.</content>
        </item>

        <item>
            <title>ext3: magic, more magic.</title>
            <id>ext3-magic</id>
            <link>https://cofault.com/ext3-magic.html#ext3-magic</link>
            <pubDate>2006/02/01</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/ext3-magic.html#ext3-magic">
                     ext3 htree code in Linux kernel implements peculiar version of &lt;a href=&quot;http://www.bluerwhite.org/btree/&quot;&gt;balanced tree&lt;/a&gt; used to efficiently handle large directories.htree directory consists of block sized nodes. Some of them (leaf nodes) contain directory entries in the same format as ext2. Other nodes contain &lt;i&gt;index&lt;/i&gt;: they are filled with hashes and pointers to other nodes.When new file is created in a directory, a directory entry is inserted in one of leaf nodes. When leaf node has not enough space for new entry, new node is appended to the tree, and part of directory entries is moved there. This process is known as a &lt;i&gt;split&lt;/i&gt;. Pointer to new node is then inserted into some index node, and new node can overflow at this point, causing another split and so on.If splits occur whole way up to the root of the tree, new root has to be added (tree grows).It&amp;#x27;s obvious that in the worst case (extremely rare in practice) insertion of a new entry may require a new block on each tree level, plus new root, right? Now, looking at the &lt;a href=&quot;http://lxr.linux.no/ident?i=ext3_dx_add_entry&quot;&gt;&lt;code class=&quot;inline&quot;&gt;ext3_dx_add_entry&lt;/a&gt;()&lt;/code&gt; function we see something strange:                 } else {
                         dxtrace(printk(&amp;quot;Creating second level index...\n&amp;quot;));
                         memcpy((char *) entries2, (char *) entries,
                                icount * sizeof(struct dx_entry));
                         dx_set_limit(entries2, dx_node_limit(dir));

                         /* Set up root */
                         dx_set_count(entries, 1);
                         dx_set_block(entries + 0, newblock);
                         ((struct dx_root *) frames[0].bh-&amp;gt;b_data)-&amp;gt;info.indirect_levels = 1;

                         /* Add new access path frame */
                         frame = frames + 1;
                         frame-&amp;gt;at = at = at - entries + entries2;
                         frame-&amp;gt;entries = entries = entries2;
                         frame-&amp;gt;bh = bh2;
                         err = ext3_journal_get_write_access(handle,
                                                              frame-&amp;gt;bh);
                         if (err)
                                 goto journal_error;
                 }At this moment &lt;code class=&quot;inline&quot;&gt;entries&lt;/code&gt; points to the already existing full node and &lt;code class=&quot;inline&quot;&gt;entries2&lt;/code&gt; to the newly created one. As one can see, contents of &lt;code class=&quot;inline&quot;&gt;entries&lt;/code&gt; is shifted into &lt;code class=&quot;inline&quot;&gt;entries2&lt;/code&gt;, and &lt;code class=&quot;inline&quot;&gt;entries&lt;/code&gt; is declared to be new root of the tree. So now tree has a root node with a single pointer to the index node that... still has not enough free space (remember &lt;code class=&quot;inline&quot;&gt;entries2&lt;/code&gt; got everything &lt;code class=&quot;inline&quot;&gt;entries&lt;/code&gt; had). Omitted code that follows proceeds with splitting leaf node, assuming that its parent has enough space to insert a pointer to the new leaf. So how this is supposed to work? Or, does this work at all? That&amp;#x27;s tricky part and the curious reader is invited to try to infer what&amp;#x27;s going on without looking at the rest of this post.The answer is simple: by ext3 htree design, capacity of the root node is smaller than that of non-root index one. This is a byproduct of binary compatibility between htree and old ext2 format: root node is always the first block in the directory and it always contains dot and dotdot directory entries. As a result, when contents of old root is copied into new node, that node ends up having enough space for two additional entries.This is obviously one of the worst hacks &lt;i&gt;and&lt;/i&gt; least documented at that. Shame.Thanks to Alex Tomas for clearing this mystery for me. As he says: &amp;quot;&lt;i&gt;Htree code is simple to understand: it only takes to tune yourself to Daniel Phillips brain-waves frequency&lt;/i&gt;&amp;quot;.</content>
        </item>

        <item>
            <title>Review of Feminism, Interrupted: Disrupting Power by L. Olufemi</title>
            <id>feminism</id>
            <link>https://cofault.com/feminism.html#feminism</link>
            <pubDate>2025/03/08</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/feminism.html#feminism">
                     &lt;span class=&quot;align-right&quot;&gt; &amp;quot;&lt;i&gt;feminism means freedom, it means the right to be ... incoherent&lt;/i&gt;&amp;quot;, p. 71&lt;/span&gt;Let me state outright, that I won&amp;#x27;t be able to provide a critique of the cogent rational argument that forms the core of Ms. Olufemi&amp;#x27;s book, for the simple fact that even the most diligent search will not find an argument of that sort there.I am going to prove with ample internal and external evidence, that the book does not present an articulated argument for anything. That it is little more than a haphazard collection of claims, that are not only not supported by evidence, but do not even form a consistent sequence.All references are to the &lt;a href=&quot;https://www.amazon.com/Feminism-Interrupted-Disrupting-Power-Outspoken/dp/0745340067&quot;&gt;paperback 2020 edition&lt;/a&gt;.PreambleThe most striking feature of the book before us is that it is difficult to find a way to approach it. A sociological study and a political pamphlet still have something in common: they have a goal. The goal is to convince the reader. The methods of convincing can be quite different, involve data and logic and authority. But in any case, &lt;i&gt;something&lt;/i&gt; is needed. As you start reading &lt;i&gt;Feminism Interrupted&lt;/i&gt; you are bound to find that this something is hidden very well. Indeed, as I just counted, one of the first sections &lt;i&gt;Who&amp;#x27;s the boss&lt;/i&gt; has as many claims as it has sentences (some claims are in the form of rhetorical questions). There, as you see, was no space left for any form of supporting argumentation. Because it is not immediately obvious how to analyse a text with such a (non-)structure, let me start the same way as Ms. Olufemi starts in Introduction and just read along, jotting down notes and impressions, gradually finding our way through the book, forming a conception of the whole.The following is a numbered list of places in the book that made me sigh or laugh. They are classified as: E (not supported by Evidence), C (Contradiction with itself or an earlier claim) and I (Incoherence). These classes are necessarily arbitrary and overlapping. I will also provide a commentary about some common themes and undercurrents running through the book.One may object that this is too pedantic a way to review a book. Well, maybe it is, but this is the only way I know to lay ground for justifiable conclusions, with which my review will be concluded.Notes on the text1.E, p. 4: &amp;quot;&lt;i&gt;neo-liberalism refers to the imposition of cultural and economic policies and practices by NGOs and governments in the last three to four decades that have resulted in the extraction and redistribution of public resources from the working class upwards&lt;/i&gt;&amp;quot; — this of course has very little to do with the definition of Neo-liberalism. Trivial as it is, this sentence introduces one of the most interesting and unexpected themes that will resurface again and again: Ms. Olufemi, a self-anointed radical feminist from the extreme left of the political spectrum, in many respects is virtually indistinguishable from her brethren on the opposite side. Insidious &amp;quot;&lt;i&gt;NGOs&lt;/i&gt;&amp;quot; machinating together with governments against common people are the staple imagery of the far-right.2.C, p. 5: &amp;quot;&lt;i&gt;... that feminism has a purpose beyond just highlighting the ways women are &amp;#x27;discriminated&amp;#x27; against... It taught me that feminism&amp;#x27;s task is to remedy the consequences of gendered oppression through organising... For me, &amp;#x27;justice work&amp;#x27; involves reimagining the world we live in and working towards a liberated future for all... We refuse to remain silent about how our lives are limited by heterosexist, racist, capitalist patriarchy. We invest in a political education that seeks above all, to make injustice impossible to ignore.&lt;/i&gt;&amp;quot; — With a characteristic ease, that we will appreciate to enjoy, Ms. Olufemi tells us that feminism is not words, and in the very next sentence, supports this by her refusal to remain silent.3.C, p. 7: &amp;quot;&lt;i&gt;Pop culture and mainstream narratives can democratise feminist theory, remove it from the realm of the academic and shine a light on important grassroots struggle, reminding us that feminism belongs to no one.&lt;/i&gt;&amp;quot; — Right after being schooled on how the iron fist of capitalist patriarchy controls every aspect of society, we suddenly learn that the capitalist society media welcomes the revolution.4.C, p. 8: This is the first time that Ms. Olufemi has decided to grace us with a cited source (an article from Sp!ked, 2018). The reference is in the form of a footnote, and the footnote is a 70-character URL. That is what almost all her references and footnotes look like. A particularly gorgeous URL is in footnote 3 on p. 53: it&amp;#x27;s 173 characters, of which the last 70 are unreadable gibberish. Am I supposed to retype this character-by-character on my phone? Or the references are for ornamentation only? In any case, it seems Ms. Olufemi either cannot hide her extreme contempt for the readers, or spent her life among people with an unusual amount of leisure.5.E, p. 15: &amp;quot;&lt;i&gt;When black feminists ... organised in the UK ... [t]hey were working towards collective improvement in material conditions...  For example...&lt;/i&gt;&amp;quot; — The examples provided are: Grunwick strike by South Asian women and an Indian lady, Jayaben Desai. Right in the next sentence after that, Ms. Olufemi concludes: &amp;quot;&lt;i&gt;There is a long history of black women ... mounting organised and strategic campaigning and lobbying efforts&amp;quot;&lt;/i&gt;. Again as in 2.C, she is completely unabated by the fact that the best examples of black feminist activities that she is able to furnish, have nothing to do with black feminists.6.E. p. 23: &amp;quot;&lt;i&gt;Critical feminism argues that state sexism has not lessened [for the last 50 years]&amp;quot;&lt;/i&gt;. Evidence: &amp;quot;&lt;i&gt;MPs in parliament hide the very insidious ways that the state continues to enable male dominance ... &lt;/i&gt;&amp;quot; — tension rises! — &amp;quot;&lt;i&gt;the Conservative government introduced their plans to pass a Domestic Violence Bill with the intention of increasing the number of convictions for perpetrators of abuse... &lt;/i&gt;&amp;quot; — which looks good on the surface, but of course — &amp;quot;&lt;i&gt;it is simply another example of the way the state plays on our anxieties about women&amp;#x27;s oppression to disguise the enactment of policies that trap women in subordinate positions.&lt;/i&gt;&amp;quot; — Finally, we are about to learn how exactly the governments (and NGOs, remember!) keep women subjugated for the last 50 years, we are agog with curiosity! — &amp;quot;&lt;i&gt;Research from the Prison Reform Trust has found an increase in the number of survivors being arrested&lt;/i&gt;&amp;quot; (p. 24) — And then... And then there is nothing. How does this prove that things are not better than 50 years ago? Just follow Mr. Olufemi example, and completely expunge from your mind everything that you claimed more than five sentences and seconds ago.7.C, p. 26. &amp;quot;&lt;i&gt;But this figure does not tell the whole story. The impact of these cuts is felt particularly by low-income black women and women of colour.&lt;/i&gt;&amp;quot; — Another constant motif of the book is that Ms. Olufemi alternately blames the state for violence and overreach, only to immediately request expansion of paternalistic services and welfare.8.C, p. 27: &amp;quot;&lt;i&gt;If a woman must disclose ... that she has been raped ... her dignity, agency and power over personal information is compromised.&lt;/i&gt;&amp;quot; — In a sudden turn of events our feminist seems to argue that it would be preferable for rape survivors to stay silent.9.E, p. 28: When she does provide any sort of supporting evidence, it feels better that she wouldn&amp;#x27;t: &amp;quot;&lt;i&gt;We know that thousands of disabled people have died as a direct result of government negligence surrounding Personal Independence Payments ...&lt;/i&gt;\((^9)\)&amp;quot; — The footnote is nothing but a 100 character URL, that I patiently typed in, only to be greeted with 404. According to &lt;code class=&quot;inline&quot;&gt;webarchive.org&lt;/code&gt;, the referred-to page never existed. Ultimately, after many false starts (whose details I shall spare you), I found the document at a completely different web-site:&lt;code class=&quot;inline&quot;&gt;https://questions-statements.parliament.uk/written-questions/detail/2018-12-19/203817&lt;/code&gt;Imagine my (lack of) surprise, when it turned out that government &amp;quot;&lt;i&gt;negligence&lt;/i&gt;&amp;quot; is neither mentioned nor in any way implied or imputed—Ms. Olufemi simply fabricated the whole story.10.I, p.29: &amp;quot;&lt;i&gt;[In Yarl&amp;#x27;s Wood IRC] they are locked in, unable to leave and subjected to surveillance by outsourced security guards. Tucked away in Bedford outside of the public consciousness, it&amp;#x27;s hard to think of a more potent example of state violence.&lt;/i&gt;&amp;quot; — Judgment of anybody who, in the world of wars, continuous genocides and slaughter of human beings, maintains that the worst example of state violence is the sufferings of the women, who fled their ruined countries to the relative safety of the UK, must be thoroughly questioned. The second quoted sentence is also indefensible grammatically.11.E, p. 30: In support of her claim that the state violently oppresses black women, Ms. Olufemi provides stories of 3 black women, that died in police custody over the course of... 50 years. &amp;quot;&lt;i&gt;they reveal a pattern&lt;/i&gt;&amp;quot; — she confidently concludes. No, they don&amp;#x27;t. Statistical data would, but they do not support Ms. Olufemi&amp;#x27;s thesis. She then proceeds to lament &amp;quot;&lt;i&gt;a dystopian nightmare for the undocumented migrants&lt;/i&gt;&amp;quot; — conveniently forgetting that these people tried as hard as they could to move to the dystopian UK and none of them hurried back.  The section the quote is from is called State Killings — the 3 examples provided are somehow put in the same rubric as the doings of Pol-Pot and Mao.12.E, p. 31: &amp;quot;&lt;i&gt;If black women die disproportionately at the hands of the police, historically and in the present moment&lt;/i&gt;&amp;quot; — and then she proceeds on the assumption that they do, without providing any evidence. Immediately available public data (from INQUEST and IOPC reports), clearly refute the premise.13.C, p. 32: &amp;quot;&lt;i&gt;This refusal to participate [in capitalism] takes many forms: feminist activists are finding new and creative ways to oppose austerity.&lt;/i&gt;&amp;quot; — Ms. Olufemi&amp;#x27;s personal creative way to refuse to participate in the capitalist economy is to copyright a book, publish it with a publishing corporation (a capitalist enterprise, mind you) and then collect the royalties.14.E., p. 33: &amp;quot;&lt;i&gt;Sisters Uncut has put domestic and sexual violence on the national agenda&lt;/i&gt;&amp;quot; — Ms. Olufemi&amp;#x27;s desire to prop her friends is laudable, but it does not eliminate the need to provide evidence.15.I., p.33: &amp;quot;&lt;i&gt;When I ask Sandy where the idea to create Sisters came from, she tells me&lt;/i&gt;&amp;quot; — Who&amp;#x27;s Sandy? No Sandy was mentioned before. A certain Sandy Stone, the author of &lt;i&gt;A Posttranssexual Manifesto&lt;/i&gt; appears 30 pages later, but it is unlikely she is meant here. The simple present tense of the sentence uncannily reminds of the way children talk about their imaginary friends.16.C., p. 36: &amp;quot;&lt;i&gt;So that just ... – Shulamith Firestone&lt;/i&gt;&amp;quot; — Oops, Ms. Olufemi approvingly quotes S. Firestone — a central figure in the so much derided second-wave liberal feminism.17.C, p. 38: Trying to tie &amp;#x27;social reproduction&amp;#x27; to race, Ms. Olufemi notices: &amp;quot;&lt;i&gt;Wealthy white women have always been able to exercise greater agency over their reproductive capacity because they can afford private healthcare and specialist medical advice&lt;/i&gt;&amp;quot;, omitting to mention that so have wealthy black women too. The difference, as she herself emphasised with the &amp;quot;&lt;i&gt;because&lt;/i&gt;&amp;quot; part, is in wealth not race. Mr. Olufemi then proceeds to build far-reaching conclusions from this rather trivial error.18.E, p. 39: Being a radical revolutionary, Ms. Olufemi is not afraid to cast aspersions on defenceless dead women: &amp;quot;&lt;i&gt;Margaret Sanger, reproductive rights advocate responsible for the first birth control-clinic in the United States was a vocal eugenicist&lt;/i&gt;&amp;quot; — the consensus in the literature is that M. Sanger was not a eugenist or racist in any shape of form. SeeRoberts, Dorothy (1998). Killing the Black Body: Race, Reproduction, and the Meaning of Liberty. Knopf Doubleday. ISBN 9780679758693. LCCN 97002383, p.77--78Gordon, Linda (2002). The Moral Property of Women: A History of Birth Control Politics in America. University of Illinois Press. ISBN 9780252027642.Valenza, Charles (1985). &amp;quot;Was Margaret Sanger a Racist?&amp;quot;. Family Planning Perspectives. 17 (1). Guttmacher Institute: 44–46. doi:10.2307/2135230. JSTOR 2135230. PMID 3884362Ms. Olufemi&amp;#x27;s source? Angela Davis. At this point, let me make an aside. Ms Olufemi treats Angela Davis as a kind of mother figure and a hero: she quotes her left and right, and puts her on the blurb of the back cover. Angela Davis, in the meantime, is a KGB stooge, a &amp;quot;&lt;i&gt;useful idiot&lt;/i&gt;&amp;quot; in an apt expression of Lenin. That beacon of freedom-fighting unashamedly praised and was on the pay of the Soviet communist regime that, as was very well-known at the time, organised the extermination of tens of millions of people.19.C, p. 41: Suddenly Ms. Olufemi lashes out against contraceptives, linking them to... eugenic: &amp;quot;&lt;i&gt;eugenics has shaped our notion of family ... the racist logic of &amp;#x27;population control&amp;#x27; that birthed the desire for contraceptives&lt;/i&gt;&amp;quot; — in this place again, it&amp;#x27;s difficult to tell her from far-right and religious fundamentalists.20.C, p. 44: &amp;quot;&lt;i&gt;nobody understands the stakes around the right to access abortion and reproductive justice more than working class women&amp;quot;&lt;/i&gt; — That looks like a good point to discuss Ms. Olufemi&amp;#x27;s background. Far from being qualified to understand the &amp;quot;&lt;i&gt;stakes&lt;/i&gt;&amp;quot;, she comes from what definitely does not look like a working class: after graduating from a privileged grammar school, she was immediately forced by the oppressive patriarchal society to study at Cambridge. Her PhD. research was sponsored (via TECHNE AHRC) by the very same government that she so mercilessly scrutinises in the present opus.21.E, p. 44: &amp;quot;&lt;i&gt;Ireland is coded &amp;#x27;white&amp;#x27;, and &amp;#x27;Irish woman&amp;#x27; means only those who fall under that coding&lt;/i&gt;&amp;quot; — neither of these claims is supported. Fortunately they are, as usual, in no way used in the following, because Ms Olufemi quickly switches to other, equally unsupported, claims.22.E, p. 47: &amp;quot;&lt;i&gt;English MPs voted ... to change Northern Ireland&amp;#x27;s abortion law .... This means that Abortion in Northern Ireland has only recently been decriminalised, the possibility of persecution has been lifted from those administering and undergoing abortions.&lt;/i&gt;&amp;quot; — (Capitalisation as in the original.) There were no &amp;quot;&lt;i&gt;underground&lt;/i&gt;&amp;quot; abortions in N. Ireland, because free abortions were available in England, a few hours away on a ferry.23.E, p. 47: &amp;quot;&lt;i&gt;The tendency to consider the UK a progressive environment for reproductive justice sorely underestimates the number of people, who despite the change in law may still have no recourse to abortion services&lt;/i&gt;&amp;quot; — Well, then tell us.24.E, p. 48: &amp;quot;&lt;i&gt;Winning radically would mean ... a world without work&lt;/i&gt;&amp;quot; — That&amp;#x27;s refreshingly honest, even though Marx won&amp;#x27;t approve of such blatant revisionism.25.E, p. 50: &amp;quot;&lt;i&gt;throughout history, to be &amp;#x27;female&amp;#x27; has often meant death, mutilation and oppression&lt;/i&gt;&amp;quot; — this unsupported claim is clearly wrong. Throughout history, most victims of violence by a large margin were and are men. Most people killed in the wars are men. Most people dying a violent death are men. Most people in prisons and mental institutions are men. More than 90% of work-related deaths happen to men.26.I, p. 50: &amp;quot;&lt;i&gt;If there are only two categories, it is easier for us to organise the world and attach feelings, emotions and ways of being to each one.&lt;/i&gt;&amp;quot; — If it were so, then all categories would have been binary: there would have been 2 nations, 2 fashion styles, &lt;i&gt;etc&lt;/i&gt;.27.C, p. 50 Ms. Olufemi continues to argue that gender is fluid and a person can change it at will. Her arguments: &amp;quot;&lt;i&gt;there is no way to adequately describe what gender is. Every definition does a disservice to the shifting, multiple and complex set of power relations that come to shape a person&amp;#x27;s gender.&lt;/i&gt;&amp;quot; — It would be interesting to trace her train of thought if &amp;quot;&lt;i&gt;gender&lt;/i&gt;&amp;quot; were replaced with &amp;quot;&lt;i&gt;race&lt;/i&gt;&amp;quot; in this sentence. As race is much more of a social construct and less rooted in biology, surely Ms. Olufemi would agree that we should welcome when a &amp;quot;&lt;i&gt;racially dysphoric&lt;/i&gt;&amp;quot; white person claims to be black. Unfortunately that would uproot her basic tenet about the exclusivity of black women&amp;#x27;s experience and its central role in the formation of radical feminism.28.C, p. 52: &amp;quot;&lt;i&gt;If one group of people consistently behave, speak, move, present themselves in one way and another in the &amp;#x27;opposite&amp;#x27; way, we reaffirm the idea that there is actually an inherent difference between those two groups when no such difference exists.&lt;/i&gt;&amp;quot; — I guess the groups Ms. Olufemi has in mind are males and females. Or maybe whites and blacks?29.C, p. 52: &amp;quot;&lt;i&gt;Many intersex infants ... have surgery to &amp;#x27;correct&amp;#x27; their genitalia without their consent.&lt;/i&gt;&amp;quot; — That&amp;#x27;s an interesting notion. Should we abstain from, for example, fixing broken bones of small children, until such time as they would be mature enough to consent?30.E, p. 53: &amp;quot;&lt;i&gt;Many women are physically stronger than men; many men are physically weaker than women. These are not exceptions that defy a rule; there simply is no rule.&lt;/i&gt;&amp;quot; — This betrays an utter ignorance of statistics and data. Normal distribution of strength (as measured, for example, by grip tests) in a population with different means for males and females is among the most reliably established anthropometrical facts.31.E, p. 54: &amp;quot;&lt;i&gt;To argue that there is a clear difference between sex and gender serves to solidify the idea that biological sex, prior to human beings inventing it and naming its tenants, exists.&lt;/i&gt;&amp;quot; — here again Ms. Olufemi joins far-right and religious fundamentalists in her anti-science stance and denial of the evolutionary origin of mechanisms of sexual reproduction. The objective existence of biological sex, manifested in morphological, physiological and behavioural differences (sexual dimorphism) is attested beyond the slightest doubt across the entire animal kingdom.32.E, p.68: &amp;quot;&lt;i&gt;It is the public rejoicing at 19-year-old Shamima Begum being stripped of her citizenship&lt;/i&gt;&amp;quot; — Ms. Olufemi chose as her example of Islamophobia a girl who joined ISIS, and became there an enforcer that threatened other women with death lest they comply with ISIS rules, stripped suicide vests into their clothes and ended up burying all her 3 children in this non-secular utopia.33.E, p. 71: &amp;quot;&lt;i&gt;Muslim women are the most economically disenfranchised group in the country.&lt;/i&gt;&amp;quot; — this simple claim is simply wrong. According to the UK Office for National Statistics, the most economically disenfranchised group in the UK are (as expected) refugees and asylum seekers, followed (unfortunately for Ms. Olufemi) by white workers in &amp;quot;&lt;i&gt;post-industrial&lt;/i&gt;&amp;quot; (read: de-industrialised) communities.34.C, p. 74: &amp;quot;&lt;i&gt;A staunchly secular way of thinking about our lives and bodies limits Muslim women&amp;#x27;s ability to understand themselves&lt;/i&gt;&amp;quot; — Ms. Olufemi sympathy for organised monotheistic religions and her distrust in the secular society is rather unexpected. It is not clear how to reconcile her idea that to better understand themselves women should abandon secularism and return to the church or mosque with the feminist dogma.35.I, p. 76: &amp;quot;&lt;i&gt;creation of a public outcry about &amp;#x27;Asian Grooming Gangs.&amp;#x27;&lt;/i&gt;&amp;quot; — It&amp;#x27;s sad that a feminist can scary-quote and dismiss one of the most horrible cases of mass abuse of women. A sacrifice of the suffering of more than a thousand girls to make a vindictive political point does not paint Ms. Olufemi as a good human being.36.I, p. 86: &amp;quot;&lt;i&gt;Art is a tool for feminist propaganda&lt;/i&gt;&amp;quot; — Unfortunately Ms. Olufemi forgot that this chapter is called Art for Art&amp;#x27;s Sake and its main thesis is that art of not a tool of anything. Notice also how she repeats Stalin and Goebbels almost verbatim.37.C, p. 88: &amp;quot;&lt;i&gt;Poor women do not get to make art: the fact that Saye&amp;#x27;s work could be displayed in one of the most prestigious arenas in the world ... calls us to wake up to the cruelty of inequity. &lt;/i&gt;&amp;quot; — This is probably one of the most impressive examples of Ms. Olufemi&amp;#x27;s ability to forget the beginning of a sentence (that she wrote!) by the time she gets to its middle — she demonstrates that poor women cannot make art by an example of a poor woman whose art became fashionable and famous. But then she easily outdoes herself! By the time we get to the end of the sentence, she forgets what was in the middle (or otherwise she thinks that being displayed at a Venice Biennale is unusually cruel).38.C, p. 89: &amp;quot;&lt;i&gt;Momtaza Mehri, essayist, researcher and former Poet Laureate for young people, tells me. &lt;/i&gt;&amp;quot; — Ms. Olufemi continues to give proof of art being unavailable to poor women by providing another example: of a poor woman who was a Poet Laureate.39.I, p. 110: &amp;quot;&lt;i&gt;The idea that justice is served when criminals go to prison is relatively new. ... Ironically, prisons were introduced in order to make punishment more &amp;#x27;humane&amp;#x27;.&lt;/i&gt;&amp;quot; — Unironically, this is one of the most blatantly ignorant statements to grace the printing press lately. Prisons, as known to anybody with even superficial knowledge of history, existed as long as states did. There are some echoes of Foucault in that sentence, but poorly read or remembered, because his conclusion was the opposite.40.E, p. 123: &amp;quot;&lt;i&gt;In July 2019, Cancer Research UK, fundraising partners with dieting organisation Slimming World, launched a multi-million pound campaign using defunct scientific indicators to claim that obesity was the second leading cause of cancer.&lt;/i&gt;&amp;quot; — This is outright dangerous. Spreading falsehoods to the vulnerable people in the risk groups is extremely irresponsible. Large‑scale cohort studies show that higher body mass index (BMI) and excess adiposity correlate with increased incidence and worse outcomes for multiple cancer types. These data form the backbone of public‑health recommendations promoting weight management:Renehan AG, Tyson M, Egger M, Heller RF, Zwahlen M. &amp;quot;&lt;i&gt;Body-mass index and   incidence of cancer: a systematic review and meta-analysis of prospective   observational studies.&lt;/i&gt;&amp;quot; The Lancet, 371(9612), 569-578 (2008).Bhaskaran K, Douglas I, Forbes H, dos-Santos-Silva I, Leon DA, Smeeth   L. &amp;quot;&lt;i&gt;Body-mass index and risk of 22 specific cancers: a population-based   cohort study of 5·24 million UK adults.&lt;/i&gt;&amp;quot; The Lancet, 384(9945), 755-765   (2014).41.I, p. 124: &amp;quot;&lt;i&gt;There is no clearer manifestation of neo-liberalism than in our attitudes towards bodies.&lt;/i&gt;&amp;quot; — this, in the words of Pauli &amp;quot;&lt;i&gt;is not even wrong&lt;/i&gt;&amp;quot;, whatever &amp;quot;&lt;i&gt;attitudes toward bodies&lt;/i&gt;&amp;quot; means, they are not the clearest manifestation of neo-liberalism.42.C, p. 125: &amp;quot;&lt;i&gt;the myth that fatness means ill health&lt;/i&gt;&amp;quot; — Again, Ms Olufemi would be home with far-right conspiracy theorists. Excess adipose tissue (body fat) is strongly linked to a variety of health problems, including hypertension, insulin resistance, type 2 diabetes, cardiovascular disease, sleep apnea, and certain cancers. Medical researchers generally treat obesity as a risk factor that actively contributes to many of these conditions.43.I, p. 126: &amp;quot;&lt;i&gt;Nearly half of single parents in the UK – working or unemployed – live in relative poverty.&lt;/i&gt;&amp;quot; — That&amp;#x27;s because relative poverty is defined by the UK statistical agencies as &amp;quot;&lt;i&gt;being poorer than half of the population&lt;/i&gt;&amp;quot;.At this point your humble Scheherazade broke off in exhaustion.Conclusions&lt;span class=&quot;align-right&quot;&gt;&amp;quot;&lt;i&gt;we need to remove the shame in the way we talk about acceptable forms of killing&lt;/i&gt;&amp;quot; — p. 48&lt;/span&gt;I hope my notes demonstrated that even the most lenient and indulgent reader would quickly conclude that Feminism Interrupted is balderdash. That would be, however, too trivial a conclusion. Everything has a purpose and Ms. Olufemi book can find one with our help. As far as I can see, the purpose is to realise that even though incoherent and rambling, the text has a texture, some recurrent images appear again and again:1. Ms Olufemi continuously laments the exploitation, poverty and oppression of  women in the UK. Well, as everything in human condition, exploitation is  relative. Ms. Olufemi enjoys the life of comfort, privilege and ease  unimaginable to anyone outside of the scopes of the &amp;quot;developed&amp;quot; (&lt;i&gt;i.e.&lt;/i&gt;,  capitalist) world or the last hundred years. She imagines a utopia of a  stateless society free of &amp;quot;exploitation&amp;quot;, but there is no indication that this  eschaton is possible. It is not even a practical possibility that is  questionable, but logical: is her image free of internal contradictions? All  attempts to realise this millenialist dream, from Bogomils to Soviet and  Chinese communists, are remembered for little besides industrial scale murder  they invariably resulted in.2. Ms. Olufemi&amp;#x27;s feelings toward organised religion are clearly ambiguous. On   one hand, she presumably understands that organised religion is the core   institution of patriarchy that maintains and perpetuates values and structures   that she finds so odious. On the other hand, she obviously cannot stop   expressing her admiration of the austere faith of Mohammed, comparing it   favourably with the decadent secular societies of the West.3. Ms. Olufemi cannot decide whether she wants to abolish the state or expand   it tremendously. Often in the course of the same period she registers her   conviction that the state is evil and should be abolished, only to proceed to   point out how unjust it is that the state does not sufficiently help the   dispossessed and to request enlargement of welfare.4. As was noted on many occasions, many of Ms. Olufemi&amp;#x27;s positions echo ones   of far-right conspirologists. Her distrust of science and NGOs makes one   reconsider the &amp;quot;&lt;a href=&quot;https://en.wikipedia.org/wiki/Horseshoe_theory&quot;&gt;&lt;i&gt;horseshoe theory&lt;/i&gt;&lt;/a&gt;&amp;quot; favourably.</content>
        </item>

        <item>
            <title>you have a strange forbidding feeling...</title>
            <id>forbidden</id>
            <link>https://cofault.com/forbidden.html#forbidden</link>
            <pubDate>2005/06/26</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/forbidden.html#forbidden">
                     [Updated: 2005.07.24]A scary thing happened to me: my first thought, while looking at &lt;code class=&quot;inline&quot;&gt;linux-2.6.5-7.151/lib/vsprintf.c&lt;/code&gt;if (*fmt == &amp;#x27;h&amp;#x27; || *fmt == &amp;#x27;l&amp;#x27; || *fmt == &amp;#x27;L&amp;#x27; ||
    *fmt == &amp;#x27;Z&amp;#x27; || *fmt == &amp;#x27;z&amp;#x27;) {
    qualifier = *fmt;
    fmt++;
}was something like &lt;i&gt;Hmm... I should be careful about that &lt;a href=&quot;http://www.cim.mcgill.ca/~simra/nhtohtml/html/master_lich.html&quot;&gt;master lich&lt;/a&gt; here...&lt;/i&gt;. I should throttle down.</content>
        </item>

        <item>
            <title>gcc-13 bug</title>
            <id>gcc-13-bug</id>
            <link>https://cofault.com/gcc-13-bug.html#gcc-13-bug</link>
            <pubDate>2025/05/04</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/gcc-13-bug.html#gcc-13-bug">
                     I hit what more and more looks like &lt;span class=&quot;annotation&quot; data-uid=&quot;3&quot;&gt;a bug&lt;/span&gt; in the standard Ubuntu 24 gcc version. Here is a minimal reproducer that I with great pain extracted from 12KLOC sources:struct foo {
        int   seq;
        void *data;
};

struct bar {
        struct foo rung[1];
};

static int used;

static char ll(const struct foo *n) {
        return *(char *)n-&amp;gt;data;
}

int main(int argc, char **argv) {
        struct bar p = {};
        int result = 0;
        used = 0;
        __asm__ __volatile__(&amp;quot;&amp;quot;: : :&amp;quot;memory&amp;quot;);
        for (int i = 0; i &amp;lt;= used &amp;amp;&amp;amp; result == 0; ++i) {
                struct foo *r = &amp;amp;p.rung[i];
                __attribute__((assume(i &amp;lt;= 0 || ll(r) + 1 == ll(r - 1))));
                if (!(r-&amp;gt;seq == 0 &amp;amp;&amp;amp; (i &amp;lt;= 0 || ll(r) + 1 == ll(r - 1)))) {
                        result = -1;
                }
        }
        return 0;
}Compile as &lt;code class=&quot;inline&quot;&gt;gcc -O1 gcc-13-bug.c&lt;/code&gt;, it crashes with SIGSEGV. Note that because the loop iterates only once, &lt;code class=&quot;inline&quot;&gt;i == 0&lt;/code&gt; in the body of the loop, so &lt;code class=&quot;inline&quot;&gt;ll(r)&lt;/code&gt; should not be called. Yet, &lt;code class=&quot;inline&quot;&gt;ll(r)&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;ll(r-1)&lt;/code&gt; are both called.The reproducer is minimal in the sense that it is locally optimal: any small random change eliminates the effect. For example,Move &lt;code class=&quot;inline&quot;&gt;used = 0&lt;/code&gt; over the &lt;code class=&quot;inline&quot;&gt;asm&lt;/code&gt;-barrier (or simply remove the barrier).Remove &lt;code class=&quot;inline&quot;&gt;result == 0&lt;/code&gt; from the loop guard.Replace &lt;code class=&quot;inline&quot;&gt;struct bar p = {}&lt;/code&gt; with &lt;code class=&quot;inline&quot;&gt;struct foo[1] p = {}&lt;/code&gt; &lt;i&gt;mutatis  mutandis&lt;/i&gt;. This one is especially surprising.</content>
        </item>

        <item>
            <title>gcc error message</title>
            <id>gcc-error-message</id>
            <link>https://cofault.com/gcc-error-message.html#gcc-error-message</link>
            <pubDate>2005/04/12</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/gcc-error-message.html#gcc-error-message">
                     Quite some time ago (in the previous century), gcc greeted me with the following self-explanatory message (My feelings toward C++ only increased since then.):src/algorithms/parse/GrammarNode.cpp:114: `((new QR::ObjectWrapper(((new QR::Concatenation(&amp;quot;barNo&amp;quot;,
new QR::List(2, ((new QR::ObjectWrapper(((new QR::Terminal(&amp;quot;bar&amp;quot;, new QR::String(&amp;quot;keyword_bar&amp;quot;)) !=
0) ? new QR::Terminal(&amp;quot;bar&amp;quot;, new QR::String(&amp;quot;keyword_bar&amp;quot;))-&amp;gt;QR::Terminal::_vb.Q22QR11GrammarNode-&amp;gt;
QR::GrammarNode::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top : 0)) != 0) ? new QR::ObjectWrapper(((
new QR::Terminal(&amp;quot;bar&amp;quot;, new QR::String(&amp;quot;keyword_bar&amp;quot;)) != 0) ? new QR::Terminal(&amp;quot;bar&amp;quot;, new QR::Stri
ng(&amp;quot;keyword_bar&amp;quot;))-&amp;gt;QR::Terminal::_vb.Q22QR11GrammarNode-&amp;gt;QR::GrammarNode::_vb.Q22QR6Object-&amp;gt;QR::Ob
ject::_vb.Q22QR3Top : 0))-&amp;gt;QR::ObjectWrapper::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top : 0), ((n
ew QR::ObjectWrapper(((new QR::Terminal(&amp;quot;&amp;lt; &amp;gt;&amp;quot;, new QR::String(&amp;quot;Whitespace&amp;quot;)) != 0) ? new QR::Termin
al(&amp;quot;&amp;lt; &amp;gt;&amp;quot;, new QR::String(&amp;quot;Whitespace&amp;quot;))-&amp;gt;QR::Terminal::_vb.Q22QR11GrammarNode-&amp;gt;QR::GrammarNode::_vb
.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top : 0)) != 0) ? new QR::ObjectWrapper(((new QR::Terminal(&amp;quot;&amp;lt;
&amp;quot;, new QR::String(&amp;quot;Whitespace&amp;quot;)) != 0) ? new QR::Terminal(&amp;quot;&amp;lt; &amp;gt;&amp;quot;, new QR::String(&amp;quot;Whitespace&amp;quot;))-&amp;gt;QR
::Terminal::_vb.Q22QR11GrammarNode-&amp;gt;QR::GrammarNode::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top :
0))-&amp;gt;QR::ObjectWrapper::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top : 0), ((new QR::ObjectWrapper((
(new QR::Terminal(&amp;quot;no&amp;quot;, new QR::String(&amp;quot;NumericLiteral&amp;quot;)) != 0) ? new QR::Terminal(&amp;quot;no&amp;quot;, new QR::St
ring(&amp;quot;NumericLiteral&amp;quot;))-&amp;gt;QR::Terminal::_vb.Q22QR11GrammarNode-&amp;gt;QR::GrammarNode::_vb.Q22QR6Object-&amp;gt;Q
R::Object::_vb.Q22QR3Top : 0)) != 0) ? new QR::ObjectWrapper(((new QR::Terminal(&amp;quot;no&amp;quot;, new QR::Strin
g(&amp;quot;NumericLiteral&amp;quot;)) != 0) ? new QR::Terminal(&amp;quot;no&amp;quot;, new QR::String(&amp;quot;NumericLiteral&amp;quot;))-&amp;gt;QR::Terminal
::_vb.Q22QR11GrammarNode-&amp;gt;QR::GrammarNode::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top : 0))-&amp;gt;QR::O
bjectWrapper::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top : 0), 0)) != 0) ? new QR::Concatenation(&amp;quot;
barNo&amp;quot;, new QR::List(2, ((new QR::ObjectWrapper(((new QR::Terminal(&amp;quot;bar&amp;quot;, new QR::String(&amp;quot;keyword_b
ar&amp;quot;)) != 0) ? new QR::Terminal(&amp;quot;bar&amp;quot;, new QR::String(&amp;quot;keyword_bar&amp;quot;))-&amp;gt;QR::Terminal::_vb.Q22QR11Gram
marNode-&amp;gt;QR::GrammarNode::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top : 0)) != 0) ? new QR::ObjectW
rapper(((new QR::Terminal(&amp;quot;bar&amp;quot;, new QR::String(&amp;quot;keyword_bar&amp;quot;)) != 0) ? new QR::Terminal(&amp;quot;bar&amp;quot;, new
QR::String(&amp;quot;keyword_bar&amp;quot;))-&amp;gt;QR::Terminal::_vb.Q22QR11GrammarNode-&amp;gt;QR::GrammarNode::_vb.Q22QR6Object
-&amp;gt;QR::Object::_vb.Q22QR3Top : 0))-&amp;gt;QR::ObjectWrapper::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top :
0), ((new QR::ObjectWrapper(((new QR::Terminal(&amp;quot;&amp;lt; &amp;gt;&amp;quot;, new QR::String(&amp;quot;Whitespace&amp;quot;)) != 0) ? new QR:
:Terminal(&amp;quot;&amp;lt; &amp;gt;&amp;quot;, new QR::String(&amp;quot;Whitespace&amp;quot;))-&amp;gt;QR::Terminal::_vb.Q22QR11GrammarNode-&amp;gt;QR::GrammarNo
de::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top : 0)) != 0) ? new QR::ObjectWrapper(((new QR::Termi
nal(&amp;quot;&amp;lt; &amp;gt;&amp;quot;, new QR::String(&amp;quot;Whitespace&amp;quot;)) != 0) ? new QR::Terminal(&amp;quot;&amp;lt; &amp;gt;&amp;quot;, new QR::String(&amp;quot;Whitespace
&amp;quot;))-&amp;gt;QR::Terminal::_vb.Q22QR11GrammarNode-&amp;gt;QR::GrammarNode::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR
3Top : 0))-&amp;gt;QR::ObjectWrapper::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top : 0), ((new QR::ObjectWr
apper(((new QR::Terminal(&amp;quot;no&amp;quot;, new QR::String(&amp;quot;NumericLiteral&amp;quot;)) != 0) ? new QR::Terminal(&amp;quot;no&amp;quot;, new
QR::String(&amp;quot;NumericLiteral&amp;quot;))-&amp;gt;QR::Terminal::_vb.Q22QR11GrammarNode-&amp;gt;QR::GrammarNode::_vb.Q22QR6Obj
ect-&amp;gt;QR::Object::_vb.Q22QR3Top : 0)) != 0) ? new QR::ObjectWrapper(((new QR::Terminal(&amp;quot;no&amp;quot;, new QR:
:String(&amp;quot;NumericLiteral&amp;quot;)) != 0) ? new QR::Terminal(&amp;quot;no&amp;quot;, new QR::String(&amp;quot;NumericLiteral&amp;quot;))-&amp;gt;QR::Te
rminal::_vb.Q22QR11GrammarNode-&amp;gt;QR::GrammarNode::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top : 0))-
QR::ObjectWrapper::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top : 0), 0))-&amp;gt;QR::GrammarNode::_vb.Q22
QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top : 0)) != 0) ? new QR::ObjectWrapper(((new QR::Concatenation(&amp;quot;b
arNo&amp;quot;, new QR::List(2, ((new QR::ObjectWrapper(((new QR::Terminal(&amp;quot;bar&amp;quot;, new QR::String(&amp;quot;keyword_ba
r&amp;quot;)) != 0) ? new QR::Terminal(&amp;quot;bar&amp;quot;, new QR::String(&amp;quot;keyword_bar&amp;quot;))-&amp;gt;QR::Terminal::_vb.Q22QR11Gramm
arNode-&amp;gt;QR::GrammarNode::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top : 0)) != 0) ? new QR::ObjectWr
apper(((new QR::Terminal(&amp;quot;bar&amp;quot;, new QR::String(&amp;quot;keyword_bar&amp;quot;)) != 0) ? new QR::Terminal(&amp;quot;bar&amp;quot;, new
QR::String(&amp;quot;keyword_bar&amp;quot;))-&amp;gt;QR::Terminal::_vb.Q22QR11GrammarNode-&amp;gt;QR::GrammarNode::_vb.Q22QR6Object
-&amp;gt;QR::Object::_vb.Q22QR3Top : 0))-&amp;gt;QR::ObjectWrapper::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top :
0), ((new QR::ObjectWrapper(((new QR::Terminal(&amp;quot;&amp;lt; &amp;gt;&amp;quot;, new QR::String(&amp;quot;Whitespace&amp;quot;)) != 0) ? new QR:
:Terminal(&amp;quot;&amp;lt; &amp;gt;&amp;quot;, new QR::String(&amp;quot;Whitespace&amp;quot;))-&amp;gt;QR::Terminal::_vb.Q22QR11GrammarNode-&amp;gt;QR::GrammarNo
de::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top : 0)) != 0) ? new QR::ObjectWrapper(((new QR::Termi
nal(&amp;quot;&amp;lt; &amp;gt;&amp;quot;, new QR::String(&amp;quot;Whitespace&amp;quot;)) != 0) ? new QR::Terminal(&amp;quot;&amp;lt; &amp;gt;&amp;quot;, new QR::String(&amp;quot;Whitespace
&amp;quot;))-&amp;gt;QR::Terminal::_vb.Q22QR11GrammarNode-&amp;gt;QR::GrammarNode::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR
3Top : 0))-&amp;gt;QR::ObjectWrapper::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top : 0), ((new QR::ObjectWr
apper(((new QR::Terminal(&amp;quot;no&amp;quot;, new QR::String(&amp;quot;NumericLiteral&amp;quot;)) != 0) ? new QR::Terminal(&amp;quot;no&amp;quot;, new
QR::String(&amp;quot;NumericLiteral&amp;quot;))-&amp;gt;QR::Terminal::_vb.Q22QR11GrammarNode-&amp;gt;QR::GrammarNode::_vb.Q22QR6Obj
ect-&amp;gt;QR::Object::_vb.Q22QR3Top : 0)) != 0) ? new QR::ObjectWrapper(((new QR::Terminal(&amp;quot;no&amp;quot;, new QR:
:String(&amp;quot;NumericLiteral&amp;quot;)) != 0) ? new QR::Terminal(&amp;quot;no&amp;quot;, new QR::String(&amp;quot;NumericLiteral&amp;quot;))-&amp;gt;QR::Te
rminal::_vb.Q22QR11GrammarNode-&amp;gt;QR::GrammarNode::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top : 0))-
QR::ObjectWrapper::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top : 0), 0)) != 0) ? new QR::Concatena
tion(&amp;quot;barNo&amp;quot;, new QR::List(2, ((new QR::ObjectWrapper(((new QR::Terminal(&amp;quot;bar&amp;quot;, new QR::String(&amp;quot;key
word_bar&amp;quot;)) != 0) ? new QR::Terminal(&amp;quot;bar&amp;quot;, new QR::String(&amp;quot;keyword_bar&amp;quot;))-&amp;gt;QR::Terminal::_vb.Q22QR
11GrammarNode-&amp;gt;QR::GrammarNode::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top : 0)) != 0) ? new QR::O
bjectWrapper(((new QR::Terminal(&amp;quot;bar&amp;quot;, new QR::String(&amp;quot;keyword_bar&amp;quot;)) != 0) ? new QR::Terminal(&amp;quot;bar
&amp;quot;, new QR::String(&amp;quot;keyword_bar&amp;quot;))-&amp;gt;QR::Terminal::_vb.Q22QR11GrammarNode-&amp;gt;QR::GrammarNode::_vb.Q22QR
6Object-&amp;gt;QR::Object::_vb.Q22QR3Top : 0))-&amp;gt;QR::ObjectWrapper::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22Q
R3Top : 0), ((new QR::ObjectWrapper(((new QR::Terminal(&amp;quot;&amp;lt; &amp;gt;&amp;quot;, new QR::String(&amp;quot;Whitespace&amp;quot;)) != 0) ?
new QR::Terminal(&amp;quot;&amp;lt; &amp;gt;&amp;quot;, new QR::String(&amp;quot;Whitespace&amp;quot;))-&amp;gt;QR::Terminal::_vb.Q22QR11GrammarNode-&amp;gt;QR::Gr
ammarNode::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top : 0)) != 0) ? new QR::ObjectWrapper(((new QR
::Terminal(&amp;quot;&amp;lt; &amp;gt;&amp;quot;, new QR::String(&amp;quot;Whitespace&amp;quot;)) != 0) ? new QR::Terminal(&amp;quot;&amp;lt; &amp;gt;&amp;quot;, new QR::String(&amp;quot;Whi
tespace&amp;quot;))-&amp;gt;QR::Terminal::_vb.Q22QR11GrammarNode-&amp;gt;QR::GrammarNode::_vb.Q22QR6Object-&amp;gt;QR::Object::_v
b.Q22QR3Top : 0))-&amp;gt;QR::ObjectWrapper::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top : 0), ((new QR::O
bjectWrapper(((new QR::Terminal(&amp;quot;no&amp;quot;, new QR::String(&amp;quot;NumericLiteral&amp;quot;)) != 0) ? new QR::Terminal(&amp;quot;n
o&amp;quot;, new QR::String(&amp;quot;NumericLiteral&amp;quot;))-&amp;gt;QR::Terminal::_vb.Q22QR11GrammarNode-&amp;gt;QR::GrammarNode::_vb.Q
22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top : 0)) != 0) ? new QR::ObjectWrapper(((new QR::Terminal(&amp;quot;no&amp;quot;,
new QR::String(&amp;quot;NumericLiteral&amp;quot;)) != 0) ? new QR::Terminal(&amp;quot;no&amp;quot;, new QR::String(&amp;quot;NumericLiteral&amp;quot;))-
QR::Terminal::_vb.Q22QR11GrammarNode-&amp;gt;QR::GrammarNode::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top
: 0))-&amp;gt;QR::ObjectWrapper::_vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top : 0), 0))-&amp;gt;QR::GrammarNode::_
vb.Q22QR6Object-&amp;gt;QR::Object::_vb.Q22QR3Top : 0))-&amp;gt;QR::ObjectWrapper::_vb.Q22QR6Object-&amp;gt;QR::Object::
_vb.Q22QR3Top : 0)&amp;#x27; cannot be used as a function</content>
        </item>

        <item>
            <title>the power of gdb</title>
            <id>gdb</id>
            <link>https://cofault.com/gdb.html#gdb</link>
            <pubDate>2005/03/31</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/gdb.html#gdb">
                     Yesterday I was running long file system stress test (&lt;a href=&quot;http://www.codemonkey.org.uk/cruft/fsx-linux.c&quot;&gt;fsx&lt;/a&gt; if you want to know) when X server on my workstation locked up completely (because it ran on a heavily patched kernel as turned out later). One consequence of this was that xterm which fsx output was going to, went, together with X server, to the land of Eternal GoodDrawable and stopped caring about silly clients sending frantic write(2)s to it.fsx stopped which was unfortunate. So I logged to the test box and didSession$ gdb fsx $(pgrep fsx) # attach to the fsx
(gdb) bt
#0  0x90010760 in write ()
#1  0x90026104 in _swrite ()
#2  0x90020c80 in __sflush ()
#3  0x90031e00 in __fflush ()
#4  0x90006e4c in __sfvwrite ()
#5  0x90006ef0 in __sprint ()
#6  0x90006a48 in __vfprintf ()
#7  0x9000c76c in vfprintf ()
#8  0x000025a0 in prt ()
#9  0x00004a0c in dotruncate ()
#10 0x000051c0 in test ()
#11 0x0000659c in main ()
#12 0x0000220c in _start (argc=2, argv=0xbffffa14, envp=0xbffffa20) at /SourceCache/Csu/Csu-46/crt.c:267
#13 0x00002080 in start ()
(gdb) # yes it really stuck doing write to the stdout. And yes, this is Mac OS X.
(gdb) # now fun part begins
(gdb) call (int)close(1) # close standard output
$1 = 0
(gdb) # it worked! Leave fsx in piece...
(gdb) detach
(gdb) quitand test was running further happily.The moral: gdb can save your day.</content>
        </item>

        <item>
            <title>Why Go is Not My Favorite Programming Language</title>
            <id>golang</id>
            <link>https://cofault.com/golang.html#golang</link>
            <pubDate>2019/01/27</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/golang.html#golang">
                     &lt;i&gt;Disclaimer&lt;/i&gt;: this article shares very little except the title with the classical &lt;a href=&quot;https://www.lysator.liu.se/c/bwk-on-pascal.html&quot;&gt;Why Pascal is Not My Favorite Programming Language&lt;/a&gt;. No attempt is made to analyse Go in any systematic fashion. To the contrary, the focus is on one particular, if grave, issue. Moreover, the author happily admits that his experience with Go programming is very limited.Go is a system programming language and a large fraction of system software is processing of incoming &lt;i&gt;requests&lt;/i&gt; of some sort, for example:[KERNEL] an OS kernel processes system calls;[SERVER] a server processes requests received over network or IPC;[LIB] a library processes invocations of its entry points.A distinguishing feature of system software is that it should be resilient against abnormal conditions it the environment such as network communication failures, storage failure, &lt;i&gt;etc&lt;/i&gt;. Of course, there are practical limits to such resilience and it is very difficult to construct a software that would operate correctly in the face on undetected processor or memory failures (albeit, such systems &lt;a href=&quot;https://en.wikipedia.org/wiki/Tandem_Computers&quot;&gt;were built&lt;/a&gt; in the past), but it is generally agreed that system software should handle a certain class of failures to be usable as a foundation of software stack. We argue that Go is not suitable for system programming because it cannot deal with one of the most important failures in this class: memory allocation errors.Out of many existing designs of failure handling (exceptions, &lt;a href=&quot;https://users.ece.cmu.edu/~koopman/des_s99/sw_fault_tolerance/&quot;&gt;recovery &lt;/a&gt;&lt;a href=&quot;https://users.ece.cmu.edu/~koopman/des_s99/sw_fault_tolerance/&quot;&gt;blocks&lt;/a&gt;, &lt;i&gt;etc&lt;/i&gt;.) Go exclusively selects explicit error checking with a simple &lt;a href=&quot;https://golang.org/ref/spec#Handling_panics&quot;&gt;panic-&lt;a href=&quot;https://users.ece.cmu.edu/~koopman/des_s99/sw_fault_tolerance/&quot;&gt;recovery &lt;/a&gt;&lt;/a&gt;mechanism. This makes sense, because this is the only design that works in all the use-cases mentioned above. However, memory allocation errors do not produce checkable errors in Go. The language specification does not even &lt;a href=&quot;https://golang.org/ref/spec#Allocation&quot;&gt;mention a possibility of allocation failure&lt;/a&gt; and in the discussions of these issues (see &lt;i&gt;e.g.&lt;/i&gt;, &lt;a href=&quot;https://github.com/golang/go/issues/243&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;https://github.com/golang/go/issues/14162&quot;&gt;here&lt;/a&gt;) Google engineers adamantly refuse considering a possibility of adding an interface to intercept memory allocation errors. Instead, various methods to warn the application that memory is &amp;quot;about to be exhausted&amp;quot; as proposed. These methods, of course, only reduce the probability of running out of memory, but never eliminate it (thus making bugs in the error handling code more difficult to test). As one can easily check by running a simple program that allocates all available memory, memory allocation error results in unconditional program termination, rather than a recoverable panic.But even if a way to check for allocation errors or recover from them were added, it would not help, because Go often allocates memory behind the scenes, so that there is no point in the program source, where a check could be made. For example, memory is allocated whenever a struct is used as an interface:package main
type foo interface {
        f() int
}

type bar struct {
        v int
}

func out(s foo) int {
        return s.f() - 1
}

func (self bar) f() int {
        return self.v + 1
}

func main() {
        for {
                out(bar{})
        }
}The program above contains no explicit memory allocations, still, it allocates a lot of memory. The assembly output (use &lt;a href=&quot;https://go.godbolt.org/&quot;&gt;godbolt.org&lt;/a&gt; for example) for &lt;code class=&quot;inline&quot;&gt;out(bar{})&lt;/code&gt; contains a call to &lt;code class=&quot;inline&quot;&gt;runtime.convT64()&lt;/code&gt; (see the &lt;a href=&quot;https://github.com/golang/go/blob/master/src/runtime/iface.go&quot;&gt;source&lt;/a&gt;) that calls &lt;a href=&quot;https://github.com/golang/go/blob/master/src/runtime/malloc.go&quot;&gt;mallocgc&lt;/a&gt;.func convT64(val uint64) (x unsafe.Pointer) {
	if val == 0 {
		x = unsafe.Pointer(&amp;amp;amp;zeroVal[0])
	} else {
		x = mallocgc(8, uint64Type, false)
		*(*uint64)(x) = val
	}
	return
}To summarise, the combination of the following reasons makes Go unsuitable for construction of reliable system software:it is not, in general, possible to guarantee that memory allocation would  always succeed. For example, in the [LIBRARY] case, other parts of the process  or other processes can exhaust all the available memory. Pre-allocating memory  for the worst case is impractical except in the simplest cases;due to the design of Go runtime and the implementation of the fundamental  language features like interfaces, it is not possible to reliably check for  memory allocation errors;software that can neither prevent nor resolve memory allocation errors is  unreliable. For example, a library that when called crashes the entire process,  because some other process allocated all available memory cannot be used to  build reliable software on top of it.</content>
        </item>

        <item>
            <title>The Cook, The Thief, His Wife and Her Lover go to the masses.</title>
            <id>greenway</id>
            <link>https://cofault.com/greenway.html#greenway</link>
            <pubDate>2005/04/22</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/greenway.html#greenway">
                     &lt;a href=&quot;https://www.kommersant.ru/doc/572221?query=%D0%9F%D0%BE%D0%B2%D0%B0%D1%80&quot;&gt;Yesterday&lt;/a&gt; [2005/04/21], Russian nation-wide TV Channel Россия, broadcast Peter Greenway&amp;#x27;s &lt;a href=&quot;https://en.wikipedia.org/wiki/The_Cook,_the_Thief,_His_Wife_%26_Her_Lover&quot;&gt;&lt;i&gt;The Cook, The Thief, His Wife and Her Lover&lt;/i&gt;&lt;/a&gt;. Isn&amp;#x27;t there is something very Greenwayish in the image of 40 million people turning their TV sets on to relax after a hard day only to be confronted with what can be only viewed, but not described?PS: I just [2025/05/11] noticed that the TV program above hilariously lists the movie as „Киноакадемия &amp;quot;Повар, вор, его жена и ее любовник&amp;quot;. Режиссер О. Стоун. В ролях: Т. Круз, У. Дефо (США)“ (Film Academy: The Cook, the Thief, His Wife &amp;amp; Her Lover, directed by O. Stone, starring: T. Cruz, W. Dafoe (USA)). Imagine mixing Greenway&amp;#x27;s movie with &lt;a href=&quot;https://en.wikipedia.org/wiki/Born_on_the_Fourth_of_July_(film)&quot;&gt;Born on the Fourth of July&lt;/a&gt;.</content>
        </item>

        <item>
            <title>The Hunt for Addi(c)tive Monster</title>
            <id>hunt.1</id>
            <link>https://cofault.com/hunt.1.html#hunt.1</link>
            <pubDate>2010/01/12</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/hunt.1.html#hunt.1">
                     &lt;span class=&quot;linktarget&quot; data-uid=&quot;0&quot;&gt;&lt;span class=&quot;linktarget&quot; data-uid=&quot;1&quot;&gt;T&lt;/span&gt;&lt;/span&gt;his is &lt;span class=&quot;annotation&quot; data-uid=&quot;2&quot;&gt;another spurious post&lt;/span&gt; about mathematics that happened instead of something more useful. Let&amp;#x27;s talk about one of the most common mathematical objects: a &lt;a href=&quot;http://en.wikipedia.org/wiki/Function_%28mathematics%29&quot;&gt;function&lt;/a&gt; that maps &lt;a href=&quot;http://en.wikipedia.org/wiki/Real_number&quot;&gt;real numbers&lt;/a&gt; (\(\R\)) to &lt;a href=&quot;http://en.wikipedia.org/wiki/Real_number&quot;&gt;real numbers&lt;/a&gt;. We shall call such a &lt;a href=&quot;http://en.wikipedia.org/wiki/Function_%28mathematics%29&quot;&gt;function&lt;/a&gt; \(f : \R \rightarrow \R\) &lt;i&gt;additive&lt;/i&gt; &lt;a href=&quot;http://en.wikipedia.org/wiki/Iff&quot;&gt;iff&lt;/a&gt; for any real \(x\) and \(y\)f(a + b) = f(a) + f(b)This is a natural and simple condition. Well-known examples of additive functions are provided by &lt;i&gt;linear&lt;/i&gt; functions \(f : x \mapsto k \cdot x\), where \(k\) is called &lt;i&gt;a slope&lt;/i&gt;.Are there other, non-linear additive functions? And if so, how do they look like? A bit of thinking convinces one that a non-linear additive function is not trivial to find. In fact, as we shall show below, should such a function exist, it would exhibit extremely weird features. Hence, we shall call a non-linear additive function &lt;i&gt;a monster&lt;/i&gt;.  In the following, some properties that a monster function has to possess are investigated, until a monster is cornered either out of existence or into an example. Out of misplaced spite we shall use \(\epsilon-\delta\) &lt;a href=&quot;http://en.wikipedia.org/wiki/%28%CE%B5,_%CE%B4%29-definition_of_limit&quot;&gt;technique&lt;/a&gt; in some proofs.First, some trivial remarks about the collection of all additive functions (which will be denoted \(\Add\)).If \(f : \R \rightarrow \R\), \(g : \R \rightarrow \R\) are two additive functions and \(\alpha \in \R\) — an arbitrary real number, then \(f + g\), \(-f\) and \(\alpha \cdot f\) are additive. This means that additive functions form a &lt;a href=&quot;http://en.wikipedia.org/wiki/Vector_space&quot;&gt;vector space&lt;/a&gt; over field \(\R\) with constant zero additive function as a &lt;a href=&quot;http://en.wikipedia.org/wiki/Zero_vector&quot;&gt;zero vector&lt;/a&gt;. This vector space is a sub-space of a vector space of all functions from \(\R\) to \(\R\). Product of two additive functions is not in general additive (when it is?), but their composition is:(f \circ g)(x + y) = f(g(x + y)) = f(g(x) + g(y)) = f(g(x)) + f(g(y)) = (f \circ g)(x) + (f \circ g)(y)Unfortunately, composition is not compatible with scalars (&lt;i&gt;i.e.&lt;/i&gt;, \((\alpha\cdot f)\circ(\beta\cdot g)\neq (\alpha\cdot\beta)\cdot(f\circ g)\)), and additive functions are not an &lt;a href=&quot;http://en.wikipedia.org/wiki/Algebra_over_a_field&quot;&gt;algebra over a field&lt;/a&gt; \(\R\), but see below.Looking at an individual additive function \(f : \R \rightarrow \R\), it&amp;#x27;s easy to see that even it is not clear that it must be linear everywhere, there are some subsets of \(\R\) on which is obviously has to be linear:For any real number \(x\) and for any natural number \(n\),f(n\cdot x) = f(x + \cdots x) = f(x) + \cdots + f(x) = n\cdot f(x)that is, restriction of \(f\) to any subset \(x \cdot \N \subset \R\) is linear and in particular, \(f\) is linear when restricted to the natural numbers. Specifically, \(f(0) = f(2\cdot 0) = 2\cdot f(0) = 0\), from thisf(-x) = f(-x) + f(x) - f(x) = f(-x + x) - f(x) = f(0) - f(x) = 0 - f(x) = -f(x)Similarly,f(\frac{1}{n}\cdot x) = \frac{1}{n}\cdot n\cdot f(\frac{1}{n}\cdot x) = \frac{1}{n}\cdot f(n\cdot \frac{1}{n}\cdot x) = \frac{1}{n}\cdot f(x)Combining these results, for any rational number \(q = \frac{n}{m} \in \Q\),f(q\cdot x) = f(\frac{n}{m}\cdot x) = n\cdot f(\frac{1}{m}\cdot x) = \frac{n}{m}\cdot f(x) = q\cdot f(x)That is, \(f\) is linear when restricted to any subset of the form \(x \cdot \Q \subset \R\). We shall call such subset &lt;i&gt;a \(\Q\)-set&lt;/i&gt;.Notice that we just proved that composition of linear functions is compatible with multiplication on rational scalars (see above), so that \(\Add\) is an algebra over \(\Q\).Having briefly looked over the landscape of \(\Add\), let&amp;#x27;s start converging on our prey. How bad a monster function must be?  A linear function has all the good qualities one might wish for: it is &lt;a href=&quot;http://en.wikipedia.org/wiki/Monotonic_function&quot;&gt;monotonic&lt;/a&gt;, &lt;a href=&quot;http://en.wikipedia.org/wiki/Continuous_function&quot;&gt;continuous&lt;/a&gt;, &lt;a href=&quot;http://en.wikipedia.org/wiki/Differentiable_function&quot;&gt;differentiable&lt;/a&gt;, &lt;a href=&quot;http://en.wikipedia.org/wiki/Smooth_function&quot;&gt;smooth&lt;/a&gt;, it&amp;#x27;s even... linear. Which of these it enjoys together with a monster? It&amp;#x27;s intuitively very unlikely that an additive, but non-linearfunction might happen to be &lt;a href=&quot;http://en.wikipedia.org/wiki/Differentiable_function&quot;&gt;differentiable&lt;/a&gt;, so let&amp;#x27;s start with checking continuity.&lt;i&gt;Statement 0&lt;/i&gt;. If an additive function \(f : \R \rightarrow \R\) is continuous at point \(x\), then \(f(x) = x \cdot f(1)\).Indeed,\begin{array}{r@{\;}c@{\;}l@{\quad}}
  f(x)                                  &amp;amp;\;=\;&amp;amp; \text{take a sequence of rationals converging to \(x\)} \\
  f(\displaystyle\lim_{n\to\infty, q_n\in\Q}q_n)     &amp;amp;\;=\;&amp;amp; \text{by definition of continuity} \\
  \displaystyle\lim_{q_n}f(q_n)                      &amp;amp;\;=\;&amp;amp; \text{by linearity on rationals} \\
  \displaystyle\lim_{q_n}(q_n\cdot f(1))             &amp;amp;\;=\;&amp;amp; \text{by property of limits} \\
  (\displaystyle\lim_{q_n}q_n)\cdot f(1)             &amp;amp;\;=\;&amp;amp; \text{by definition of \(q_n\)} \\
  f(x)\cdot 1                           &amp;amp;     &amp;amp; 
\end{array}That is, an additive function is linear everywhere it is continuous.  This means that a monster must be discontinuous at least in one point. Note that linear functions are precisely everywhere continuous additive functions. Can a monster function be discontinuous in a single point? Or, even, can it be continuous &lt;i&gt;somewhere&lt;/i&gt;? It is easy to show that property of additivity constrains structure of sets on which function is continuous severely:&lt;i&gt;Statement 1&lt;/i&gt;. If an additive function \(f : \R \rightarrow \R\) is continuous  at point \(x\), it is linear.Take an arbitrary non-zero point \(y\). By statement 0, \(f(x) = x \cdot f(1)\). By definition of continuity at \(x\),\forall \epsilon &amp;gt; 0 \to \exists \delta &amp;gt; 0 : \forall x&amp;#x27; : |x&amp;#x27; - x| &amp;lt; \delta \to |f(x&amp;#x27;) - f(x)| &amp;lt; \epsilonFor any natural \(n\), take \(\epsilon = \frac{1}{n} &amp;gt; 0\) and find a rational number \(q_n\), such that \(|q_n\cdot y - x| &amp;lt; \min(\delta, \frac{1}{n})\). Such \(q_n\) always exists due to density of rationals. By choice of \(q_n\) we have:-\frac{1}{n} &amp;lt; q_n\cdot y - x &amp;lt; \frac{1}{n}and by the &lt;a href=&quot;http://en.wikipedia.org/wiki/Squeeze_theorem&quot;&gt;sandwich theorem&lt;/a&gt;, \(q_n\) converges: \(\displaystyle\lim_{n\to\infty}q_n = \frac{x}{y}\). Now, again, by choice of \(q_n\): \(|q_n\cdot y - x| &amp;lt; \delta\), so \(y\cdot q_n\) satisfies the condition on \(x&amp;#x27;\) above and\epsilon = \frac{1}{n} &amp;gt; |f(q_n \cdot y) - f(x)| = |q_n \cdot f(y) - x \cdot f(1)|Taking the (obviously existing) limits of both sides of this inequality, one getsf(y) = \frac{x \cdot f(1)}{\displaystyle\lim_{n\to\infty}q_n} = \frac{x \cdot f(1)}{x/y} = y \cdot f(1)The case of y being 0 is trivial.Oh. A monster function cannot be continuous even at a single point—it is discontinuous everywhere. Additive functions are divided into two separated classes: nice, everywhere continuous linear functions and unseemly, everywhere discontinuous monsters. (We still don&amp;#x27;t know whether the latter class is populated, though.) Our expectations of capturing a monster and placing a trophy in a hall must be adjusted: even if we prove that a monster exists and construct it, an idea of drawing its &lt;a href=&quot;http://en.wikipedia.org/wiki/Graph_of_a_function&quot;&gt;graph&lt;/a&gt; must be abandoned—it&amp;#x27;s too ugly to be depicted.&lt;span class=&quot;linktarget&quot; data-uid=&quot;1&quot;&gt;L&lt;/span&gt;et&amp;#x27;s think for a moment how a monster might look like. Every additive function is linear on any \(\Q\)-set. If it is linear with the same slope on all \(\Q\)-sets—it is linear. A monster must have different slopes for at least some of \(\Q\)-sets. In the simplest case there is a single \(\Q\)-set with a slope different from the others. There is a famous function (a freshman nightmare and examiner delight) immediately coming into a mind: the &lt;a href=&quot;http://en.wikipedia.org/wiki/Nowhere_continuous_function&quot;&gt;Dirichlet function&lt;/a&gt;, \(D : \R \rightarrow \mathbb{Z_2}\), equal \(1\) on rationals and \(0\) on irrationals. The function \(d : x \mapsto x \cdot D(x)\) is identity (and hence linear) when restricted to rationals and is constant zero (again linear) when restricted to irrationals. Looks promising? Unfortunately,0 = d(1 + \pi) \neq d(1) + d(\pi) = 1 + 0 = 1Also, \(d\) is continuous at \(0\) and thus disqualified from monstrousness by statement 1. This shot into darkness missed. At at least we now see that not only monster must have different slopes at different \(\Q\)-sets, but these slopes must be selected to be consistent with addition.Let&amp;#x27;s return to monster properties. A monster function is discontinuous everywhere, but how badly is it discontinuous? E.g., a function is &lt;a href=&quot;http://en.wikipedia.org/wiki/Local_boundedness&quot;&gt;locally bounded&lt;/a&gt; at every point where it is continuous. A monster is continuous nowhere, but is it still locally bounded anywhere or somewhere? In a way similar to statement 1 it&amp;#x27;s easy to prove the&lt;i&gt;Statement 2&lt;/i&gt;. If an additive function \(f : \R \rightarrow \R\) is bounded on  any segment \([a, b]\), \(a &amp;lt; b\), then it is linear.First, by using that \(f(-x) = -f(x)\), and restricting segment if necessary,  one can assume that \(0 &amp;lt; a &amp;lt; b\), and \(\forall x\in[a, b] \to |f(x)| &amp;lt; C\)Let&amp;#x27;s prove that \(f\) is continuous at \(0\), then it will be linear by the  statement 1. For arbitrary \(\epsilon &amp;gt; 0\), let&amp;#x27;s select \(\delta\), such that  \(0 &amp;lt; \delta &amp;lt; \frac{a}{C}\cdot\epsilon\) (this choice is a typical magician hat  trick of \(\epsilon-\delta\) proofs). For arbitrary \(x\) from the  \(\delta\)-vicinity of \(0\) there is always a rational \(q\), such that \(a &amp;lt;  q\cdot x &amp;lt; b\). For such \(q\) we have:|q| &amp;gt; \frac{a}{|x|} &amp;gt; \frac{a}{\delta} &amp;gt; \frac{a}{a}\cdot\frac{C}{\epsilon} = \frac{C}{\epsilon}on the other hand, we have:\begin{array}{r@{\;}c@{\;}l@{\quad}}
  |f(x)|                                &amp;amp;\;=\;&amp;amp; \\
  |f(\frac{q\cdot x}{q})|               &amp;amp;\;=\;&amp;amp; \text{by linearity on rationals} \\
  \frac{1}{|q|}\cdot|f(q\cdot x)|       &amp;amp;\;&amp;lt;\;&amp;amp; \text{by boundness} \\
  \frac{1}{|q|}\cdot C                  &amp;amp;\;=\;&amp;amp; \text{by inequality on \(q\)} \\
  \frac{\epsilon\cdot C}{C}             &amp;amp;\;=\;&amp;amp; \epsilon
\end{array}establishing that \(f\) is continuous at 0.This indicates that a monster is not just a bad function, it&amp;#x27;s a very bad function, that takes arbitrarily large absolute values in arbitrarily small segments. Too bad. As a byproduct, a monster cannot be monotonic on any segment, because a function monotonic on \([a, b]\) is bounded there: \(f(a) \leq f(x) \leq f(b)\) (for increasing function, similarly for decreasing).Continued &lt;a href=&quot;hunt.2.html#hunt.2-start&quot;&gt;here&lt;/a&gt;.</content>
        </item>

        <item>
            <title>The Hunt for Addi(c)tive Monster 2.</title>
            <id>hunt.2</id>
            <link>https://cofault.com/hunt.2.html#hunt.2</link>
            <pubDate>2010/02/04</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/hunt.2.html#hunt.2">
                     &lt;span class=&quot;linktarget&quot; data-uid=&quot;3&quot;&gt;I&lt;/span&gt;n the &lt;a href=&quot;hunt.1.html#hunt.1-start&quot;&gt;previous post&lt;/a&gt;, we were looking for &lt;i&gt;a monster&lt;/i&gt;—a nonlinear additive function. We found that such a function is extremely pathological: it is nowhere locally monotone, nowhere continuous and nowhere locally bounded. Worse than that, it&amp;#x27;s easy to prove that the graph of a monster is &lt;a href=&quot;http://en.wikipedia.org/wiki/Dense_set&quot;&gt;dense&lt;/a&gt; in \(\R \times \R\), that is, for every \(x\) and \(y\), an arbitrary neighborhood of \(x\) contains a point that monster sends arbitrarily close to \(y\).Recall &lt;a href=&quot;hunt.1.html#hunt.1-attempt&quot;&gt;our attempt&lt;/a&gt; to construct a monster. Any additive function is linear on any \(\Q\)-set and is fully determined on this set by a value it has in any single of its points. Our Direchlet function derived monster failed (or rather fell) because the slopes an additive function has on different \(\Q\)-sets are not independent. Indeed, given that \(f\) has a slope \(k_1\) on a \(\Q\)-set \(\Q\cdot\alpha_1\) and a slope \(k_2\) on a \(\Q\)-set \(\Q\cdot\alpha_2\), it has to have a slope \(k_1 + k_2\) on a \(\Q\)-set \(\Q\cdot(\alpha_1 + \alpha_2)\). This shows a way to construct a monster: one has to find a collection \(B\) of real numbers \(r_1, r_2, \ldots\) such that (i) every real number can be represented as a sum \(q_1\cdot r_1 + q_2\cdot r_2 + \ldots\), with rational coefficients \(q_1, q_2, \ldots\) of which only finite number is non-zero (so that the sum is defined) and (ii) that such representation is unique. Then one can select arbitrary values on elements of \(B\) and take moster&amp;#x27;s value on \(q_1\cdot r_1 + q_2\cdot r_2 + \ldots\) to be \(q_1\cdot f(r_1) + q_2\cdot f(r_2) + \ldots\), which is well-defined thanks to (ii).Looks familiar? It should be: the definition of \(B\) is exactly the definition of &lt;a href=&quot;http://en.wikipedia.org/wiki/Basis_(linear_algebra)&quot;&gt;a basis&lt;/a&gt; of a vector space. Real numbers can be added to each other and multiplied by rationals and, therefore, form a vector space over \(\Q\). This space is very different from a usual one-dimensional vector space real numbers form over \(\R\) (&lt;i&gt;i.e.&lt;/i&gt;, over themselves).After a streak of bad and unlikely properties that a monster has, we now got something positive: a monster exists if and only if \(\R\) as a vector space over \(\Q\) has a basis. Does it?But of course. Any vector space has a basis—this is a general theorem almost immediately following from the &lt;a href=&quot;http://en.wikipedia.org/wiki/Zorn&#x27;s_lemma&quot;&gt;Zorn&amp;#x27;s lemma&lt;/a&gt;. The basis we are looking for even got a name of its own: &lt;a href=&quot;http://mathworld.wolfram.com/HamelBasis.html&quot;&gt;&lt;i&gt;Hamel basis&lt;/i&gt;&lt;/a&gt;.At last we stumbled across the whole family on monsters. Specifically, there exists a set \(B \subset \mathbb{R}\) and a function \(q : \mathbb{R}\times B \rightarrow \Q\) such that every real number r can be uniquely represented asr = \displaystyle\sum_{b\in B}q(r, b)\cdot bwhere only finite number of \(q(r, b)\) are non-zero for a given \(r\). From this it immediately follows that \(q(r_1 + r_2, b) = q(r_1, b) + q(r_2, b)\).Take an arbitrary function \(f_0 : B \rightarrow \mathbb{R}\), and definef(r) = \displaystyle\sum_{b\in B} f_0(b)\cdot q(r, b)\cdot b\begin{array}{r@{\;}c@{\;}l@{\quad}}
        f(r_1) + f(r_2) &amp;amp;\;=\;&amp;amp; \\
                        &amp;amp;\;=\;&amp;amp; \displaystyle\sum_{b\in B} f_0(b)\cdot q(r_1, b)\cdot b + \displaystyle\sum_{b\in B} f_0(b)\cdot q(r_2, b)\cdot b \\
                        &amp;amp;\;=\;&amp;amp; \displaystyle\sum_{b\in B} f_0(b)\cdot\left(q(r_1, b) + q(r_2, b)\right)\cdot b \\
                        &amp;amp;\;=\;&amp;amp; \displaystyle\sum_{b\in B} f_0(b)\cdot q(r_1 + r_2, b) \cdot b \\
                        &amp;amp;\;=\;&amp;amp; f(r_1 + r_2)
\end{array}that is, \(f\) is additive. Intuitively, \(f_0(b)\) is a slope \(f\) has at the \(\Q\)-set \(\Q\cdot b\). \(f\) is linear if and only if \(f_0\) is a constant function, in all other cases \(f\) is a monster. If one takes \(f_0 : b \mapsto 1/b\), thenf(r) = \displaystyle\sum_{b\in B} q(r, b)is an especially weird monster function: it takes only rational values!Note that almost all additive functions are, after all, monsters—only very small sub-set of them is linear.</content>
        </item>

        <item>
            <title>Inaccessible Cardinals</title>
            <id>inaccessible-cardinals</id>
            <link>https://cofault.com/inaccessible-cardinals.html#inaccessible-cardinals</link>
            <pubDate>2005/04/12</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/inaccessible-cardinals.html#inaccessible-cardinals">
                     &lt;span class=&quot;align-right&quot;&gt;„On the Consistency of Choice for Strongly Inaccessible Cardinals.“&lt;/span&gt;&lt;span class=&quot;align-right&quot;&gt;„О непротиворечивости выбора сильно недостижимых кардиналов.“&lt;/span&gt;In this from &lt;a href=&quot;http://cnn.com/2005/WORLD/europe/04/09/pope.main/index.html&quot;&gt;&lt;span class=&quot;annotation&quot; data-uid=&quot;0&quot;&gt;CNN&lt;/span&gt;&lt;/a&gt; or from Seminaire Bourbaki Novembre 1974 56eme annee?</content>
        </item>

        <item>
            <title>inactive_dirty and inactive_clean are considered harmful</title>
            <id>inactive-dirty</id>
            <link>https://cofault.com/inactive-dirty.html#inactive-dirty</link>
            <pubDate>2005/07/25</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/inactive-dirty.html#inactive-dirty">
                     Found interesting discussion on linux-mm (Sept. 2002):AKPM and Rik (&amp;quot;inactive_dirty list&amp;quot;)[AKPM proposed separate inactive_dirty and inactive_clean lists to avoid excessive scanning of pages that cannot be reclaimed (due to then-new non-blocking VM scanner]:    Riel:
    &amp;gt; AKPM:
    &amp;gt; &amp;gt; - inactive_dirty holds pages which are dirty or under writeback.
    &amp;gt; 
    &amp;gt; &amp;gt; - everywhere where we add a page to the inactive list will now
    &amp;gt; &amp;gt;   add it to either inactive_clean or inactive_dirty, based on
    &amp;gt; &amp;gt;   its PageDirty || PageWriteback state.
    &amp;gt; 
    &amp;gt; If I had veto power I&amp;#x27;d use it here ;)
    &amp;gt; 
    &amp;gt; We did this in early 2.4 kernels and it was a disaster. The
    &amp;gt; reason it was a disaster was that in many workloads we&amp;#x27;d
    &amp;gt; always have some clean pages and we&amp;#x27;d end up always reclaiming
    &amp;gt; those before even starting writeout on any of the dirty pages.
    &amp;gt; 
    &amp;gt; It also meant we could have dirty (or formerly dirty) inactive
    &amp;gt; pages eating up memory and never being recycled for more active
    &amp;gt; data.And later in the same thread:    AKPM:
    &amp;gt; You&amp;#x27;re proposing that we get that IO underway sooner if there
    &amp;gt; is page reclaim pressure, and that one way to do that is to
    &amp;gt; write one page for every reclaimed one.  Guess that makes
    &amp;gt; sense as much as anything else ;)(decrease dirty cache balancing rules when hitting memory pressure, so that &lt;code class=&quot;inline&quot;&gt;balance_dirty_pages()&lt;/code&gt; and pdflush do write-out in scanner&amp;#x27;s stead)And further more:    Daniel Phillips
    &amp;gt; On Saturday 07 September 2002 01:34, Andrew Morton wrote:
    &amp;gt; &amp;gt; You&amp;#x27;re proposing that we get that IO underway sooner if there
    &amp;gt; &amp;gt; is page reclaim pressure, and that one way to do that is to
    &amp;gt; &amp;gt; write one page for every reclaimed one.  Guess that makes
    &amp;gt; &amp;gt; sense as much as anything else ;)
    &amp;gt; 
    &amp;gt; Not really.  The correct formula will incorporate the allocation rate
    &amp;gt; and the inactive dirty/clean balance.  The reclaim rate is not
    &amp;gt; relevant, it is a time-delayed consequence of the above.  Relying on
    &amp;gt; it in a control loop is simply asking for oscillation.</content>
        </item>

        <item>
            <title>Unexpected isomorphism.</title>
            <id>iso</id>
            <link>https://cofault.com/iso.html#iso</link>
            <pubDate>2020/10/15</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/iso.html#iso">
                     &lt;span class=&quot;linktarget&quot; data-uid=&quot;4&quot;&gt;S&lt;/span&gt;ince Cantor&amp;#x27;s &amp;quot;I see it, but I cannot believe it&amp;quot; (1877), we know that \(\mathbb{R}^n\) are isomorphic sets for all \(n &amp;gt; 0\). This being as shocking as it is, over time we learn to live with it, because the bijections between continua of different dimensions are extremely discontinuous and we assume that if we limit ourselves to any reasonably well-behaving class of maps the isomorphisms will disappear. Will they?&lt;i&gt;Theorem&lt;/i&gt;. Additive groups \(\mathbb{R}^n\) are isomorphic for all \(n &amp;gt;0\)  (and, therefore, isomorphic to the additive group of the complex numbers).&lt;i&gt;Proof&lt;/i&gt;. Each \(\mathbb{R}^n\) is a vector space over rationals. Assuming axiom  of choice, any vector space has a basis. By simple cardinality considerations,  the cardinality of a basis of \(\mathbb{R}^n\) over \(\mathbb{Q}\) is the same  as cardinality of \(\mathbb{R}^n\). Therefore all \(\mathbb{R}^n\) have the  same dimension over \(\mathbb{Q}\), and, therefore, are isomorphic as vector  spaces and as additive groups. &lt;i&gt;End of proof&lt;/i&gt;.This means that for any \(n, m &amp;gt; 0\) there are bijections \(f : \mathbb{R}^n \to \mathbb{R}^m\) such that \(f(a + b) = f(a) + f(b)\) and, necessary, \(f(p\cdot a + q\cdot b) = p\cdot f(a) + q\cdot f(b)\) for all rational \(p\) and \(q\).I feel that this should be highly counter-intuitive for anybody who internalised the Cantor result, or, maybe, especially to such people. The reason is that intuitively there are many more continuous maps than algebraic homomorphisms between the &amp;quot;same&amp;quot; pair of objects. Indeed, the formula defining continuity has the form \(\forall x\forall\epsilon\exists\delta\forall y P(x, \epsilon, \delta, y)\) (a local property), while homomorphisms are defined by \(\forall x\forall y Q(x, y)\) (a stronger global property). Because of this, topological categories have much denser lattices of sub- and quotient-objects than algebraic ones. From this one would expect that as there are no isomorphisms (continuous bijections) between continua of different dimensions, there definitely should be no homomorphisms between them. Yet there they are.</content>
        </item>

        <item>
            <title>Ineluctable modality of the past, indeed.</title>
            <id>keyring</id>
            <link>https://cofault.com/keyring.html#keyring</link>
            <pubDate>2025/05/31</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/keyring.html#keyring">
                     A lot of history in GPG keyrings...$ gpg -k

...

pub   dsa1024 2003-08-08 [SCA]
      5E69659A734629663FBF04EB166C3B2362DBF2F4
uid           [ unknown] &lt;a href=&quot;https://en.wikipedia.org/wiki/Hans_Reiser&quot;&gt;Hans Reiser&lt;/a&gt; (created on laptop) &amp;lt;reiser@namesys.com&amp;gt;
sub   elg2048 2003-08-08 [E]

pub   dsa1024 2003-12-01 [SCA]
      86EFEB4D2AB605B5E3549F69A3F4319719FEDF80
uid           [ unknown] &lt;a href=&quot;https://www.cbsnews.com/news/betrayal-29-12-2008/&quot;&gt;Nina Reiser&lt;/a&gt; &amp;lt;ninasha@namesys.com&amp;gt;
sub   elg2048 2003-12-01 [E]</content>
        </item>

        <item>
            <title>360 years later or „Скрещенья ног“</title>
            <id>later-360</id>
            <link>https://cofault.com/later-360.html#later-360</link>
            <pubDate>2021/02/13</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/later-360.html#later-360">
                     In 1896 &lt;a href=&quot;https://en.wikipedia.org/wiki/Paul_Gauguin&quot;&gt;Paul Gauguin&lt;/a&gt; completed &lt;a href=&quot;https://fineartamerica.com/featured/te-arii-vahine-the-king-s-wife-paul-gauguin.html&quot;&gt;&lt;i&gt;Te Arii Vahine&lt;/i&gt;&lt;/a&gt; (&lt;i&gt;The King’s Wife&lt;/i&gt;):From many similar paintings of his Tahitian period this, together with a couple of preparatory watercolours, is distinguished by an artificial legs placement, which can be characterised in Russian by the equally forced line (quoted in this article&amp;#x27;s title) from a certain universally acclaimed poem. This strange posture is neither a deficiency nor an artistic whim. It is part of a silent, subtle game played over centuries, where the moves are echoes and the reward—some flickering form of immortality:This is &lt;a href=&quot;https://www.meisterdrucke.uk/fine-art-prints/Lucas-Cranach-the-Elder/84728/Diana-Resting,-or-The-Nymph-of-the-Fountain,-1537-.html&quot;&gt;&lt;i&gt;Diana Resting&lt;/i&gt;&lt;/a&gt;, by &lt;a href=&quot;https://en.wikipedia.org/wiki/Lucas_Cranach_the_Elder&quot;&gt;Cranach the Elder&lt;/a&gt;, 1537. Let me just note the birds and leave the pleasure of finding other clues to the reader. Lucas Cranach (and this is more widely known) himself played a very similar game with &lt;a href=&quot;https://en.wikipedia.org/wiki/Albrecht_D%C3%BCrer&quot;&gt;Dürer&lt;/a&gt;.By &lt;span class=&quot;annotation&quot; data-uid=&quot;3&quot;&gt;sheer luck&lt;/span&gt;, the first painting is just few kilometers away from me in Pushkin&amp;#x27;s museum.</content>
        </item>

        <item>
            <title>Leisure pace of progress</title>
            <id>leisure</id>
            <link>https://cofault.com/leisure.html#leisure</link>
            <pubDate>2007/08/08</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/leisure.html#leisure">
                     Recently I found a paper in &lt;a href=&quot;http://acm.org&quot;&gt;ACM Library&lt;/a&gt; describing two distributed file systems with the following features:distributed read-write locking at the byte granularity;user visible distributed transactions with isolation and roll-back;capability based authentication;files implemented as B-trees;distributed garbage collection of unreferenced objects;atomicity through COW (aka &lt;i&gt;shadow writes&lt;/i&gt;, aka &lt;i&gt;wandering logs&lt;/i&gt;);intent logging of file system updates (hello, &lt;a href=&quot;http://en.wikipedia.org/wiki/Zfs&quot;&gt;ZFS&lt;/a&gt;);storage failure resilience methods, similar to ones in &lt;a href=&quot;http://marc.info/?l=linux-fsdevel&amp;amp;m=117779868908188&amp;amp;w=2&quot;&gt;TileFS&lt;/a&gt;;directories implemented as separate service, using the same interface as usual clients.Quite impressive and obviously matched by nothing publicly available currently. How it happened that these marvels are not trumpeted about on every corner? Very simple: these systems were put in production &lt;i&gt;before 1981&lt;/i&gt;. AD, that is. Funny enough, one of them is even named &lt;a href=&quot;http://clusterfs.com&quot;&gt;CFS&lt;/a&gt;.[0] James G. Mitchell, Jeremy Dion &lt;a href=&quot;http://portal.acm.org/citation.cfm?id=358475&amp;amp;dl=ACM&amp;amp;coll=portal&quot;&gt;&lt;i&gt;A comparison of two network-based file servers&lt;/i&gt;&lt;/a&gt;[1] Jeremy Dion &lt;a href=&quot;http://portal.acm.org/citation.cfm?id=850710&amp;amp;dl=ACM&amp;amp;coll=portal&quot;&gt;&lt;i&gt;The Cambridge File Server&lt;/i&gt;&lt;/a&gt;</content>
        </item>

        <item>
            <title>A bit of out-of-context quoting</title>
            <id>lessons</id>
            <link>https://cofault.com/lessons.html#lessons</link>
            <pubDate>2006/01/11</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/lessons.html#lessons">
                     &lt;a href=&quot;http://blogs.sun.com/roller/resources/esaxe/recruiting-preso-v2.pdf&quot;&gt;&lt;span class=&quot;annotation&quot; data-uid=&quot;0&quot;&gt;Lessons Learned&lt;/span&gt;&lt;/a&gt;Solaris has been functioning, essentially, by accident, for over one year.&lt;i&gt;We realize this again and again, every so often...&lt;/i&gt;It is amazing that anything works at allIt&amp;#x27;s all broken...</content>
        </item>

        <item>
            <title>limit and evaluation</title>
            <id>limit-eval</id>
            <link>https://cofault.com/limit-eval.html#limit-eval</link>
            <pubDate>2005/07/24</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/limit-eval.html#limit-eval">
                     Let \(D\) be a category with functorial limits of functors from some category \(C\). That is, there is a functor\lim : \Cat(C, D) \to D.For each object \(x\) from \(C\), there is a functorev_x : \Cat(C, D) \to D,sending a functor \(F : C \to D\) to \(F(x)\), and sending a natural transformation \(r : F \to G : C \to D\) to its component at \(x\) (\(r_x : F(x) \to G(x)\)). By mapping \(x\) to \(ev_x\) and morphism \(f : x \to y\) to an obvious natural transformation from \(ev_x\) to \(ev_y\) we obtain a functor \(\EV : C \to \Cat(\Cat(C, D), D)\).Amusing and trivially checkable fact is that \(\lim = \Lim \EV\). That is, limits are &lt;i&gt;always&lt;/i&gt; &lt;span class=&quot;annotation&quot; data-uid=&quot;5&quot;&gt;point-wise&lt;/span&gt;.</content>
        </item>

        <item>
            <title>Publish or Perish in style.</title>
            <id>liouville</id>
            <link>https://cofault.com/liouville.html#liouville</link>
            <pubDate>2025/03/03</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/liouville.html#liouville">
                     &lt;a href=&quot;https://en.wikipedia.org/wiki/Joseph_Liouville&quot;&gt;Joseph Liouville&lt;/a&gt;, a famous French mathematician, whom multiple important theorems are named after, was also the founder and the editor of &lt;a href=&quot;https://en.wikipedia.org/wiki/Journal_de_Math%C3%A9matiques_Pures_et_Appliqu%C3%A9es&quot;&gt;&lt;i&gt;Journal de Mathématiques Pures et Appliquées&lt;/i&gt;&lt;/a&gt;, universally known as &lt;i&gt;Liouville&amp;#x27;s journal&lt;/i&gt; (still in print, still very prestigious, two centuries later!).Here is the list of the articles Liouville published in his own journal in 1861:And then some more:... and more ......Look somewhat... similar don&amp;#x27;t they? The truth is, Liouville proved a certain general result about quadratic forms, but chose to keep it secret. Instead, he published almost &lt;i&gt;two hundred&lt;/i&gt; papers with special cases, easily obtainable from his general theorem, but rather mysterious otherwise.This was the bulk of his scientific output in the early 1860s.References[0] Lützen, Jesper, Joseph Liouville, 1809-1882: Master of Pure and Applied Mathematics. Springer New York, 1990.</content>
        </item>

        <item>
            <title>Long [story of] division.</title>
            <id>division</id>
            <link>https://cofault.com/division.html#division</link>
            <pubDate>2025/02/25</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/division.html#division">
                     The following text can be viewed as extremely dry and intimidating, or, equally, lightheadedly funny.Let&amp;#x27;s formally verify the venerable long-division algorithm.uintN_t div(uintN_t n, uintN_t d) {
        uintN_t q := 0;
        uintN_t r := 0;
        int     i := N - 1;
        while (i != -1) {
                r &amp;lt;&amp;lt;= 1;
                r |= ((n &amp;gt;&amp;gt; i) &amp;amp; 1);
                if (r &amp;gt;= d) {
                        r := r - d;
                        q |= 1 &amp;lt;&amp;lt; i;
                }
                i := i - 1;
        }
        return q;
}Here &lt;code class=&quot;inline&quot;&gt;uintN_t&lt;/code&gt; is the type of unsigned &lt;code class=&quot;inline&quot;&gt;N&lt;/code&gt;-bit integers, &lt;code class=&quot;inline&quot;&gt;N &amp;gt; 0&lt;/code&gt;.We shall establish formal correctness via &lt;a href=&quot;https://en.wikipedia.org/wiki/Hoare_logic&quot;&gt;Hoare logic&lt;/a&gt;. The following is by no means an introduction to the subject, our presentation skims over a large number of important details, please refer to the literature cited on the Wikipedia page. The basic element of &lt;a href=&quot;https://en.wikipedia.org/wiki/Hoare_logic&quot;&gt;Hoare logic&lt;/a&gt; is a &lt;i&gt;Hoare triple&lt;/i&gt;, which is a construction of the form⟦ precondition ⟧
COMMAND
⟦ postcondition ⟧This triple means that if an execution of &lt;code class=&quot;inline&quot;&gt;COMMAND&lt;/code&gt; starts in a state satisfying &lt;code class=&quot;inline&quot;&gt;precondition&lt;/code&gt;, then the execution can only terminate in a state satisfying &lt;code class=&quot;inline&quot;&gt;postcondition&lt;/code&gt;. (We use &lt;b&gt;⟦&lt;/b&gt; and &lt;b&gt;⟧&lt;/b&gt; instead of more traditional { and }, because our ambient language uses braces.) The pre- and postconditions are formulae of predicate calculus that can refer to the terms of the programming language (variables, literals, &lt;i&gt;etc&lt;/i&gt;.). A triple is valid, if it can be proved starting from the usual rules of the predicate calculus and certain axioms. For a given programming language, one presents a list of axioms, describing the behaviour of the language constructs, and then proves &lt;a href=&quot;https://en.wikipedia.org/wiki/Soundness&quot;&gt;&lt;i&gt;soundness&lt;/i&gt;&lt;/a&gt;, &lt;i&gt;i.e.&lt;/i&gt;, establishes that the axioms and the accepted rules of inference are satisfied by all possible computations. We will need the following axioms:Axiom of assignment⟦ S[ x := E ] ⟧
x := E
⟦ S ⟧Here &lt;code class=&quot;inline&quot;&gt;S[ x:= E ]&lt;/code&gt; is the result of substituting &lt;code class=&quot;inline&quot;&gt;E&lt;/code&gt; for each occurrence of &lt;code class=&quot;inline&quot;&gt;x&lt;/code&gt; in the formula &lt;code class=&quot;inline&quot;&gt;S&lt;/code&gt;. (In this form the axiom really only works for simple unaliased variables and does not work for pointers or arrays, which is sufficient in our case.) The axiom looks &amp;quot;backward&amp;quot;, so let&amp;#x27;s play with it a bit. First, check that the assignment does set the variable to the desired value:⟦ ? ⟧
x := 4
⟦ x == 4 ⟧The command is a simple assignment &lt;code class=&quot;inline&quot;&gt;x := 4&lt;/code&gt;, the postcondition, &lt;code class=&quot;inline&quot;&gt;x == 4&lt;/code&gt;, verifies that the variable got the expected value. What precondition guarantees that the assignment establishes the postcondition? The assignment axiom gives us for the precondition &lt;code class=&quot;inline&quot;&gt;(x == 4)[ x := 4 ] = (4 == 4) = true&lt;/code&gt;. That is, no matter what was going on before the assignment, after it terminates, &lt;code class=&quot;inline&quot;&gt;x == 4&lt;/code&gt;, as expected:⟦ true ⟧
x := 4
⟦ x == 4 ⟧A bit more complex example:⟦ ? ⟧
x := x + 1
⟦ x &amp;gt; 0 ⟧What precondition guarantees that &lt;code class=&quot;inline&quot;&gt;x&lt;/code&gt; will be positive after increment? We can compute the precondition, it is &lt;code class=&quot;inline&quot;&gt;(x &amp;gt; 0)[ x := x + 1 ] = (x + 1 &amp;gt; 0) = (x &amp;gt; -1)&lt;/code&gt; — perfectly reasonable.What if we are given a precondition does not have the form that the axiom requires?⟦ x == A ⟧
x := x + d
⟦ ? ⟧There is no postcondition &lt;code class=&quot;inline&quot;&gt;S&lt;/code&gt;, such that &lt;code class=&quot;inline&quot;&gt;(x == A) = S[ x := x + d ]&lt;/code&gt;Well, in this case you are stuck. To derive a postcondition using the axiom of assignment, you first have to massage the precondition in a form, where &lt;code class=&quot;inline&quot;&gt;x&lt;/code&gt; only happens as part of &lt;code class=&quot;inline&quot;&gt;E&lt;/code&gt;. Fortunately in this case it&amp;#x27;s easy:/* Comments as in PL/I. */
⟦ x == A ⟧
/* Simple arithmetics: add d to both sides. */
⟦ x + d == A + d ⟧
x := x + d
⟦ x == A + d ⟧What if the precondition does not contain &lt;code class=&quot;inline&quot;&gt;x&lt;/code&gt;? Then the assignment is useless for program correctness, and, hence, can be most likely discarded. :-)Typically, when you use the assignment axiom for a formal verification, you have to come up with a precondition, that has one or more instances of &lt;code class=&quot;inline&quot;&gt;E&lt;/code&gt; and then the axiom let&amp;#x27;s you to jump to a postcondition where each &lt;code class=&quot;inline&quot;&gt;E&lt;/code&gt; is simplified to &lt;code class=&quot;inline&quot;&gt;x&lt;/code&gt;.Next isAxiom of compositionThis axiom describes the &lt;code class=&quot;inline&quot;&gt;;&lt;/code&gt;-sequencing operator. If we have⟦ precondition ⟧
COMMAND0
⟦ condition ⟧and⟦ condition ⟧
COMMAND1
⟦ postcondition ⟧Then the axiom allows us to conclude⟦ precondition ⟧
COMMAND0 ; COMMAND1
⟦ postcondition ⟧This matches the expected semantics of sequential execution.Conditional axiomFor a conditional statement of a formif (guard) { 
        COMMAND0 
} else {
        COMMAND1 
}We have⟦ precondition ⟧
if (guard) {
        ⟦ guard &amp;amp;&amp;amp; precondition ⟧
        COMMAND0;
        ⟦ postcondition ⟧
} else {
        ⟦ !guard &amp;amp;&amp;amp; precondition ⟧
        COMMAND0;
        ⟦ postcondition ⟧
}
⟦ postcondition ⟧That is, if both &amp;quot;then&amp;quot; and &amp;quot;else&amp;quot; commands establish the same postcondition, given the original precondition strengthened by the guard or its negation, then the entire conditional statement establishes the same postcondition. This is fairly intuitively obvious.Finally, we needWhile-loop axiomConsider a loopwhile (guard) {
        BODY
}To apply the while-loop axiom, we have to find an assertion, called &lt;i&gt;a loop invariant&lt;/i&gt; that is preserved by the loop body, that is such that⟦ guard &amp;amp;&amp;amp; invariant ⟧
BODY
⟦ invariant ⟧If the body is entered, while the invariant holds (and the guard holds too), then the invariant is true at the end of the body execution. Given an invariant, the while-loop axiom gives⟦ invariant ⟧
while (guard) {
        BODY
}
⟦ !guard &amp;amp;&amp;amp; invariant ⟧In other words, if the invariant was true at the beginning of the loop execution, then it is true when the loop terminates. The while-loop axiom shows to an observant reader that loops are pure magic: it is the only construction that starts in a state satisfying a known condition, given by the invariant, and then miraculously strengthens that condition by adding &lt;code class=&quot;inline&quot;&gt;!guard&lt;/code&gt; conjunct. Perhaps due to this the founders of structured programming preferred while-loops to the much-derided loops with &amp;quot;a control variable&amp;quot;, like &lt;code class=&quot;inline&quot;&gt;DO&lt;/code&gt; loops in FORTRAN and for-each loops of the modern languages.There are many more axioms (what about the rules for function calls and recursion?), but we won&amp;#x27;t need them or will hand-wave around them.Now, back to the long division. We want to establish the validity of the following triple:uintN_t div(uintN_t n, uintN_t d) {
        ⟦ d &amp;gt; 0 ⟧
        uintN_t q := 0;
        uintN_t r := 0;
        int     i := N - 1;
        while (i != -1) {
                r &amp;lt;&amp;lt;= 1;
                r |= ((n &amp;gt;&amp;gt; i) &amp;amp; 1);
                if (r &amp;gt;= d) {
                        r := r - d;
                        q |= 1 &amp;lt;&amp;lt; i;
                }
                i := i - 1;
        }
        ⟦ n == d*q + r &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; r &amp;lt; d ⟧
        return q;
}The structure of the code basically forces the structure of any possible proof:Find an invariant, preserved by the loop body.Prove that the invariant is established before the loop is entered.Prove that the desired postcondition follows from the conjunction of the   invariant and the negation of the guard.Finding a suitable invariant is the most non-trivial part of the job. Fortunately, in this case we are helped by our (presumed) experience of manually executing this algorithm all too many times at the elementary school. To make it less boring, I give an example of how long division is done in my native country, you should be able to figure it out:After the first step (when the subtraction under the first horizontal line on the left has been completed), the algorithm established that &lt;code class=&quot;inline&quot;&gt;273 == 97*2 + 79&lt;/code&gt;, where by construction &lt;code class=&quot;inline&quot;&gt;79 &amp;lt; 97&lt;/code&gt;, which looks promisingly similar to the form of the postcondition that we want to establish: &lt;code class=&quot;inline&quot;&gt;n == d*q + r &amp;amp;&amp;amp; r &amp;lt; d&lt;/code&gt;. It then makes sense to select as the invariant &amp;quot;the highest &lt;code class=&quot;inline&quot;&gt;N - i - 1&lt;/code&gt; digits of dividend (&lt;i&gt;i.e.&lt;/i&gt;, &lt;code class=&quot;inline&quot;&gt;n&lt;/code&gt;), divided by the divisor (&lt;i&gt;i.e.&lt;/i&gt;, &lt;code class=&quot;inline&quot;&gt;d&lt;/code&gt;), have the highest &lt;code class=&quot;inline&quot;&gt;N - i - 1&lt;/code&gt; digits of &lt;code class=&quot;inline&quot;&gt;q&lt;/code&gt; as the quotient and &lt;code class=&quot;inline&quot;&gt;r&lt;/code&gt; at the remainder&amp;quot; (in our binary case the digits are bits).Provided that we manage to establish that this is actually an invariant, the other remaining pieces fall in place quickly:At the beginning of the loop, &lt;code class=&quot;inline&quot;&gt;i == N - 1&lt;/code&gt; so &amp;quot;the highest &lt;code class=&quot;inline&quot;&gt;N - i - 1&lt;/code&gt; bits&amp;quot;  degenerate into &amp;quot;the highest 0 bits&amp;quot;, for which the condition is vacuous.Similarly at the termination of the loop we have &lt;code class=&quot;inline&quot;&gt;i == -1&lt;/code&gt;, so &lt;code class=&quot;inline&quot;&gt;N - i - 1 == N&lt;/code&gt;   and we have the desired postcondition.But before we embark on the actual proof, we have to introduce some terminology, to simplify the necessary formal manipulations.We are operating on &lt;code class=&quot;inline&quot;&gt;N&lt;/code&gt;-bit unsigned binary numbers. We shall refer to the more and less significant bits as &amp;quot;left&amp;quot; or &amp;quot;last&amp;quot; or &amp;quot;high&amp;quot; and &amp;quot;right&amp;quot; or &amp;quot;first&amp;quot; or &amp;quot;low&amp;quot; respectively, with the appropriate comparative and superlative forms and without, of course, making any assumptions about endianness. Bits are indexed &lt;code class=&quot;inline&quot;&gt;0 ... N - 1&lt;/code&gt; from right to left (Thank you, Fibonacci, very clever! Not.).We will do a lot of bit-shifting. Recall that for &lt;code class=&quot;inline&quot;&gt;t &amp;gt;= 0&lt;/code&gt;, &lt;code class=&quot;inline&quot;&gt;x &amp;gt;&amp;gt; t == floor(x/2^t)&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;x &amp;lt;&amp;lt; t == x*2^t&lt;/code&gt;. Again, all values are unsigned, and so are shifts. Bitwise &lt;code class=&quot;inline&quot;&gt;OR&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;AND&lt;/code&gt; are denoted as &lt;code class=&quot;inline&quot;&gt;|&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;&amp;amp;&lt;/code&gt; as in C.On a loop iteration with a particular value of &lt;code class=&quot;inline&quot;&gt;i&lt;/code&gt;, we will be especially interested in shifts by &lt;code class=&quot;inline&quot;&gt;i&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;i + 1&lt;/code&gt; bits. Write&lt;code class=&quot;inline&quot;&gt;B&amp;#x27; = (1 &amp;lt;&amp;lt; i)&lt;/code&gt; for the &lt;code class=&quot;inline&quot;&gt;i&lt;/code&gt;-th bit bitmask.&lt;code class=&quot;inline&quot;&gt;B&amp;quot; = (1 &amp;lt;&amp;lt; (i + 1))&lt;/code&gt; for the &lt;code class=&quot;inline&quot;&gt;(i + 1)&lt;/code&gt;-st bit bitmask.&lt;code class=&quot;inline&quot;&gt;t&amp;#x27; = (t &amp;gt;&amp;gt; i)&lt;/code&gt;, for the value &lt;code class=&quot;inline&quot;&gt;t&lt;/code&gt; shifted &lt;code class=&quot;inline&quot;&gt;i&lt;/code&gt; bits right.&lt;code class=&quot;inline&quot;&gt;t&amp;quot; = (t &amp;gt;&amp;gt; (i + 1))&lt;/code&gt;, for the value &lt;code class=&quot;inline&quot;&gt;t&lt;/code&gt; shifted &lt;code class=&quot;inline&quot;&gt;i + 1&lt;/code&gt; bits right.&lt;code class=&quot;inline&quot;&gt;M(k) = (1 &amp;lt;&amp;lt; k) - 1&lt;/code&gt;, for the bitmask of the first &lt;code class=&quot;inline&quot;&gt;k&lt;/code&gt; bits.We treat &lt;code class=&quot;inline&quot;&gt;&amp;#x27;&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;&amp;quot;&lt;/code&gt; as &lt;a href=&quot;https://en.wikipedia.org/wiki/Arity#:~:text=the%20term%20%22singulary%22%20is%20the%20correct%20adjective%2C%20rather%20than%20%22unary%22&quot;&gt;singular&lt;/a&gt; operators, binding tighter than any binary ones.As a warm-up, prove the following&lt;b&gt;Lemma&lt;/b&gt; &lt;code class=&quot;inline&quot;&gt;x&amp;#x27; == 2*x&amp;quot; + x&amp;#x27;&amp;amp;1&lt;/code&gt;(Once you rewrite &lt;code class=&quot;inline&quot;&gt;2*x&amp;quot;&lt;/code&gt; as &lt;code class=&quot;inline&quot;&gt;(x &amp;gt;&amp;gt; (i + 1)) &amp;lt;&amp;lt; 1&lt;/code&gt;, it should be trivial.)&amp;quot;The highest &lt;code class=&quot;inline&quot;&gt;N - i - 1&lt;/code&gt; bits&amp;quot; of &lt;code class=&quot;inline&quot;&gt;x&lt;/code&gt; mentioned in the informal invariant above can be obtained by discarding the remaining &lt;code class=&quot;inline&quot;&gt;N - (N - i - 1) == i + 1&lt;/code&gt; bits, and so are &lt;code class=&quot;inline&quot;&gt;x &amp;gt;&amp;gt; (i + 1)&lt;/code&gt;, or, as we luckily agreed, &lt;code class=&quot;inline&quot;&gt;x&amp;quot;&lt;/code&gt;. It makes sense to try &lt;code class=&quot;inline&quot;&gt;n&amp;quot; == d*q&amp;quot; + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r&lt;/code&gt; as the invariant. This assertion is established at the loop entrance and guarantees the final postcondition after the loop termination. Unfortunately, it is &lt;b&gt;not&lt;/b&gt; an invariant of our loop. To conclude this, observe that this assertion holds at the loop entrance even if the initial value of &lt;code class=&quot;inline&quot;&gt;q&lt;/code&gt; is not &lt;code class=&quot;inline&quot;&gt;0&lt;/code&gt;. If it were an invariant, then initialising &lt;code class=&quot;inline&quot;&gt;q&lt;/code&gt; to an arbitrary value would still produce a correct result, which is clearly not the case, because bits of &lt;code class=&quot;inline&quot;&gt;q&lt;/code&gt; are only set (by &lt;code class=&quot;inline&quot;&gt;q |= 1 &amp;lt;&amp;lt; i&lt;/code&gt;) and never cleared, so in the final value of &lt;code class=&quot;inline&quot;&gt;q&lt;/code&gt; all the bits set initially remain set.As it turns out (after many a painful attempt), this is the only obstruction and once we add to the invariant a conjunct &lt;code class=&quot;inline&quot;&gt;q&amp;amp;M(i + 1) == 0&lt;/code&gt; stating that &lt;code class=&quot;inline&quot;&gt;i + 1&lt;/code&gt; lowest bits of &lt;code class=&quot;inline&quot;&gt;q&lt;/code&gt; are 0, we obtain the desired invariant:&lt;b&gt;Loop invariant&lt;/b&gt; &lt;code class=&quot;inline&quot;&gt;n&amp;quot; == d*q&amp;quot; + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0&lt;/code&gt;(If you want a good laugh and have some time to spare, paste &lt;code class=&quot;inline&quot;&gt;div()&lt;/code&gt; code in a &lt;a href=&quot;https://chatgpt.com/&quot;&gt;ChatGPT&lt;/a&gt; chat and ask various models what the loop invariant is.)To the proof then. First, check that the invariant is established at the loop entrance that is, that the following triple is valid.⟦ d &amp;gt; 0 ⟧
uintN_t q := 0;
uintN_t r := 0;
int     i := N - 1;
⟦ n&amp;quot; == d*q&amp;quot; + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 ⟧Go from bottom to top, applying the assignment axiom and simplifying on each step. First, expand the invariant as⟦ n &amp;gt;&amp;gt; (i + 1) == d*(q &amp;gt;&amp;gt; (i + 1)) + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;((1 &amp;lt;&amp;lt; (i + 1)) - 1) == 0 ⟧Now apply the assignment axiom (&lt;i&gt;i.e.&lt;/i&gt;, replace &lt;code class=&quot;inline&quot;&gt;i&lt;/code&gt; with &lt;code class=&quot;inline&quot;&gt;(N - 1)&lt;/code&gt;)...⟦ n &amp;gt;&amp;gt; ((N - 1) + 1) == d*(q &amp;gt;&amp;gt; ((N - 1) + 1)) + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;((1 &amp;lt;&amp;lt; ((N - 1) + 1)) - 1) == 0 ⟧
i := N - 1;
⟦ n &amp;gt;&amp;gt; (i + 1) == d*(q &amp;gt;&amp;gt; (i + 1)) + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;((1 &amp;lt;&amp;lt; (i + 1)) - 1) == 0 ⟧... simplify, use &lt;code class=&quot;inline&quot;&gt;x &amp;gt;&amp;gt; N == 0&lt;/code&gt; for any &lt;code class=&quot;inline&quot;&gt;N&lt;/code&gt;-bit value, and apply the assignment axiom again ...⟦ 0 == d*0 + 0 &amp;amp;&amp;amp; 0 &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= 0 &amp;amp;&amp;amp; (q &amp;amp; ~0) == 0 ⟧
r := 0
⟦ 0 == d*0 + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; (q &amp;amp; ~0) == 0 ⟧... and one more time ...⟦ 0 == 0 &amp;amp;&amp;amp; 0 &amp;lt; d &amp;amp;&amp;amp; (0 &amp;amp; ~0) == 0 ⟧
q := 0
⟦ 0 == d*0 + 0 &amp;amp;&amp;amp; 0 &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= 0 &amp;amp;&amp;amp; (q &amp;amp; ~0) == 0 ⟧... which finally gives⟦ 0 &amp;lt; d ⟧Which is exactly the given precondition. &lt;i&gt;Voilà!&lt;/i&gt; Interestingly, it seems division by zero is impossible, because there is no suitable remainder.Next, we need to prove that the invariant is preserved by the loop body. This is by far the most complex and inundating part of the proof. We want to establish the following triple (at this point let&amp;#x27;s expand the compound assignment operators and add a trivial &lt;code class=&quot;inline&quot;&gt;else&lt;/code&gt; to the conditional so that it conforms to the form expected by our conditional axiom):⟦ n&amp;quot; == d*q&amp;quot; + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 &amp;amp;&amp;amp; i != -1 ⟧
r := r &amp;lt;&amp;lt; 1;
r := r | ((n &amp;gt;&amp;gt; i) &amp;amp; 1);
if (r &amp;gt;= d) {
        r := r - d;
        q := q | (1 &amp;lt;&amp;lt; i);
} else {
}
i := i - 1;
⟦ n&amp;quot; == d*q&amp;quot; + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 ⟧First, the guard &lt;code class=&quot;inline&quot;&gt;i != -1&lt;/code&gt; is only needed to guarantee that shifts by &lt;code class=&quot;inline&quot;&gt;i&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;i + 1&lt;/code&gt; bits make sense. It is not used for anything else and will not be mentioned again.We can proceed as before: start at the bottom and apply the assignment axiom to work our way up:⟦ n&amp;#x27; == d*q&amp;#x27; + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i) == 0 ⟧
i := i - 1;
⟦ n&amp;quot; == d*q&amp;quot; + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 ⟧Note that after substituting &lt;code class=&quot;inline&quot;&gt;i - 1&lt;/code&gt; for &lt;code class=&quot;inline&quot;&gt;i&lt;/code&gt;, &lt;code class=&quot;inline&quot;&gt;x&amp;quot;&lt;/code&gt; nicely transforms into &lt;code class=&quot;inline&quot;&gt;x&amp;#x27;&lt;/code&gt;. But at this point we are stuck: we know the postcondition that the conditional operator must establish, but we have no idea what &lt;i&gt;its&lt;/i&gt; suitable precondition is. Take a step back. We now have &lt;code class=&quot;inline&quot;&gt;n&amp;#x27; == d*q&amp;#x27; + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i) == 0&lt;/code&gt;, that we will call the &lt;i&gt;target&lt;/i&gt;. The composition of two assignments and one conditional operator, starting from the loop invariant must establish the target. Write it down:&lt;b&gt;Loop invariant&lt;/b&gt; &lt;code class=&quot;inline&quot;&gt;n&amp;quot; == d*q&amp;quot; + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0&lt;/code&gt;&lt;b&gt;Target&lt;/b&gt; &lt;code class=&quot;inline&quot;&gt;n&amp;#x27; == d*q&amp;#x27; + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i) == 0&lt;/code&gt;Comparing the loop invariant and the target, we see that transforming the former into the latter takes:Replacing &lt;code class=&quot;inline&quot;&gt;q&amp;quot;&lt;/code&gt; with &lt;code class=&quot;inline&quot;&gt;q&amp;#x27;&lt;/code&gt;.Replacing &lt;code class=&quot;inline&quot;&gt;n&amp;quot;&lt;/code&gt; with &lt;code class=&quot;inline&quot;&gt;n&amp;#x27;&lt;/code&gt;.Replacing &lt;code class=&quot;inline&quot;&gt;q&amp;amp;M(i + 1) == 0&lt;/code&gt; with &lt;code class=&quot;inline&quot;&gt;q&amp;amp;M(i) == 0&lt;/code&gt;.The last one is easy: if the first &lt;code class=&quot;inline&quot;&gt;i + 1&lt;/code&gt; bits of &lt;code class=&quot;inline&quot;&gt;q&lt;/code&gt; are zero (this is what &lt;code class=&quot;inline&quot;&gt;q&amp;amp;M(i + 1) == 0&lt;/code&gt; means), then &lt;i&gt;a fortiori&lt;/i&gt; so are its &lt;code class=&quot;inline&quot;&gt;i&lt;/code&gt; first bits, so &lt;code class=&quot;inline&quot;&gt;q&amp;amp;M(i) == 0&lt;/code&gt;.As for replacing &lt;code class=&quot;inline&quot;&gt;q&amp;quot;&lt;/code&gt; with &lt;code class=&quot;inline&quot;&gt;q&amp;#x27;&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;n&amp;quot;&lt;/code&gt; with &lt;code class=&quot;inline&quot;&gt;n&amp;#x27;&lt;/code&gt;, we will do this via the lemma we stated (and you proved) earlier. We will now apply transformations to the loop invariant such that: (i) it will make it possible to apply the lemma and (ii) it will produce the result that will be a suitable precondition for the following assignments. The right-hand sides of the assignments are &lt;code class=&quot;inline&quot;&gt;r &amp;lt;&amp;lt;= 1&lt;/code&gt; (that is &lt;code class=&quot;inline&quot;&gt;2*r&lt;/code&gt;) and &lt;code class=&quot;inline&quot;&gt;r | ((n &amp;gt;&amp;gt; i) &amp;amp; 1)&lt;/code&gt; (that is &lt;code class=&quot;inline&quot;&gt;r | (n&amp;#x27;&amp;amp;1)&lt;/code&gt;), so we will try to produce an assertion having sub-formulae of this form.The starting invariant again:⟦ n&amp;quot; == d*q&amp;quot; + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 ⟧Multiply both sides of all conjuncts by &lt;code class=&quot;inline&quot;&gt;2&lt;/code&gt;. This produces terms such that the lemma and the assignment axiom for &lt;code class=&quot;inline&quot;&gt;r := 2*r&lt;/code&gt; can be applied.⟦ 2*n&amp;quot; == 2*d*q&amp;quot; + 2*r &amp;amp;&amp;amp; 2*r &amp;lt; 2*d &amp;amp;&amp;amp; 0 &amp;lt;= 2*r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 ⟧Immediately we can apply the lemma: &lt;code class=&quot;inline&quot;&gt;2*q&amp;quot; == q&amp;#x27; - q&amp;#x27;&amp;amp;1&lt;/code&gt;.⟦ 2*n&amp;quot; == d*(q&amp;#x27; - q&amp;#x27;&amp;amp;1) + 2*r &amp;amp;&amp;amp; 2*r &amp;lt; 2*d &amp;amp;&amp;amp; 0 &amp;lt;= 2*r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 ⟧&lt;code class=&quot;inline&quot;&gt;q&amp;amp;M(i + 1) == 0&lt;/code&gt; hence we can drop &lt;code class=&quot;inline&quot;&gt;q&amp;#x27;&amp;amp;1&lt;/code&gt;, as it is guaranteed to be &lt;code class=&quot;inline&quot;&gt;0&lt;/code&gt;.⟦ 2*n&amp;quot; == d*q&amp;#x27; + 2*r &amp;amp;&amp;amp; 2*r &amp;lt; 2*d &amp;amp;&amp;amp; 0 &amp;lt;= 2*r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 ⟧Amazing! We got rid of &lt;code class=&quot;inline&quot;&gt;q&amp;quot;&lt;/code&gt; and this is even before the first statement of the loop body was executed. Continue...Looking forward to &lt;code class=&quot;inline&quot;&gt;r := r | n&amp;#x27;&amp;amp;1&lt;/code&gt;, we see that we have no &lt;code class=&quot;inline&quot;&gt;|&lt;/code&gt;-s in sight, so the assignment axiom cannot be applied directly. Intuitively, this should not be the problem, because after &lt;code class=&quot;inline&quot;&gt;r&lt;/code&gt; is doubled, its lowest bit is zero, and so &lt;code class=&quot;inline&quot;&gt;|&lt;/code&gt; to it is the same as &lt;code class=&quot;inline&quot;&gt;+&lt;/code&gt;, and we have plenty of additions. To prove this it will be nice to have a conjunct &lt;code class=&quot;inline&quot;&gt;r&amp;amp;1 == 0&lt;/code&gt; at that point. But if such a conjunct is present, then &lt;b&gt;before&lt;/b&gt; the &lt;code class=&quot;inline&quot;&gt;r := 2*r&lt;/code&gt; assignment it looked (as per the assignment axiom) as &lt;code class=&quot;inline&quot;&gt;(2*r)&amp;amp;1 == 0&lt;/code&gt;, which is always true, and so we can just as well insert it at this point!⟦ 2*n&amp;quot; == d*q&amp;#x27; + 2*r &amp;amp;&amp;amp; 2*r &amp;lt; 2*d &amp;amp;&amp;amp; 0 &amp;lt;= 2*r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 &amp;amp;&amp;amp; (2*r)&amp;amp;1 == 0 ⟧More pressingly, to apply the assignment axiom to &lt;code class=&quot;inline&quot;&gt;r := r | n&amp;#x27;&amp;amp;1&lt;/code&gt; we need &lt;code class=&quot;inline&quot;&gt;n&amp;#x27;&amp;amp;1&lt;/code&gt; next to each &lt;code class=&quot;inline&quot;&gt;r&lt;/code&gt;. To this end, observe that &lt;code class=&quot;inline&quot;&gt;n&amp;#x27;&amp;amp;1&lt;/code&gt; is either &lt;code class=&quot;inline&quot;&gt;0&lt;/code&gt; or &lt;code class=&quot;inline&quot;&gt;1&lt;/code&gt;, and so if &lt;code class=&quot;inline&quot;&gt;2*r &amp;lt; 2*d&lt;/code&gt; then &lt;code class=&quot;inline&quot;&gt;2*r + n&amp;#x27;&amp;amp;1 &amp;lt; 2*d&lt;/code&gt;.⟦ 2*n&amp;quot; == d*q&amp;#x27; + 2*r &amp;amp;&amp;amp; 2*r + n&amp;#x27;&amp;amp;1 &amp;lt; 2*d &amp;amp;&amp;amp; 0 &amp;lt;= 2*r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 &amp;amp;&amp;amp; (2*r)&amp;amp;1 == 0 ⟧We are fully ready to apply the assignment axiom:⟦ 2*n&amp;quot; == d*q&amp;#x27; + 2*r &amp;amp;&amp;amp; 2*r + n&amp;#x27;&amp;amp;1 &amp;lt; 2*d &amp;amp;&amp;amp; 0 &amp;lt;= 2*r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 &amp;amp;&amp;amp; (2*r)&amp;amp;1 == 0 ⟧
r := 2*r
⟦ 2*n&amp;quot; == d*q&amp;#x27; + r &amp;amp;&amp;amp; r + n&amp;#x27;&amp;amp;1 &amp;lt; 2*d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 &amp;amp;&amp;amp; r&amp;amp;1 == 0 ⟧Apply the lemma: &lt;code class=&quot;inline&quot;&gt;2*n&amp;quot; == n&amp;#x27; - n&amp;#x27;&amp;amp;1&lt;/code&gt;⟦ n&amp;#x27; == d*q&amp;#x27; + r + n&amp;#x27;&amp;amp;1 &amp;amp;&amp;amp; r + n&amp;#x27;&amp;amp;1 &amp;lt; 2*d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 &amp;amp;&amp;amp; r&amp;amp;1 == 0 ⟧The next statement is the assignment &lt;code class=&quot;inline&quot;&gt;r := r | n&amp;#x27;&amp;amp;1&lt;/code&gt;. Thanks to &lt;code class=&quot;inline&quot;&gt;r&amp;amp;1 == 0&lt;/code&gt; conjunct, carefully prepared in advance, we know that we can replace &lt;code class=&quot;inline&quot;&gt;r + n&amp;#x27;&amp;amp;1&lt;/code&gt; with &lt;code class=&quot;inline&quot;&gt;r | n&amp;#x27;&amp;amp;1&lt;/code&gt; and apply the assignment axiom:⟦ n&amp;#x27; == d*q&amp;#x27; + r + n&amp;#x27;&amp;amp;1 &amp;amp;&amp;amp; r + n&amp;#x27;&amp;amp;1 &amp;lt; 2*d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 &amp;amp;&amp;amp; r&amp;amp;1 == 0 ⟧
⟦ n&amp;#x27; == d*q&amp;#x27; + (r | n&amp;#x27;&amp;amp;1) &amp;amp;&amp;amp; (r | n&amp;#x27;&amp;amp;1) &amp;lt; 2*d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 &amp;amp;&amp;amp; r&amp;amp;1 == 0 ⟧
r := r | n&amp;#x27;&amp;amp;1
⟦ n&amp;#x27; == d*q&amp;#x27; + r &amp;amp;&amp;amp; r &amp;lt; 2*d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 ⟧One starts feeling at this point, that the steps of the derivation are practically forced by the form of the invariant. The appearance of &lt;code class=&quot;inline&quot;&gt;r + n&amp;#x27;&amp;amp;1&lt;/code&gt; components in the assertion is a result of using the lemma to get rid of &lt;code class=&quot;inline&quot;&gt;q&amp;quot;&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;n&amp;quot;&lt;/code&gt;. In fact, it seems possible that the algorithm itself could have been derived &lt;i&gt;ad initio&lt;/i&gt;, given the invariant. More about this at the end.We found the mysterious precondition of the conditional statement. One relatively simple final step remains: we have to establish that both conditional branches, given this precondition, establish the target. Let&amp;#x27;s start with the &lt;code class=&quot;inline&quot;&gt;r &amp;gt;= d&lt;/code&gt; branch. We need⟦ n&amp;#x27; == d*q&amp;#x27; + r &amp;amp;&amp;amp; r &amp;lt; 2*d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 &amp;amp;&amp;amp; r &amp;gt;= d ⟧
r := r - d;
q := q | B&amp;#x27;
⟦ n&amp;#x27; == d*q&amp;#x27; + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i) == 0 ⟧Experienced as we are at this point, we can easily transform the precondition to a form suitable for the next assignment (and also drop the redundant &lt;code class=&quot;inline&quot;&gt;0 &amp;lt;= r&lt;/code&gt; conjunct, implied by the conditional guard):⟦ n&amp;#x27; == d*q&amp;#x27; + (r - d) + d &amp;amp;&amp;amp; r - d &amp;lt; d &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 &amp;amp;&amp;amp; r - d &amp;gt;= 0 ⟧Apply the assignment axiom⟦ n&amp;#x27; == d*q&amp;#x27; + (r - d) + d &amp;amp;&amp;amp; r - d &amp;lt; d &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 &amp;amp;&amp;amp; r - d &amp;gt;= 0 ⟧
r := r - d
⟦ n&amp;#x27; == d*q&amp;#x27; + r + d &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 &amp;amp;&amp;amp; r &amp;gt;= 0 ⟧Prepare for the &lt;code class=&quot;inline&quot;&gt;q := q | B&amp;#x27;&lt;/code&gt; assignment. To this end, we have to transform the last assertion to a form where &lt;code class=&quot;inline&quot;&gt;q&lt;/code&gt; only happens as a part of &lt;code class=&quot;inline&quot;&gt;q | B&amp;#x27;&lt;/code&gt;. First, from &lt;code class=&quot;inline&quot;&gt;q&amp;amp;M(i + 1) == 0&lt;/code&gt; it follows that &lt;code class=&quot;inline&quot;&gt;q | B&amp;#x27; == q + B&amp;#x27;&lt;/code&gt; (because &lt;code class=&quot;inline&quot;&gt;i&lt;/code&gt;-th bit of &lt;code class=&quot;inline&quot;&gt;q&lt;/code&gt; is zero). Next, do the easy part, &lt;code class=&quot;inline&quot;&gt;q&amp;amp;M(i + 1) == 0&lt;/code&gt;: weaken it, as was discussed above, to &lt;code class=&quot;inline&quot;&gt;q&amp;amp;M(i) == 0&lt;/code&gt;, then, use &lt;code class=&quot;inline&quot;&gt;(B&amp;#x27; | M(i)) == 0&lt;/code&gt; (immediately from the definition of &lt;code class=&quot;inline&quot;&gt;M(i)&lt;/code&gt;) to arrive at &lt;code class=&quot;inline&quot;&gt;(q | B&amp;#x27;)&amp;amp;M(i) == 0&lt;/code&gt;.Next, deal with &lt;code class=&quot;inline&quot;&gt;d*q&amp;#x27; + r + d&lt;/code&gt;.         d*q&amp;#x27; + r + d
      == d*(q&amp;#x27; + 1)  + r
      == d*(q + B&amp;#x27;)&amp;#x27; + r /* Convince yourself that (x &amp;gt;&amp;gt; i) + 1 == (x + (1 &amp;lt;&amp;lt; i)) &amp;gt;&amp;gt; i */
      == d*(q | B&amp;#x27;)&amp;#x27; + rApply the assignment axiom⟦ n&amp;#x27; == d*(q | B&amp;#x27;)&amp;#x27; + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; (q|B&amp;#x27;)&amp;amp;M(i) == 0 &amp;amp;&amp;amp; r &amp;gt;= 0 ⟧
q := q | B&amp;#x27;
⟦ n&amp;#x27; == d*q&amp;#x27; + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; q&amp;amp;M(i) == 0 &amp;amp;&amp;amp; r &amp;gt;= 0 ⟧Wait a second. This is exactly the target: &lt;code class=&quot;inline&quot;&gt;n&amp;#x27; == d*q&amp;#x27; + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i) == 0&lt;/code&gt;. We are done! What remains, is the trivial verification for the &lt;code class=&quot;inline&quot;&gt;r &amp;lt; d&lt;/code&gt; conditional branch:⟦ n&amp;#x27; == d*q&amp;#x27; + r &amp;amp;&amp;amp; r &amp;lt; 2*d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 &amp;amp;&amp;amp; r &amp;lt; d ⟧
/* Algebra and weakening q&amp;amp;M(i + 1) == 0 to q&amp;amp;M(i) == 0 */
⟦ n&amp;#x27; == d*q&amp;#x27; + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i) == 0 ⟧&lt;b&gt;We are done with the verification of the loop invariant!&lt;/b&gt;We now know that our loop invariant is indeed an invariant. The while-loop axiom then assures us that at the termination of the loop, the invariant will still hold, together with the negation of the guard:⟦ n&amp;quot; == d*q&amp;quot; + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 ⟧
while (i != -1) {
        r &amp;lt;&amp;lt;= 1;
        r |= ((n &amp;gt;&amp;gt; i) &amp;amp; 1);
        if (r &amp;gt;= d) {
                r := r - d;
                q |= 1 &amp;lt;&amp;lt; i;
        }
        i := i - 1;
}
⟦ n&amp;quot; == d*q&amp;quot; + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 &amp;amp;&amp;amp; i == -1 ⟧OK, so substitute &lt;code class=&quot;inline&quot;&gt;i == -1&lt;/code&gt; to the invariant:⟦ n&amp;quot; == d*q&amp;quot; + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 &amp;amp;&amp;amp; i == -1 ⟧
⟦ n == d*q + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r ⟧Hallelujah!Let&amp;#x27;s put it all togetheruintN_t div(uintN_t n, uintN_t d) {
⟦ d &amp;gt; 0 ⟧
⟦ 0 == 0 &amp;amp;&amp;amp; 0 &amp;lt; d &amp;amp;&amp;amp; (0 &amp;amp; ~0) == 0 ⟧
        uintN_t q := 0;
⟦ 0 == d*0 + 0 &amp;amp;&amp;amp; 0 &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= 0 &amp;amp;&amp;amp; (q &amp;amp; ~0) == 0 ⟧
        uintN_t r := 0;
⟦ 0 == d*0 + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; (q &amp;amp; ~0) == 0 ⟧
        int     i := N - 1;
⟦ n&amp;quot; == d*q&amp;quot; + r &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 ⟧
        while (i != -1) {
⟦ n&amp;quot; == d*q&amp;quot; + r &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; r &amp;lt; d  &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 &amp;amp;&amp;amp; i != -1 ⟧
⟦ 2*n&amp;quot; == 2*d*q&amp;quot; + 2*r &amp;amp;&amp;amp; 2*r &amp;lt; 2*d &amp;amp;&amp;amp; 0 &amp;lt;= 2*r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 ⟧
⟦ 2*n&amp;quot; == d*(q&amp;#x27; - q&amp;#x27;&amp;amp;1) + 2*r &amp;amp;&amp;amp; 2*r &amp;lt; 2*d &amp;amp;&amp;amp; 0 &amp;lt;= 2*r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 ⟧
⟦ 2*n&amp;quot; == d*q&amp;#x27; + 2*r &amp;amp;&amp;amp; 2*r &amp;lt; 2*d &amp;amp;&amp;amp; 0 &amp;lt;= 2*r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 ⟧
⟦ 2*n&amp;quot; == d*q&amp;#x27; + 2*r &amp;amp;&amp;amp; 2*r &amp;lt; 2*d &amp;amp;&amp;amp; 0 &amp;lt;= 2*r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 &amp;amp;&amp;amp; (2*r)&amp;amp;1 == 0 ⟧
⟦ 2*n&amp;quot; == d*q&amp;#x27; + 2*r &amp;amp;&amp;amp; 2*r + n&amp;#x27;&amp;amp;1 &amp;lt; 2*d &amp;amp;&amp;amp; 0 &amp;lt;= 2*r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 &amp;amp;&amp;amp; (2*r)&amp;amp;1 == 0 ⟧
                r &amp;lt;&amp;lt;= 1;
⟦ 2*n&amp;quot; == d*q&amp;#x27; + r &amp;amp;&amp;amp; r + n&amp;#x27;&amp;amp;1 &amp;lt; 2*d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 &amp;amp;&amp;amp; r&amp;amp;1 == 0 ⟧
⟦ n&amp;#x27; == d*q&amp;#x27; + r + n&amp;#x27;&amp;amp;1 &amp;amp;&amp;amp; r + n&amp;#x27;&amp;amp;1 &amp;lt; 2*d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 &amp;amp;&amp;amp; r&amp;amp;1 == 0 ⟧
                r |= ((n &amp;gt;&amp;gt; i) &amp;amp; 1);
⟦ n&amp;#x27; == d*q&amp;#x27; + r &amp;amp;&amp;amp; r &amp;lt; 2*d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 ⟧
                if (r &amp;gt;= d) {
⟦ n&amp;#x27; == d*q&amp;#x27; + r &amp;amp;&amp;amp; r &amp;lt; 2*d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 &amp;amp;&amp;amp; r &amp;gt;= d ⟧
⟦ n&amp;#x27; == d*q&amp;#x27; + r + d &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 &amp;amp;&amp;amp; r &amp;gt;= 0 ⟧
                        r := r - d;
⟦ n&amp;#x27; == d*q&amp;#x27; + r + d &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 &amp;amp;&amp;amp; r &amp;gt;= 0 ⟧
⟦ n&amp;#x27; == d*(q | B&amp;#x27;)&amp;#x27; + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; (q|B&amp;#x27;)&amp;amp;M(i) == 0 &amp;amp;&amp;amp; r &amp;gt;= 0 ⟧
                        q |= 1 &amp;lt;&amp;lt; i;
⟦ n&amp;#x27; == d*q&amp;#x27; + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i) == 0 ⟧
                } else {
⟦ n&amp;#x27; == d*q&amp;#x27; + r &amp;amp;&amp;amp; r &amp;lt; 2*d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 &amp;amp;&amp;amp; r &amp;lt; d ⟧
⟦ n&amp;#x27; == d*q&amp;#x27; + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i) == 0 ⟧
                }
⟦ n&amp;#x27; == d*q&amp;#x27; + r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; q&amp;amp;M(i) == 0 ⟧
                i := i - 1;
⟦ n&amp;quot; == d*q&amp;quot; + r &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; q&amp;amp;M(i + 1) == 0 ⟧
        }
⟦ n&amp;quot; == d*q&amp;quot; + r &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; r &amp;lt; d &amp;amp;&amp;amp; i == -1 ⟧
⟦ n == d*q + r &amp;amp;&amp;amp; 0 &amp;lt;= r &amp;amp;&amp;amp; r &amp;lt; d ⟧
        return q;
}Seriously, the proof above looks at a first (and then any following) sight, as a random barrage of bizarre formal spasms in haphazard directions. It is practically impossible to construct such a sequence of assertions in a top-to-bottom fashion, unless one spends an unhealthy amount of time interacting with &lt;span class=&quot;annotation&quot; data-uid=&quot;5&quot;&gt;Hoare triples in dark alleys&lt;/span&gt;.And this is why nobody is doing it this way (among humans that is, automated provers are only too happy to try insane numbers of possible dead-ends). Early on, a much better-structured approach, going in the opposite direction, starting from the known targets (postconditions) was developed, see &lt;a href=&quot;https://en.wikipedia.org/wiki/Predicate_transformer_semantics&quot;&gt;Predicate transformer semantics&lt;/a&gt;, or better still, read &lt;a href=&quot;https://www.amazon.com/Discipline-Programming-Edsger-W-Dijkstra/dp/013215871X&quot;&gt;A Discipline of Programming&lt;/a&gt; (&amp;quot;59683rd Edition&amp;quot; as the Amazon page mentions nonchalantly). Dijkstra also shared the opinion that the structure of the program and the postcondition are tightly locked to the extent that it is possible to derive a program, given its formal specification, see the amazing &lt;a href=&quot;https://www.cs.utexas.edu/~EWD/ewd11xx/EWD1162.PDF&quot;&gt;EWD1162&lt;/a&gt;.</content>
        </item>

        <item>
            <title>S. MacLane died</title>
            <id>maclane</id>
            <link>https://cofault.com/maclane.html#maclane</link>
            <pubDate>2005/04/17</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/maclane.html#maclane">
                     &lt;a href=&quot;http://en.wikipedia.org/wiki/Mac_Lane&quot;&gt;Saunders MacLane&lt;/a&gt; passed away on the morning of April 14.</content>
        </item>

        <item>
            <title>A macro.</title>
            <id>macro</id>
            <link>https://cofault.com/macro.html#macro</link>
            <pubDate>2012/05/11</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/macro.html#macro">
                     &lt;a href=&quot;http://en.wikipedia.org/wiki/C_language&quot;&gt;C language&lt;/a&gt; is wonderfully profound. After almost 20 years, I still find new ways to (ab-)use it. Here is a little problem:Define a macro &lt;code class=&quot;inline&quot;&gt;IN(x, set)&lt;/code&gt;, called as&lt;code class=&quot;inline&quot;&gt;IN(x, (v0, v1, ..., vn))&lt;/code&gt;that expands into an expression&lt;code class=&quot;inline&quot;&gt;((x) == (v0) || (x) == (v1) || ... (x) == (vn))&lt;/code&gt;which evaluates to true &lt;a href=&quot;http://en.wikipedia.org/wiki/Iff&quot;&gt;iff&lt;/a&gt; &lt;code class=&quot;inline&quot;&gt;x&lt;/code&gt; is a member of set &lt;code class=&quot;inline&quot;&gt;{v0, ..., vn }&lt;/code&gt;, where the type of &lt;code class=&quot;inline&quot;&gt;x&lt;/code&gt; and all &lt;code class=&quot;inline&quot;&gt;v&lt;/code&gt;s is the same. Alternatively, define a macro &lt;code class=&quot;inline&quot;&gt;IN1(x, ...)&lt;/code&gt; that expands to the same expression as &lt;code class=&quot;inline&quot;&gt;IN(x, (...))&lt;/code&gt;.</content>
        </item>

        <item>
            <title>A look at several memory management units...</title>
            <id>mm-units</id>
            <link>https://cofault.com/mm-units.html#mm-units</link>
            <pubDate>2005/08/24</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/mm-units.html#mm-units">
                     An interesting &lt;a href=&quot;http://www.engr.umd.edu/~blj/papers/asplos98.pdf&quot;&gt;paper&lt;/a&gt; (via &lt;a href=&quot;http://www.livejournal.com/users/mulix/157621.html&quot;&gt;Muli Ben-Yehuda&lt;/a&gt;) that describes, in particular, VM organization of several platforms. A bit I didn&amp;#x27;t knew: ULTRIX uses two level page tables that are traversed &lt;i&gt;bottom-up&lt;/i&gt;: leaf level of the tree lives in the virtual space and is contiguous in it. As a result, to handle TLB miss at the virtual address A it&amp;#x27;s enough to do:ULTRIX page-fault handler. V0phys_address = LEAF_TABLE[A &amp;gt;&amp;gt; PTABLE_SHIFT_LEAF];Obviously it is somewhat more involved in reality, because appropriate portion of &lt;code class=&quot;inline&quot;&gt;LEAF_TABLE[]&lt;/code&gt; can be not in the TLB itself. In the latter case, root node of the tree is consulted:ULTRIX page-fault handler. V1        if (tlb_miss(LEAF_TABLE + (A &amp;gt;&amp;gt; PTABLE_SHIFT_LEAF))
                tlb_load(ROOT_NODE[A &amp;gt;&amp;gt; PTABLE_SHIFT_ROOT],
                         LEAF_TABLE + (A &amp;gt;&amp;gt; PTABLE_SHIFT_LEAF));
        phys_address = LEAF_TABLE[A &amp;gt;&amp;gt; PTABLE_SHIFT_LEAF];Root node is wired down into unmapped (physical) memory.This design provides following advantages:TLB miss handling requires one memory access in the best case, and two in the  worst. In top-to-bottom page tables &lt;i&gt;a la&lt;/i&gt; Intel, two (or three) accesses are  necessary for every TLB refill;This integrates nicely with virtually indexed processor caches;This allows parts of page tables to be paged out easily.Unfortunately Digital screwed this design by using slow software filled TLB.</content>
        </item>

        <item>
            <title>A Modest Proposal: For Generalizing the Field Access in C Programming Language, and for Making It Beneficial to the Public.</title>
            <id>modest-proposal</id>
            <link>https://cofault.com/modest-proposal.html#modest-proposal</link>
            <pubDate>2009/04/23</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/modest-proposal.html#modest-proposal">
                     [This is an old and never finished draft. HTML produced by &lt;a href=&quot;https://asciidoc.org/&quot;&gt;asciidoc&lt;/a&gt;.]A Modest Proposal: For Generalizing the Field Access in C Programming Language, and for Making It Beneficial to the Public.2009.04.22Nikita Danilov &amp;lt;danilov@gmail.com&amp;gt;      v0.1, September 2007AbstractA proposal is made to modify C language to make      accessing &lt;code class=&quot;inline&quot;&gt;struct&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;union&lt;/code&gt; fields      (&lt;code class=&quot;inline&quot;&gt;s.f&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;p-&amp;gt;f&lt;/code&gt;) more flexible. To that end,      instead of considering &lt;code class=&quot;inline&quot;&gt;.f&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;-&amp;gt;f&lt;/code&gt; as      families of unary postfix operators applicable to the values      of &lt;code class=&quot;inline&quot;&gt;struct&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;union&lt;/code&gt; types and pointers,      respectively, fields are treated as values or special &lt;i&gt;member      designator types&lt;/i&gt; introduced for this purpose,      while &lt;code class=&quot;inline&quot;&gt;.&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;-&amp;gt;&lt;/code&gt; become binary      operators. Typing rules for the field types and examples of      their usage are proposed.      References in square brackets are to the ISO/IEC C standard.OverviewOne of the important advantages of C language is the (relative)      simplicity and cleanness of its memory model: data structures      eventually boil down to the “objects” [3.15],      addressable by pointers and contiguous in address space. This is      most evident in the case of array subscription [6.5.2.1], that      is &lt;i&gt;defined&lt;/i&gt; through the pointer arithmetic:[6.5.2.1] International Standard ISO/IEC 9899       Semantics

        [#2] A postfix expression followed by an expression in square
        brackets [] is a subscripted designation of an element of an
        array object.  The definition of the subscript operator [] is
        that E1[E2] is identical to (*((E1)+(E2))).  Because of the
        conversion rules that apply to the binary + operator, if E1 is
        an array object (equivalently, a pointer to the initial element
        of an array object) and E2 is an integer, E1[E2] designates the
        E2-th element of E1 (counting from zero).Not only array subscription thus defined makes arrays and pointers      mostly equivalent, but it also inherits all the good properties of      addition (commutativity, associativity), and automatically defines the      meaning of multidimensional arrays.Another fundamental operation, structure and union member      de-reference [6.5.2.3] is not, however, similarly reduced to the      pointer manipulations. Instead, the “Types” [6.2.5]      section defines types of a sequential (structure) and overlapping      (union) sets of member objects, and operations are later described      abstractly as accessing member objects:[6.5.2.3] International Standard ISO/IEC 9899       Semantics

 [#3] A postfix expression followed by the . operator and  an
 identifier  designates  a  member  of  a  structure or union
 object.  The value is that of the named member,  and  is  an
 lvalue  if  the first expression is an lvalue.The inflexibility of this definition is clear when compared      with what one can do with the arrays: C permits nothing similar      to &lt;code class=&quot;inline&quot;&gt;foo(a0,a1)[bar(b0.b1)]&lt;/code&gt; for structure and union      member access. Standard &lt;code class=&quot;inline&quot;&gt;offsetof()&lt;/code&gt; macro [7.17]      converts member designator to an integer constant, equal to the      member byte offset within the structure of union, but no support      at the syntax level exists.We propose to introduce a family of scalar types representing      member designators and to define &lt;code class=&quot;inline&quot;&gt;.&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;-&amp;gt;&lt;/code&gt;      operations in terms of values of these types, in fact, in the      way very similar to how array subscription is defined.The perceived advantages of this are:array and structure operations become similar;structure and union operations are reduced to (already defined)  pointer manipulations, improving orthogonality of the language;more generic structure-like data types are introduced for free, see  below.Note that in some sense this is not a new development. Vintage C code      fragments sport usage likev6root/usr/sys/ken/iget.c
   
iupdat(p, tm)
  int *p;
  int *tm;
  {
        register *ip1, *ip2, *rp;
        int *bp, i;

        rp = p;
        if((rp-&amp;gt;i_flag&amp;amp;(IUPD|IACC)) != 0) {
        ...indicating that member designators (&lt;code class=&quot;inline&quot;&gt;i_flag&lt;/code&gt; in this      case, look at the &lt;i&gt;interesting&lt;/i&gt; declaration of &lt;code class=&quot;inline&quot;&gt;rp&lt;/code&gt;) weren&amp;#x27;t originally tied to a specific structure or union      type. They were, in fact, existing by themselves in a special      global namespace—a property that led to the custom of      prefixing field names with a unique prefix.Informal proposalA new derived type constructor &lt;code class=&quot;inline&quot;&gt;-&amp;gt;&lt;/code&gt; is introduced. A    declarator       TYPE0 -&amp;gt; TYPE1specifies a type of a member designator for a member object with a      type &lt;code class=&quot;inline&quot;&gt;TYPE1&lt;/code&gt; in a type &lt;code class=&quot;inline&quot;&gt;TYPE0&lt;/code&gt;.A declarator       TYPE0 -&amp;gt; TYPE1 :N:Mwhere &lt;code class=&quot;inline&quot;&gt;N&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;M&lt;/code&gt; are integer constants, specifies a type of a      member designator for a bit-field of a member object starting at      &lt;code class=&quot;inline&quot;&gt;N&lt;/code&gt;th bit and containing &lt;code class=&quot;inline&quot;&gt;M&lt;/code&gt; bits.Values of any member designator type can be cast to int and      back without loss of information, passed to and returned from      the functions, &lt;i&gt;etc&lt;/i&gt;. A declaration of the form       STRUCT-OR-UNION IDENTIFIER {
               TYPE0 FIELD0;
               TYPE1 FIELD1;
               ...
       };implicitly defines constants of the corresponding member designator      types for all members of &lt;code class=&quot;inline&quot;&gt;STRUCT-OR-UNION IDENTIFIER&lt;/code&gt; type. Defined      constants have values designating their eponymous structure of union      members. For example, struct F {
               int              F_x;
               float            F_y[10];
               void          *(*F_f)(int, struct F *);
               unsigned char    F_b:1;
 };implicitly defines       const struct F -&amp;gt; int                        F_x;
       const struct F -&amp;gt; float[10]                  F_y;
       const struct F -&amp;gt; void *(*)(int, struct F *) F_f;
       const struct F -&amp;gt; unsigned char :X:1         F_b; /* for some X */For any non bit-field member &lt;code class=&quot;inline&quot;&gt;FIELD&lt;/code&gt; it holds that       offsetof(STRUCT-OR-UNION IDENTIFIER, FIELD) == (int)FIELDFollowing operations are defined on values of member designator    types:given an expression &lt;code class=&quot;inline&quot;&gt;E0&lt;/code&gt; of type “pointer    to &lt;code class=&quot;inline&quot;&gt;T0&lt;/code&gt;”, and an expression &lt;code class=&quot;inline&quot;&gt;E1&lt;/code&gt; of    type &lt;code class=&quot;inline&quot;&gt;T0 -&amp;gt; T1&lt;/code&gt;, &lt;code class=&quot;inline&quot;&gt;E0-&amp;gt;E1&lt;/code&gt; is equivalent to           *(T1 *)(((char *)E0) + E1)where &lt;code class=&quot;inline&quot;&gt;E1&lt;/code&gt; is implicitly converted to an integer type;given an expression &lt;code class=&quot;inline&quot;&gt;E0&lt;/code&gt; of type &lt;code class=&quot;inline&quot;&gt;A -&amp;gt; B&lt;/code&gt;    and an expression &lt;code class=&quot;inline&quot;&gt;E1&lt;/code&gt; of type &lt;code class=&quot;inline&quot;&gt;B -&amp;gt; C&lt;/code&gt;,    expression &lt;code class=&quot;inline&quot;&gt;E0.E1&lt;/code&gt; has type &lt;code class=&quot;inline&quot;&gt;A -&amp;gt; C&lt;/code&gt;, and    corresponds to the member of &lt;code class=&quot;inline&quot;&gt;B&lt;/code&gt;, viewed as a member of &lt;code class=&quot;inline&quot;&gt;A&lt;/code&gt;;given an expression &lt;code class=&quot;inline&quot;&gt;E&lt;/code&gt; of type &lt;code class=&quot;inline&quot;&gt;A -&amp;gt; B&lt;/code&gt;, a    unary expression &lt;code class=&quot;inline&quot;&gt;-E&lt;/code&gt; has type &lt;code class=&quot;inline&quot;&gt;B -&amp;gt; A&lt;/code&gt;,    and designates an instance of &lt;code class=&quot;inline&quot;&gt;A&lt;/code&gt; in which an    instance of &lt;code class=&quot;inline&quot;&gt;B&lt;/code&gt; designated by &lt;code class=&quot;inline&quot;&gt;E&lt;/code&gt; is embedded;a compound assignment &lt;code class=&quot;inline&quot;&gt;E0 -&amp;gt;= E1&lt;/code&gt; is defined as an    abbreviation for &lt;code class=&quot;inline&quot;&gt;E0 = E0-&amp;gt;E1&lt;/code&gt;, with &lt;code class=&quot;inline&quot;&gt;E0&lt;/code&gt; evaluated    only once.ExamplesExample: Basic usagestruct F {
       int F_x;
};

struct G {
       int      G_y;
       struct F G_f;
};

void foo() {
       struct G  g;
       struct F *nested;

       printf(&amp;quot;designators: %i %i %i\n&amp;quot;, F_x, G_y, G_f);
       g.G_y = 1;     /* defined as *(g + G_y) = 1; */
       g.G_f.F_x = 2; /* defined as *(g + G_f.F_x) = 2; */
       nested = &amp;amp;g.G_f;
       /* nested-&amp;gt;(-G_f) is g */
       assert(nested-&amp;gt;(-G_f).G_y == 1);
       /* or... */
       assert(nested-&amp;gt;(-G_f.G_y) == 1);
}Example: Searching for an item in a linked    liststruct list_link {
       struct list_link *ll_next;
}

struct list_item {
       struct list_link li_next;
       int              li_value;
};

struct list_link *search(struct list_link *s, int key) {
       for (; s &amp;amp;&amp;amp; s-&amp;gt;-li_next.li_value != key; s -&amp;gt;= li_next) {
              ;
       }
       return s;
}Note that &lt;code class=&quot;inline&quot;&gt;foo-&amp;gt;-bar&lt;/code&gt; subsumes &lt;code class=&quot;inline&quot;&gt;container_of()&lt;/code&gt; macro (as used in the      Linux kernel).C is traditionally used as a language for the system      programming—a domain where one has often to deal with      formatted data on the storage or network. As a typical example      let&amp;#x27;s imagine a system that keeps formatted meta-data, &lt;i&gt;e.g.&lt;/i&gt;, a      list of directory entries for a file system or index entries for      a data-base in a block device block. Different devices have      different block sizes, which means that in general case format      of a device block cannot be described by a C structure      type. With member designator types, however, something similar      to the following can be done:/* variable sized device block */
typedef char * block_contents_t;

struct block_format {
       /* magic number at the beginning of the block */
       block_contents_t -&amp;gt; uint32_t bf_start_magic;
       /* array of keys in the index block, growing to the right */
       block_contents_t -&amp;gt; key_t[]  bf_keys;
       /* array of values, corresponding to the keys, growing to the left */
       block_contents_t -&amp;gt; val_t[]  bf_values;
       /* magic number at the end of the block */
       block_contents_t -&amp;gt; uint32_t bf_end_magic;
};

struct system_descriptor {
      ...
      struct block_format sd_format;
      ...
};

void init(struct system_descriptor *desc, int block_size) {
      switch (block_size) {
             case 512:
                    desc-&amp;gt;sd_format.bf_keys      = ...;
                    desc-&amp;gt;sd_format.bf_values    = ...;
                    desc-&amp;gt;sd_format.bf_end_magic = ...;
                    break;
             case 1024:
                    ...
      }
}

int block_search(struct system_descriptor *desc, block_contents_t block,
                key_t *key) {
       int i;

       assert(block-&amp;gt;(desc-&amp;gt;bf_start_magic) == START_MAGIC);
       assert(block-&amp;gt;(desc-&amp;gt;sd_format.bf_end_magic) == END_MAGIC);

       for (i = 0; i &amp;lt; NUM_KEYS; ++i) {
               if (key_cmp(&amp;amp;(block-&amp;gt;(desc-&amp;gt;sd_format.bf_keys))[i], key) {
                       ...
}Clearly, quite generic yet type-safe data structures can be    built this way.ProblemsBackward compatibility is broken because field names must be      unique within a compilation unit now (as they have constants      declared for them). This is “safe” violation of      compatibility in that it doesn&amp;#x27;t change the semantics of an      existing code silently.Meaning of &lt;code class=&quot;inline&quot;&gt;E0.E1&lt;/code&gt; for a non-lvalue E0 is awkward to      define.</content>
        </item>

        <item>
            <title>A monster desktop</title>
            <id>monster-desktop</id>
            <link>https://cofault.com/monster-desktop.html#monster-desktop</link>
            <pubDate>2005/08/12</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/monster-desktop.html#monster-desktop">
                     Screenshot of my desktop while running 5 node &lt;a href=&quot;http://user-mode-linux.sourceforge.net&quot;&gt;UML&lt;/a&gt; cluster:</content>
        </item>

        <item>
            <title>named formals</title>
            <id>named-formals</id>
            <link>https://cofault.com/named-formals.html#named-formals</link>
            <pubDate>2005/08/18</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/named-formals.html#named-formals">
                     Another C99 abuse: &lt;i&gt;named formal parameters&lt;/i&gt;:int foo(int a, char b)
{
        printf(&amp;quot;foo: a: %i, b: %c (%i)\n&amp;quot;, a, b, b);
}

#define foo(...) ({                 \
          struct {                  \
                   int  a;          \
                   char b;          \
          } __fa = { __VA_ARGS__ }; \
          foo(__fa.a, __fa.b);      \
})

int main(int argc, char **argv)
{
        foo(.b = &amp;#x27;b&amp;#x27;, .a = 42);
        foo();
}This outputs:foo: a: 42, b: b (98)
foo: a: 0, b:  (0)By combining compound literals and &lt;code class=&quot;inline&quot;&gt;__VA_ARGS__&lt;/code&gt; (&lt;a href=&quot;compound-literals.html#compound-literals-start&quot;&gt;again&lt;/a&gt;!) it is possible to explicitly name function arguments, specify them in arbitrary order, and omit some of them (omitted arguments are initialized by corresponding default initializers).</content>
        </item>

        <item>
            <title>opahead patch</title>
            <id>opahead-patch</id>
            <link>https://cofault.com/opahead-patch.html#opahead-patch</link>
            <pubDate>2005/11/23</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/opahead-patch.html#opahead-patch">
                     &lt;a href=&quot;http://linuxhacker.ru/~nikita/patches/2.6.15-rc1/0b-opahead.patch&quot;&gt;Here&lt;/a&gt; is a 2.6.15-rc1 version of &lt;i&gt;opahead&lt;/i&gt; patch that was sleeping in my &lt;a href=&quot;http://www.zip.com.au/~akpm/linux/patches/patch-scripts-0.20/&quot;&gt;patch-scripts&lt;/a&gt; series file for some time.&lt;i&gt;opahead&lt;/i&gt; stands for &lt;i&gt;operation-ahead&lt;/i&gt; by analogy with read-ahead. An inspiration for this patch was a &lt;a href=&quot;http://www.usenix.org/events/usenix01/kroeger.html&quot;&gt;USENIX paper&lt;/a&gt; that discusses a smarter than usual read-ahead algorithm. Kroeger and Long implemented a sub-system that kept track of read accesses to files and, according to certain stochastic model uses collected information to try to predict future accesses.opahead uses much simpler model known as &lt;i&gt;Shannon Oracle&lt;/i&gt;. (Unfortunately, I failed to find any online reference. I read a description of this algorithm many years ago in a book I no longer have.) It basically maintains enough data to answer following question: for a given sequence of &lt;code class=&quot;inline&quot;&gt;N&lt;/code&gt; reads, what reads have been seen to follow this sequence in the past and how many times? Read that followed the sequence most, is assumed to be most likely to happen, and appropriate read-ahead is issued.If &lt;code class=&quot;inline&quot;&gt;N&lt;/code&gt; equals &lt;code class=&quot;inline&quot;&gt;1&lt;/code&gt; we get familiar &lt;a href=&quot;http://en.wikipedia.org/wiki/Markov_Chain&quot;&gt;Markov Chain&lt;/a&gt; model. This is why the patch is sometimes called &lt;i&gt;Markov read-ahead&lt;/i&gt;. But Markov chains have one fundamental disadvantage that makes them unsuitable for the read-ahead implementation: to make efficient read-ahead it&amp;#x27;s necessary to saturate IO layer and for this one has to look &lt;i&gt;more than one&lt;/i&gt; event ahead in the future. That is, we have to predict next read, then assume that it did happen, and made new prediction based on that assumption. Obviously, the reliability of consecutive predictions deteriorates quickly, so it&amp;#x27;s very important to make initial prediction as reliable as possible. To this end, predictions are made on the basis of N previous reads, rather than on the basis of single one as in Markov model.Another observation is that this algorithm doesn&amp;#x27;t depend on the nature of the events that are tracked and predicted. It can be generalized to the module that tracks and predicts abstract events that can be compared for equality (and it is that generalized form that is implemented in the patch).That module can be used to do read-ahead at the different layers: VFS, file system, VM (page cache read-ahead), block layer (physical read-ahead); or it can be used for things completely unrelated to the read-ahead like, god forbid... predicting scheduling activity..This patch was used to drive read-ahead at the file system layer (by plugging calls to &lt;code class=&quot;inline&quot;&gt;opahead_{happens,predict}()&lt;/code&gt; into &lt;code class=&quot;inline&quot;&gt;ext2_file_read()&lt;/code&gt;), but even though speed up of kernel compilation was measurable, this turned out to be dead-end, because to read a page from file one has to bring inode it memory first, but currently there is no an API for asynchronous inode loading.Below is a top-level comment from &lt;code class=&quot;inline&quot;&gt;opahead.h&lt;/code&gt; header with the general description of API (at least my effort of typing it in wouldn&amp;#x27;t be wasted)./*
 * This file is an interface to the op-ahead: a generic prediction engine.
 *
 * op-ahead implementation is in lib/opahead.c
 *
 * General description.
 *
 * op-ahead makes predictions in a certain domain consisting of events. Events
 * happen sequentially. op-head clients notify engine about events that
 * happen, and engine keeps track of event patterns. Engine then can be asked
 * a question: &amp;quot;Given a sequence of N last events, what is the next event to
 * happen most likely?&amp;quot;
 *
 * To answer this question, op-ahead keeps track of all sequences of N events
 * ever observed in the domain. N is called domain depth, and said sequences
 * are called paths. For each path op-ahead maintains a list of events that
 * were observed to follow this path (that is, to happen immediately after
 * events in the path happened in order). These following events (called
 * guesses) are weighted: the weight is a guess is a number of times it was
 * observed to follow this path.
 *
 * op-ahead operation is quite simple: when event E happens, op-ahead finds a
 * path corresponding to last happened events, and increases the weight of
 * guess corresponding to E (creating new guess if necessary).
 *
 * When asked to predict what event will follow given N events, op-ahead finds
 * path corresponding to these events and returns the guess with the largest
 * weight. If there are multiple guesses with the equal weight---random one is
 * selected.
 *
 * When domain depth is 1, paths degenerate into events and op-ahead into
 * modeling Markov chains.
 *
 * op-ahead algorithm is known as &amp;quot;Shannon Oracle&amp;quot;. It is reported that in the
 * domain of two events &amp;quot;tail&amp;quot; and &amp;quot;head&amp;quot;, and with the depth of 5, Shannon
 * Oracle robustly beats human player in the game of head and tails (that is,
 * after some period of learning it&amp;#x27;s able to predict next move with the
 * probability higher than 0.5). You are hereby requested to spend at least 10
 * percent of proceeds obtained from playing head and tails with the help of
 * this kernel code to buy hardware and to provide it to Linux kernel
 * developers.
 *
 * Usage.
 *
 * To use op-ahead client creates an instance of struct opa_domain with
 * methods appropriate for its events.
 *
 * Predictions are made in the &amp;quot;context&amp;quot; which is an array of domain-&amp;gt;depth
 * pointers to events. This context is created by client (initialized by NULL
 * pointers) and is passed to opa_{predict,happen}(). It is used to record
 * latest events. When context is no longer needed, client calls
 * opa_context_put().
 *
 * When new event happens, client calls opa_happens() to record it. To predict
 * future events opa_predict() is used.
 *
 * Related work.
 *
 * In http://www.usenix.org/events/usenix01/kroeger.html a similar (albeit
 * more mathematically sophisticated) model is used to predict future file
 * accesses and to drive inter-file read-ahead.
 *
 * TODO:
 *
 * Helper functions for reference-counted events.
 *
 */</content>
        </item>

        <item>
            <title>page tickets</title>
            <id>page-tickets</id>
            <link>https://cofault.com/page-tickets.html#page-tickets</link>
            <pubDate>2005/04/05</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/page-tickets.html#page-tickets">
                     Mach VM had (or &lt;span class=&quot;annotation&quot; data-uid=&quot;1&quot;&gt;still has&lt;/span&gt; if Mac OS X counts) an interesting detail in its VM scanner implementation (&lt;code class=&quot;inline&quot;&gt;osfmk/vm/vm_page.h&lt;/code&gt;):/* 
 * Each page entered on the inactive queue obtains a ticket from a
 * particular ticket roll.  Pages granted tickets from a particular 
 * roll  generally flow through the queue as a group.  In this way when a
 * page with a ticket from a particular roll is pulled from the top of the
 * queue it is extremely likely that the pages near the top will have tickets
 * from the same or adjacent rolls.  In this way the proximity to the top
 * of the queue can be loosely ascertained by determining the identity of
 * the roll the pages ticket came from. 
 */</content>
        </item>

        <item>
            <title>Parmigianino faces.</title>
            <id>parmigianino</id>
            <link>https://cofault.com/parmigianino.html#parmigianino</link>
            <pubDate>2014/02/09</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/parmigianino.html#parmigianino">
                     An angel from &lt;a href=&quot;http://en.wikipedia.org/wiki/Madonna_with_the_Long_Neck&quot;&gt;Madonna with the long neck&lt;/a&gt; (1535):An unidentified girl from &lt;a href=&quot;http://en.wikipedia.org/wiki/Portrait_of_a_Young_Woman_(Parmigianino)&quot;&gt;Antea&lt;/a&gt; (1524, survived everything, including Austrian salt mines):Albeit one can argue that the resemblance is due to the stricture of the mannerist canon (see the earlobes, for example), this is undoubtedly the same face.A discovery no less thrilling even though I am definitely not the first to make it.</content>
        </item>

        <item>
            <title>kernel patches for 2.6.12-rc6</title>
            <id>patches-2.6.12</id>
            <link>https://cofault.com/patches-2.6.12.html#patches-2.6.12</link>
            <pubDate>2005/06/11</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/patches-2.6.12.html#patches-2.6.12">
                     After long delay I updated my kernel patches to 2.6.12-rc6. This required installing &lt;a href=&quot;http://kernel.org/git/&quot;&gt;git&lt;/a&gt; and &lt;a href=&quot;http://lwn.net/Articles/133938/&quot;&gt;co&lt;a href=&quot;http://kernel.org/git/&quot;&gt;git&lt;/a&gt;o&lt;/a&gt;, but it turned out that time wasn&amp;#x27;t wasted: these tools beat &lt;a href=&quot;http://bitmover.com&quot;&gt;bitkeeper&lt;/a&gt; hands down CPU-wise.New version of patches is uploaded &lt;a href=&quot;http://linuxhacker.ru/~nikita/patches/2.6.12-rc6/2005.06.11&quot;&gt;here&lt;/a&gt;.This series include:&lt;a href=&quot;http://linuxhacker.ru/~nikita/patches/2.6.12-rc6/2005.06.11/vm_01-zoneinfo.patch&quot;&gt;&lt;code class=&quot;inline&quot;&gt;vm_01-zoneinfo.patch&lt;/code&gt;&lt;/a&gt;Add /proc/zoneinfo file to display information about memory zones. Useful to  analyze VM behaviour. This was merged into -mm.&lt;a href=&quot;http://linuxhacker.ru/~nikita/patches/2.6.12-rc6/2005.06.11/vm_02-skip-writepage.patch&quot;&gt;&lt;code class=&quot;inline&quot;&gt;vm_02-skip-writepage.patch&lt;/code&gt;&lt;/a&gt;Don&amp;#x27;t call &lt;code class=&quot;inline&quot;&gt;-&amp;gt;writepage&lt;/code&gt; from VM scanner when page is met for the first time  during scan.New page flag &lt;code class=&quot;inline&quot;&gt;PG_skipped&lt;/code&gt; is used for this. This flag is &lt;code class=&quot;inline&quot;&gt;TestSet&lt;/code&gt;-ed just  before calling &lt;code class=&quot;inline&quot;&gt;-&amp;gt;writepage&lt;/code&gt; and is cleaned when page enters inactive list.One can see this as &amp;quot;second chance&amp;quot; algorithm for the dirty pages on the  inactive list.BSD does the same: &lt;code class=&quot;inline&quot;&gt;src/sys/vm/&lt;/code&gt;&lt;code class=&quot;inline&quot;&gt;vm_pageout.c:vm_pageout_scan()&lt;/code&gt;, &lt;code class=&quot;inline&quot;&gt;PG_WINATCFLS&lt;/code&gt;  flag.Reason behind this is that -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepages()&lt;/code&gt; will perform more efficient writeout than -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepage()&lt;/code&gt;. Skipping of page can be conditioned on zone-&amp;gt;pressure.On the other hand, avoiding -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepage()&lt;/code&gt; increases amount of scanning  performed by kswapd.(Possible drawback: executable text pages are evicted earlier.)&lt;a href=&quot;http://linuxhacker.ru/~nikita/patches/2.6.12-rc6/2005.06.11/vm_03-dont-rotate-active-list.patch&quot;&gt;&lt;code class=&quot;inline&quot;&gt;vm_03-dont-rotate-active-list.patch&lt;/code&gt;&lt;/a&gt;Currently, if zone is short on free pages, &lt;code class=&quot;inline&quot;&gt;refill_inactive_zone()&lt;/code&gt; starts moving  pages from active_list to inactive_list, rotating active_list as it goes. That  is, pages from the tail of active_list are transferred to its head, thus  destroying lru ordering, exactly when we need it most --- when system is low on  free memory and page replacement has to be performed.This patch modifies &lt;code class=&quot;inline&quot;&gt;refill_inactive_zone()&lt;/code&gt; so that it scans active_list without  rotating it. To achieve this, special dummy page &lt;code class=&quot;inline&quot;&gt;zone-&amp;gt;scan_page&lt;/code&gt; is  maintained for each zone. This page marks a place in the active_list reached  during scanning.As an additional bonus, if memory pressure is not so big as to start swapping mapped pages (&lt;code class=&quot;inline&quot;&gt;reclaim_mapped == 0&lt;/code&gt; in &lt;code class=&quot;inline&quot;&gt;refill_inactive_zone()&lt;/code&gt;), then not referenced mapped pages can be left behind &lt;code class=&quot;inline&quot;&gt;zone-&amp;gt;scan_page&lt;/code&gt; instead of moving them to the head of &lt;code class=&quot;inline&quot;&gt;active_list&lt;/code&gt;. When reclaim_mapped mode is activated, &lt;code class=&quot;inline&quot;&gt;zone-&amp;gt;scan_page&lt;/code&gt; is reset back to the tail of &lt;code class=&quot;inline&quot;&gt;active_list&lt;/code&gt; so that these pages can be re-scanned.&lt;a href=&quot;http://linuxhacker.ru/~nikita/patches/2.6.12-rc6/2005.06.11/vm_04-__alloc_pages-inject-failure.patch&quot;&gt;&lt;code class=&quot;inline&quot;&gt;vm_04-__alloc_pages-inject-failure.patch&lt;/code&gt;&lt;/a&gt;Force artificial failures in page allocator. I used this to harden some kernel  code.&lt;a href=&quot;http://linuxhacker.ru/~nikita/patches/2.6.12-rc6/2005.06.11/vm_05-page_referenced-move-dirty.patch&quot;&gt;&lt;code class=&quot;inline&quot;&gt;vm_05-page_referenced-move-dirty.patch&lt;/code&gt;&lt;/a&gt;transfer dirtiness from pte to the struct page in &lt;code class=&quot;inline&quot;&gt;page_referenced()&lt;/code&gt;. This makes  pages dirtied through mmap &amp;quot;visible&amp;quot; to the file system, that can write them  out through -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepages()&lt;/code&gt; (otherwise pages are written from -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepage()&lt;/code&gt; from  tail of the inactive list).&lt;a href=&quot;http://linuxhacker.ru/~nikita/patches/2.6.12-rc6/2005.06.11/vm_06-cluster-pageout.patch&quot;&gt;&lt;code class=&quot;inline&quot;&gt;vm_06-cluster-pageout.patch&lt;/code&gt;&lt;/a&gt;Implement pageout clustering at the VM level.With this patch VM scanner calls &lt;code class=&quot;inline&quot;&gt;pageout_cluster()&lt;/code&gt; instead of  -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepage()&lt;/code&gt;. &lt;code class=&quot;inline&quot;&gt;pageout_cluster()&lt;/code&gt; tries to find a group of dirty pages around  target page, called &lt;i&gt;pivot&lt;/i&gt; page of the cluster. If group of suitable size  is found, -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepages()&lt;/code&gt; is called for it, otherwise, &lt;code class=&quot;inline&quot;&gt;page_cluster()&lt;/code&gt; falls back  to -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepage()&lt;/code&gt;.This is supposed to help in work-loads with significant page-out of file-system  pages from tail of the inactive list (for example, heavy dirtying through  mmap), because file system usually writes multiple pages more  efficiently. Should also be advantageous for file-systems doing delayed  allocation, as in this case they will allocate whole extents at once.Few points:swap-cache pages are not clustered (although they can be, but by    &lt;code class=&quot;inline&quot;&gt;page-&amp;gt;private&lt;/code&gt; rather than &lt;code class=&quot;inline&quot;&gt;page-&amp;gt;index&lt;/code&gt;)only kswapd do clustering, because direct reclaim path should be low    latency.this patch adds new fields to struct writeback_control and expects    -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepages()&lt;/code&gt; to interpret them. This is needed, because &lt;code class=&quot;inline&quot;&gt;pageout_cluster()&lt;/code&gt;    calls -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepages()&lt;/code&gt; with pivot page already locked, so that -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepages()&lt;/code&gt; is    allowed to only trylock other pages in the cluster.Besides, rather rough plumbing (&lt;code class=&quot;inline&quot;&gt;wbc-&amp;gt;pivot_ret&lt;/code&gt; field) is added to check    whether -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepages()&lt;/code&gt; failed to write pivot page for any reason (in latter    case &lt;code class=&quot;inline&quot;&gt;page_cluster()&lt;/code&gt; falls back to -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepage()&lt;/code&gt;).Only &lt;code class=&quot;inline&quot;&gt;mpage_writepages()&lt;/code&gt; was updated to honor these new fields, but all    in-tree -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepages()&lt;/code&gt; implementations seem to call    &lt;code class=&quot;inline&quot;&gt;mpage_writepages()&lt;/code&gt;. (Except reiser4, of course, for which I&amp;#x27;ll send a    (trivial) patch, if necessary).&lt;a href=&quot;http://linuxhacker.ru/~nikita/patches/2.6.12-rc6/2005.06.11/vm_07-proc-stack.patch&quot;&gt;&lt;code class=&quot;inline&quot;&gt;vm_07-proc-stack.patch&lt;/code&gt;&lt;/a&gt;Export kernel backtrace in &lt;code class=&quot;inline&quot;&gt;/proc/&amp;lt;pid&amp;gt;/task/&amp;lt;tid&amp;gt;/stack&lt;/code&gt;. Useful when  debugging deadlocks.This somewhat duplicates functionality of SysRq-T, but is less intrusive to  the system operation and can be used in the scripts.Exporting kernel stack of a thread is probably unsound security-wise. Use with  care.Instead of adding yet another architecture specific function to output thread  stack through &lt;code class=&quot;inline&quot;&gt;seq_file&lt;/code&gt; API, it introduces &lt;i&gt;iterator&lt;/i&gt;;void do_with_stack(struct task_struct *tsk, 
     int (*actor)(int, void *, void *, void *), void *opaque)that has to be implemented by each architecture, so that generic code can  iterate over stack frames in architecture-independent way.&lt;code class=&quot;inline&quot;&gt;lib/do_with_stack.c&lt;/code&gt; is provided for archituctures that don&amp;#x27;t implement their  own. It is based on &lt;code class=&quot;inline&quot;&gt;__builtin_{frame,return}&lt;/code&gt;&lt;code class=&quot;inline&quot;&gt;_address()&lt;/code&gt;.&lt;a href=&quot;http://linuxhacker.ru/~nikita/patches/2.6.12-rc6/2005.06.11/vm_08-proc-sleep.patch&quot;&gt;&lt;code class=&quot;inline&quot;&gt;vm_08-proc-sleep.patch&lt;/code&gt;&lt;/a&gt;export per-process blocking statistics in &lt;code class=&quot;inline&quot;&gt;/proc/&amp;lt;pid&amp;gt;/task/&amp;lt;tid&amp;gt;/sleep&lt;/code&gt; and  global sleeping statistics in &lt;code class=&quot;inline&quot;&gt;/proc/sleep&lt;/code&gt;. Statistics collection for given  file is activated on the first read of corresponding &lt;code class=&quot;inline&quot;&gt;/proc&lt;/code&gt; file. When  statistics collection is on on each context switch current back-trace is built  (through &lt;code class=&quot;inline&quot;&gt;&lt;code class=&quot;inline&quot;&gt;__&lt;/code&gt;builtin_return_address()&lt;/code&gt;). For each monitored process there is a LRU  list of such back-traces. Useful when trying to understand where elapsed time  is spent.&lt;a href=&quot;http://linuxhacker.ru/~nikita/patches/2.6.12-rc6/2005.06.11/vm_09-ll_merge_requests_fn-cleanup.patch&quot;&gt;&lt;code class=&quot;inline&quot;&gt;vm_09-ll_merge_requests_fn-cleanup.patch&lt;/code&gt;&lt;/a&gt;&lt;code class=&quot;inline&quot;&gt;ll_merge_requests_fn()&lt;/code&gt; assigns &lt;code class=&quot;inline&quot;&gt;total_{phys,hw}_segments&lt;/code&gt; twice. Fix this and a typo. Merged into -mm.&lt;a href=&quot;http://linuxhacker.ru/~nikita/patches/2.6.12-rc6/2005.06.11/vm_0a-deadline-iosched.c-cleanup.patch&quot;&gt;&lt;code class=&quot;inline&quot;&gt;vm_0a-deadline-iosched.c-cleanup.patch&lt;/code&gt;&lt;/a&gt;Small cleanup.&lt;code class=&quot;inline&quot;&gt;rmap-cleanup.patch&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;WRITEPAGE_ACTIVATE-doc-fix.patch&lt;/code&gt; were merged into Linus tree.</content>
        </item>

        <item>
            <title>Update of my kernel patches for 2.6.14-rc5</title>
            <id>patches-update</id>
            <link>https://cofault.com/patches-update.html#patches-update</link>
            <pubDate>2005/10/24</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/patches-update.html#patches-update">
                     New &lt;span class=&quot;annotation&quot; data-uid=&quot;0&quot;&gt;version of patches&lt;/span&gt; is uploaded &lt;a href=&quot;http://linuxhacker.ru/~nikita/patches/2.6.14-rc5&quot;&gt;here&lt;/a&gt;.This series include:&lt;a href=&quot;http://linuxhacker.ru/~nikita/patches/2.6.14-rc5/01-skip-writepage.patch&quot;&gt;&lt;code class=&quot;inline&quot;&gt;vm_02-skip-writepage.patch&lt;/code&gt;&lt;/a&gt;:Don&amp;#x27;t call &lt;code class=&quot;inline&quot;&gt;-&amp;gt;writepage&lt;/code&gt; from VM scanner when page is met for the first time during scan.New page flag &lt;code class=&quot;inline&quot;&gt;PG_skipped&lt;/code&gt; is used for this. This flag is &lt;code class=&quot;inline&quot;&gt;TestSet&lt;/code&gt;-ed just before calling &lt;code class=&quot;inline&quot;&gt;-&amp;gt;writepage&lt;/code&gt; and is cleaned when page enters inactive list.One can see this as &lt;i&gt;second chance&lt;/i&gt; algorithm for the dirty pages on the inactive list.BSD does the same: &lt;code class=&quot;inline&quot;&gt;src/sys/vm/&lt;/code&gt;&lt;code class=&quot;inline&quot;&gt;vm_pageout.c:vm_pageout_scan()&lt;/code&gt;, &lt;code class=&quot;inline&quot;&gt;PG_WINATCFLS&lt;/code&gt; flag.Reason behind this is that -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepages()&lt;/code&gt; will perform more efficient  writeout than -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepage()&lt;/code&gt;. Skipping of page can be conditioned on  zone-&amp;gt;pressure.On the other hand, avoiding -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepage()&lt;/code&gt; increases amount of scanning  performed by kswapd.(Possible drawback: executable text pages are evicted earlier.)&lt;a href=&quot;http://linuxhacker.ru/~nikita/patches/2.6.14-rc5/02-__alloc_pages-inject-failure.patch&quot;&gt;&lt;code class=&quot;inline&quot;&gt;vm_04-__alloc_pages-inject-failure.patch&lt;/code&gt;&lt;/a&gt;Force artificial failures in page allocator. I used this to harden some kernel code.&lt;a href=&quot;http://linuxhacker.ru/~nikita/patches/2.6.14-rc5/03-async-writepage.patch&quot;&gt;&lt;code class=&quot;inline&quot;&gt;async-writepage.patch&lt;/code&gt;&lt;/a&gt;Perform calls to the -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepage()&lt;/code&gt; asynchronously.VM scanner starts pageout for dirty pages found at tail of the inactive list  during scan. It is supposed (or at least desired) that under normal conditions  amount of such write back is small.Even if few pages are paged out by scanner, they still stall &amp;quot;direct reclaim&amp;quot;  path (&lt;code class=&quot;inline&quot;&gt;alloc_pages()&lt;/code&gt; -&amp;gt; &lt;code class=&quot;inline&quot;&gt;try_to_free_pages()&lt;/code&gt; -&amp;gt; ... -&amp;gt; &lt;code class=&quot;inline&quot;&gt;shrink_list()&lt;/code&gt; -&amp;gt;  -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepage()&lt;/code&gt;), and to decrease allocation latency it makes sense to perform  pageout asynchronously.Current design is very simple: asynchronous page-out is done through pdflush  operation &lt;code class=&quot;inline&quot;&gt;kpgout()&lt;/code&gt;. If &lt;code class=&quot;inline&quot;&gt;shrink_list()&lt;/code&gt; decides that page is eligible for the  asynchronous pageout, it is placed into shared queue and later processed by one  of pdflush threads.Most interesting part of this patch is &lt;code class=&quot;inline&quot;&gt;async_writepage()&lt;/code&gt; that decides when page  should be paged out asynchronously. Currently this function allows asynchronous  writepage only from direct reclaim, only if zone memory pressure is not too  high, and only if expected number of dirty pages in the scanned chunk is larger  than some threshold: if there are only few dirty pages on the list, context  switch to the pdflush outwieghts advantages of asynchronous writepage.&lt;a href=&quot;http://linuxhacker.ru/~nikita/patches/2.6.14-rc5/04-page_referenced-move-dirty.patch&quot;&gt;&lt;code class=&quot;inline&quot;&gt;vm_05-page_referenced-move-dirty.patch&lt;/code&gt;&lt;/a&gt;transfer dirtiness from pte to the struct page in &lt;code class=&quot;inline&quot;&gt;page_referenced()&lt;/code&gt;. This makes  pages dirtied through mmap &lt;i&gt;visible&lt;/i&gt; to the file system, that can write them  out through -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepages()&lt;/code&gt; (otherwise pages are written from -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepage()&lt;/code&gt;  from tail of the inactive list).&lt;a href=&quot;http://linuxhacker.ru/~nikita/patches/2.6.14-rc5/05-cluster-pageout.patch&quot;&gt;&lt;code class=&quot;inline&quot;&gt;vm_06-cluster-pageout.patch&lt;/code&gt;&lt;/a&gt;Implement pageout clustering at the VM level.With this patch VM scanner calls &lt;code class=&quot;inline&quot;&gt;pageout_cluster()&lt;/code&gt; instead of  -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepage()&lt;/code&gt;. &lt;code class=&quot;inline&quot;&gt;pageout_cluster()&lt;/code&gt; tries to find a group of dirty pages around  target page, called &lt;i&gt;pivot&lt;/i&gt; page of the cluster. If group of suitable size is  found, -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepages()&lt;/code&gt; is called for it, otherwise, &lt;code class=&quot;inline&quot;&gt;page_cluster()&lt;/code&gt; falls back  to -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepage()&lt;/code&gt;.This is supposed to help in work-loads with significant page-out of  file-system pages from tail of the inactive list (for example, heavy dirtying  through mmap), because file system usually writes multiple pages more  efficiently. Should also be advantageous for file-systems doing delayed  allocation, as in this case they will allocate whole extents at once.Few points:swap-cache pages are not clustered (although they can be, but by page-&amp;gt;private  rather than page-&amp;gt;index)only kswapd do clustering, because direct reclaim path should be low latency.Original version of this patch added new fields to &lt;code class=&quot;inline&quot;&gt;struct writeback_control&lt;/code&gt;   and expected -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepages()&lt;/code&gt; to interpret them. This led to hard-to-fix races   against inode reclamation. Current version simply calls -&amp;gt;&lt;code class=&quot;inline&quot;&gt;writepage()&lt;/code&gt; in the   &amp;quot;correct&amp;quot; order, &lt;i&gt;i.e.&lt;/i&gt;, in the order of increasing page indices..&lt;a href=&quot;http://linuxhacker.ru/~nikita/patches/2.6.14-rc5/06-proc-stack.patch&quot;&gt;&lt;code class=&quot;inline&quot;&gt;vm_07-proc-stack.patch&lt;/code&gt;&lt;/a&gt;Export kernel backtrace in &lt;code class=&quot;inline&quot;&gt;/proc/&amp;lt;pid&amp;gt;/task/&amp;lt;tid&amp;gt;/stack&lt;/code&gt;. Useful when  debugging deadlocks.This somewhat duplicates functionality of SysRq-T, but is less intrusive to the  system operation and can be used in the scripts.Exporting kernel stack of a thread is probably unsound security-wise. Use with  care.Instead of adding yet another architecture specific function to output thread  stack through &lt;code class=&quot;inline&quot;&gt;seq_file API&lt;/code&gt;, it introduces &lt;i&gt;iterator&lt;/i&gt;:void do_with_stack(struct task_struct *tsk, 
     int (*actor)(int, void *, void *, void *), void *opaque)that has to be implemented by each architecture, so that generic code can  iterate over stack frames in architecture-independent way.&lt;code class=&quot;inline&quot;&gt;lib/do_with_stack.c&lt;/code&gt; is provided for archituctures that don&amp;#x27;t implement their  own. It is based on &lt;code class=&quot;inline&quot;&gt;__builtin_{frame,return}&lt;/code&gt;&lt;code class=&quot;inline&quot;&gt;_address()&lt;/code&gt;.&lt;a href=&quot;http://linuxhacker.ru/~nikita/patches/2.6.14-rc5/07-proc-sleep.patch&quot;&gt;&lt;code class=&quot;inline&quot;&gt;vm_08-proc-sleep.patch&lt;/code&gt;&lt;/a&gt;export per-process blocking statistics in &lt;code class=&quot;inline&quot;&gt;/proc/&amp;lt;pid&amp;gt;/task/&amp;lt;tid&amp;gt;/sleep&lt;/code&gt; and  global sleeping statistics in &lt;code class=&quot;inline&quot;&gt;/proc/sleep&lt;/code&gt;. Statistics collection for given  file is activated on the first read of corresponding &lt;code class=&quot;inline&quot;&gt;/proc&lt;/code&gt; file. When  statistics collection is on on each context switch current back-trace is built  (through &lt;code class=&quot;inline&quot;&gt;&lt;code class=&quot;inline&quot;&gt;__&lt;/code&gt;builtin_return_address()&lt;/code&gt;). For each monitored process there is a LRU  list of such back-traces. Useful when trying to understand where elapsed time  is spent.&lt;code class=&quot;inline&quot;&gt;export-filemap_populate-in-proper-place.patch&lt;/code&gt;move &lt;code class=&quot;inline&quot;&gt;EXPORT_SYMBOL(filemap_populate)&lt;/code&gt; to the proper place: just after function  itself: it&amp;#x27;s easy to miss that function is exported otherwise.&lt;a href=&quot;http://linuxhacker.ru/~nikita/patches/2.6.14-rc5/09-throttle-against-free-memory.patch&quot;&gt;&lt;code class=&quot;inline&quot;&gt;throttle-against-free-memory.patch&lt;/code&gt;&lt;/a&gt;Fix write throttling to calculate its thresholds from amount of memory that can  be consumed by file system and swap caches, rather than from the total amount  of physical memory. This avoids situations (among other things) when memory  consumed by kernel slab allocator prevents write throttling from ever  happening.&lt;a href=&quot;http://linuxhacker.ru/~nikita/patches/2.6.14-rc5/0a-BUILD_BUG_ON-fix-comment.patch&quot;&gt;&lt;code class=&quot;inline&quot;&gt;BUILD_BUG_ON-fix-comment.patch&lt;/code&gt;&lt;/a&gt;Fix comment describing &lt;code class=&quot;inline&quot;&gt;BUILD_BUG_ON&lt;/code&gt;: &lt;code class=&quot;inline&quot;&gt;BUG_ON&lt;/code&gt; is not an assertion (unfortunately).Also implement &lt;code class=&quot;inline&quot;&gt;BUILD_BUG_ON&lt;/code&gt; in a way that can be used outside of a function scope, so that compile time checks can be placed in convenient places (like in a header, close to the definition of related constants and data-types).&lt;code class=&quot;inline&quot;&gt;zoneinfo.patch&lt;/code&gt;, &lt;code class=&quot;inline&quot;&gt;deadline-iosched.c-cleanup.patch&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;ll_merge_requests_fn-cleanup.patch&lt;/code&gt; were merged into Linus tree.&lt;code class=&quot;inline&quot;&gt;dont-rotate-active-list.patch&lt;/code&gt; was dropped: it seems to cause inactive list exhaustion for certain wrodloads.</content>
        </item>

        <item>
            <title>plug and crash</title>
            <id>plug-crash</id>
            <link>https://cofault.com/plug-crash.html#plug-crash</link>
            <pubDate>2005/09/13</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/plug-crash.html#plug-crash">
                     I had some problems in my local network to-day, so I had to turn off the switch. &lt;i&gt;Bang!&lt;/i&gt; My workstation hang immediately as power cord was unplugged from the &lt;code class=&quot;inline&quot;&gt;D-Link&lt;/code&gt;. Initially I thought that something is wrong with the grounding, but a series of painful experiments proved that electricity has nothing to do with this: workstation hung whenever Ethernet cable was pulled off the socket. This looks like complete &lt;a href=&quot;http://catb.org/jargon/html/magic-story.html&quot;&gt;magic&lt;/a&gt; &lt;span class=&quot;annotation&quot; data-uid=&quot;1&quot;&gt;[1]&lt;/span&gt; isn&amp;#x27;t it?  Fortunately I was advised to boot kernel with &lt;code class=&quot;inline&quot;&gt;nmi_watchdog=1&lt;/code&gt; (before I went insane, that is), and with the first stack-trace problem became obvious:when cable is pulled, rtl8139 driver receives an interrupt and the first thing  it does is grabbing of spin-lock, protecting struct rtl8139_private...after that it goes to print &amp;quot;link-down&amp;quot; message to the console...but I am using &lt;span class=&quot;annotation&quot; data-uid=&quot;1&quot;&gt;netconsole&lt;/span&gt;, and to print that message netconsole calls back into  rtl8139 driver...and the first thing it does is grabbing of spin-lock... which is already  grabbed by that very thread---deadlock.PS: This is straight &lt;a href=&quot;https://www.usenix.org/system/files/1311_05-08_mickens.pdf&quot;&gt;from The Night Watch&lt;/a&gt;.</content>
        </item>

        <item>
            <title>purelisp: introduction</title>
            <id>purelisp.introduction</id>
            <link>https://cofault.com/purelisp.introduction.html#purelisp.introduction</link>
            <pubDate>2005/04/11</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/purelisp.introduction.html#purelisp.introduction">
                     Some time ago (I just re-checked and... Good Lord it was in &lt;span class=&quot;annotation&quot; data-uid=&quot;4&quot;&gt;October of 2003&lt;/span&gt;, time moves fast indeed) I wrote simple LISP interpreter (purelisp) in Java. This, otherwise seemingly pointless activity could be justified as an exercise in &lt;a href=&quot;http://www.sablecc.org/&quot;&gt;SableCC&lt;/a&gt; usage.SableCCSableCC is a nice compiler building toolkit with pretty standard (by nowaday standards) set of features: on input it takes a description of the language, and produces Java classes with lexer and skeleton parser. Language is defined by a grammar and terminals are defined by regular expressions. Our simple version of LISP uses &lt;span class=&quot;annotation&quot; data-uid=&quot;0&quot;&gt;&lt;code class=&quot;inline&quot;&gt;lisp.grammar&lt;/code&gt;&lt;/span&gt; as the definition, note that larger fraction of language definition is a table indicating what unicode characters are &amp;quot;&lt;i&gt;letters&lt;/i&gt;&amp;quot; in the sense of being acceptable as part of an identifier.From language definition SableCC generates:Java classes corresponding to tokens of the grammar.Lexer class that transforms input stream into sequence of tokens (optionally  omitting some tokens, &lt;i&gt;e.g.&lt;/i&gt;, white-spaces).Parser class that constructs typed AST (abstract syntax tree) from the sequence of tokens.Set of &lt;i&gt;tree-walker&lt;/i&gt; base classes. Tree-walkers traverse tree in specific  order, calling certain methods of tree node object when entering and leaving  it. This is called &amp;quot;&lt;i&gt;visitor pattern&lt;/i&gt;&amp;quot; by the people in dire need of names.The only thing left to do to finish simple interpreter is to subclass suitable tree-walker with the class that interprets program while traversing its AST. LISP program (as LISP fans will never cease to remind us) is but a LISP data, hence, natural choice for our interpreter is to build LISP object as a result of tree traversal. And building such an object is indeed simple: &lt;code class=&quot;inline&quot;&gt;local.purelisp.eval.&lt;span class=&quot;annotation&quot; data-uid=&quot;4&quot;&gt;TreeBuilder&lt;/code&gt;&lt;/span&gt;.purelisp introductionComputational universe of purelisp consists of objects, partitioned into disjoint &lt;i&gt;types&lt;/i&gt;. Objects can be &lt;i&gt;evaluated&lt;/i&gt;. Evaluation takes as input an object to be evaluated and auxiliary object of type &lt;i&gt;environment&lt;/i&gt; that affects evaluation. Result of evaluation is an object again. This can be the same object that is being evaluated, some already existing object, or new object. Ultimately, evaluation can result in error, and no result is produced in this case. Rules of evaluation for some objects are hard-wired into interpreter. For other objects, evaluation is multi-step process defined in terms of some actions performed on other objects.In particular, one important type of objects, &lt;i&gt;viz&lt;/i&gt;. &lt;i&gt;cons cells&lt;/i&gt; have evaluation defined in terms of &lt;i&gt;application&lt;/i&gt; of an object to a sequence of objects (referred to as &lt;i&gt;arguments&lt;/i&gt; of application). Rules of application are again type-dependent: hard-wired into interpreter (&lt;i&gt;e.g.&lt;/i&gt;, for built-in functions), or defined through combination of evaluation and application.Evaluation and application are fundamental mutually-recursive operations on top of which computation is implemented in LISP.LISP program is actually nothing more than description of object according to some standard syntax. LISP interpreter reads this description, build corresponding objects and evaluates it in some &amp;quot;&lt;i&gt;current&lt;/i&gt;&amp;quot; environment.</content>
        </item>

        <item>
            <title>purelisp: object types</title>
            <id>purelisp.object-types</id>
            <link>https://cofault.com/purelisp.object-types.html#purelisp.object-types</link>
            <pubDate>2005/04/11</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/purelisp.object-types.html#purelisp.object-types">
                     As was noted in the previous card, objects in purelisp are partitioned into disjoint types.types of objectsSome LISP object types have &lt;i&gt;read syntax&lt;/i&gt;, which is a way to generate string representation of a given object. Built-in function &lt;code class=&quot;inline&quot;&gt;(read)&lt;/code&gt; builds object given its string representation. Read syntax is given together with description of object types below.&lt;i&gt;Number&lt;/i&gt;. Represent arbitrary range integers (implemented in  &lt;code class=&quot;inline&quot;&gt;local.purelisp.eval.LInt&lt;/code&gt; by &lt;code class=&quot;inline&quot;&gt;java.math.BigInteger&lt;/code&gt;). Number evaluates to  itself, cannot be applied to anything, supports basic arithmetic operations.read syntax for integers10
0o12
0xa
0t1010all represent number 10&lt;i&gt;String&lt;/i&gt;. Evaluates to itself, cannot be applied. Implemented on top of  &lt;code class=&quot;inline&quot;&gt;java.lang.String&lt;/code&gt;.&lt;i&gt;Environment&lt;/i&gt;. Environment is used to evaluate objects of type  &lt;i&gt;symbol&lt;/i&gt;. Specifically, each environment contains &lt;i&gt;bindings&lt;/i&gt; from symbols to  objects. Binding can be thought of as a pair &lt;code class=&quot;inline&quot;&gt;(s, o)&lt;/code&gt;, where &lt;code class=&quot;inline&quot;&gt;s&lt;/code&gt; is a symbol,  and &lt;code class=&quot;inline&quot;&gt;o&lt;/code&gt; is an object &lt;code class=&quot;inline&quot;&gt;s&lt;/code&gt; is bound to. Environment, therefore, is a partial  function from symbols to objects. New bindings can be installed and value  symbol is bound to can be changed.Environments are arranged into tree-like hierarchy: each environment (except  the root of the tree) has parent environment, and if symbol binding is not  found in the environment, search is repeated in the parent  recursively. Environment is said to extend its parent. At the top of the tree  is &lt;i&gt;global environment&lt;/i&gt; that contains bindings for standard LISP  symbols. Interactive interpreter maintains its own environment where user adds  new or modifies existing symbol bindings. There is second environment  hierarchy, not affected by &lt;code class=&quot;inline&quot;&gt;LAMBDA&lt;/code&gt; evaluation, used to implement traditional  LISP dynamic scoping, but it is not current used in the language. Dynamic  parent environment can be accessed through &lt;code class=&quot;inline&quot;&gt;(env-dynamic env)&lt;/code&gt; built-in  function.During computation there always is a so-called current environment. Initially  it is environment of interactive interpreter, later it can be replaced when  applying &lt;code class=&quot;inline&quot;&gt;LAMBDA&lt;/code&gt; functions (see below) or evaluating &lt;code class=&quot;inline&quot;&gt;(eval-in env o)&lt;/code&gt; built-in  function (see below). Evaluation is always performed in the current  environment, and, therefore, there is no need to explicitly mention evaluation  environment.Environments have no read syntax.&lt;i&gt;Symbol&lt;/i&gt;. Symbol is a LISP object with unique name. Name is the only identity  and state that symbol has. Symbols are used to point to other objects. It has  to be stressed that while superficially similar to variables in other  languages, symbols are quite different:symbol has &lt;i&gt;NO&lt;/i&gt; value attached to it. It can be used as a key to look up value   in environment, but in different environments it can have different   values.symbol is first-class object itself: it can be stored in data-structures   including environments (so that value of symbol can be another symbol).Symbols cannot be applied and their evaluation was described above (see   &lt;i&gt;Environment&lt;/i&gt;).Read syntax for a symbol is just its name. If unknown yet valid identifier is  read, new symbol is created.Symbols, integers, and strings are collectively known as &lt;i&gt;atoms&lt;/i&gt;.&lt;i&gt;Cons cell&lt;/i&gt;. Cons cell is a pair of references to other LISP objects. First and seconds references are idiosyncratically known as &lt;code class=&quot;inline&quot;&gt;CAR&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;CDR&lt;/code&gt;, and are accessed through &lt;code class=&quot;inline&quot;&gt;(car c)&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;(cdr c)&lt;/code&gt; built-in functions respectively. Cons cells are used to build linked lists: &lt;code class=&quot;inline&quot;&gt;CAR&lt;/code&gt; of the first cell in a list points to the first object in the list, &lt;code class=&quot;inline&quot;&gt;CDR&lt;/code&gt; point to the second cell in the list, whose &lt;code class=&quot;inline&quot;&gt;CAR&lt;/code&gt; points to the second object in the list, and &lt;code class=&quot;inline&quot;&gt;CDR&lt;/code&gt; points to... List it terminated by the pointer to &lt;code class=&quot;inline&quot;&gt;NIL&lt;/code&gt; (see below).Obviously, much more general possibly cyclic data-structures, can be built from cons cells. We shall call &lt;code class=&quot;inline&quot;&gt;NIL&lt;/code&gt; terminated lists described above &lt;i&gt;well-formed lists&lt;/i&gt;. If list is terminated by reference to an object that is neither cons cell nor &lt;code class=&quot;inline&quot;&gt;NIL&lt;/code&gt;, it will be called &lt;i&gt;dotted list&lt;/i&gt;, otherwise data-structure rooted at the cons cell is called &lt;i&gt;improper list&lt;/i&gt;.read syntax for well-formed lists(1 2 3)
(1 (1 2 &amp;quot;foo&amp;quot;) &amp;quot;bar&amp;quot;)read syntax for dotted lists(1 2 . 3)Note that dotted list notation can be used to represent any cons cell whose &lt;code class=&quot;inline&quot;&gt;CAR&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;CDR&lt;/code&gt; have read syntax: &lt;code class=&quot;inline&quot;&gt;(A . B)&lt;/code&gt; builds cons cell with A as &lt;code class=&quot;inline&quot;&gt;CAR&lt;/code&gt;, and B as &lt;code class=&quot;inline&quot;&gt;CDR&lt;/code&gt;.Cons cell cannot be applied, and has peculiar and very important evaluation rule. To evaluate cons cell following is done in order:if &lt;code class=&quot;inline&quot;&gt;CDR&lt;/code&gt; of cell it not well-formed list, abort evaluation;cell&amp;#x27;s &lt;code class=&quot;inline&quot;&gt;CAR&lt;/code&gt; is evaluated, let&amp;#x27;s call resulting object &lt;code class=&quot;inline&quot;&gt;F&lt;/code&gt;;create copy of &lt;code class=&quot;inline&quot;&gt;CDR&lt;/code&gt; list, &lt;i&gt;i.e.&lt;/i&gt;, create new well-formed list containing pointers  to the same objects and in the same order as &lt;code class=&quot;inline&quot;&gt;CDR&lt;/code&gt; of cell being evaluated. Call  first cons cell of resulting list &lt;code class=&quot;inline&quot;&gt;A0&lt;/code&gt;;if F is built-in function or &lt;code class=&quot;inline&quot;&gt;LAMBDA&lt;/code&gt; function, evaluate all objects in &lt;code class=&quot;inline&quot;&gt;A0&lt;/code&gt; and  create a list of evaluation results called &lt;code class=&quot;inline&quot;&gt;A1&lt;/code&gt;. Otherwise let &lt;code class=&quot;inline&quot;&gt;A1&lt;/code&gt; be &lt;code class=&quot;inline&quot;&gt;A0&lt;/code&gt;;apply &lt;code class=&quot;inline&quot;&gt;F&lt;/code&gt; to &lt;code class=&quot;inline&quot;&gt;A1&lt;/code&gt;.This obviously accounts for neither concurrency nor re-entrancy issues (&lt;i&gt;i.e.&lt;/i&gt;, structure of argument list could change while evaluated, either as result of said evaluation, or due to some concurrent activity).Basically, to evaluate well-formed list, its &lt;code class=&quot;inline&quot;&gt;CAR&lt;/code&gt; is evaluated and applied to the remaining elements of list as arguments. Arguments are evaluated if &lt;code class=&quot;inline&quot;&gt;CAR&lt;/code&gt; evaluates to function (either built-in or &lt;code class=&quot;inline&quot;&gt;LAMBDA&lt;/code&gt;), and are not evaluated otherwise (which leaves us with &lt;code class=&quot;inline&quot;&gt;CAR&lt;/code&gt; evaluating to special form).&lt;code class=&quot;inline&quot;&gt;NIL&lt;/code&gt;. &lt;code class=&quot;inline&quot;&gt;NIL&lt;/code&gt; is a special object the denotes empty list. It is used to define  well-formed lists above. &lt;code class=&quot;inline&quot;&gt;NIL&lt;/code&gt; object is bound to symbol &amp;quot;`nil`&amp;quot; in the global  environment. Cannot be applied, evaluates to itself. As a special exception,  built-in functions &lt;code class=&quot;inline&quot;&gt;(car)&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;(cdr)&lt;/code&gt; can be applied to &lt;code class=&quot;inline&quot;&gt;NIL&lt;/code&gt; and return &lt;code class=&quot;inline&quot;&gt;NIL&lt;/code&gt; in  this case.read syntax for &lt;code class=&quot;inline&quot;&gt;NIL&lt;/code&gt;nil&lt;code class=&quot;inline&quot;&gt;LAMBDA&lt;/code&gt;. &lt;code class=&quot;inline&quot;&gt;LAMBDA&lt;/code&gt; a is LISP object (special form) used to create  lambda-functions. First, the notion of lambda-form is needed. Lambda form is a  cons cell at which following well-formed list is rooted:&lt;code class=&quot;inline&quot;&gt;LAMBDA&lt;/code&gt; form(lambda (P1 ... PM) E1 ... EN)First element of lambda form can be anything that evaluates to &lt;code class=&quot;inline&quot;&gt;LAMBDA&lt;/code&gt; (&lt;i&gt;e.g.&lt;/i&gt;,  &amp;quot;lambda&amp;quot; symbol). Note that this makes notion of lambda-form dependent on the  environment in which form is evaluated.Second element of lambda-form is well-formed list called &lt;i&gt;list of  parameters&lt;/i&gt;. Elements of this list are called &lt;i&gt;parameters&lt;/i&gt;. In traditional  LISP, parameters have to be symbols. Purelisp has some extension (to be  described later.) Parameters list may be empty.Remaining elements of lambda-form are said to constitute its &lt;i&gt;body&lt;/i&gt;. Body may  be empty.&lt;code class=&quot;inline&quot;&gt;LAMBDA&lt;/code&gt; form examples(lambda (x y) y)
(lambda (f) ((lambda (x) (f (x x))) (lambda (y) (f (y y)))))
(lambda nil 3)Lambda-form is not treated in any special way by the interpreter. Instead its  evaluation is done as for any cons cell (see above), and results in application  of &lt;code class=&quot;inline&quot;&gt;LAMBDA&lt;/code&gt; to the list &lt;code class=&quot;inline&quot;&gt;((P1 ... PM) E1 ... EN)&lt;/code&gt;. As &lt;code class=&quot;inline&quot;&gt;LAMBDA&lt;/code&gt; is special form,  elements of this list are not evaluated. Result of this application is new LISP  object: lambda-function.&lt;i&gt;Lambda-function&lt;/i&gt;. Lambda-function can be thought as a pair &lt;code class=&quot;inline&quot;&gt;(ENV, ((P1 ... PM)  E1 ... EN))&lt;/code&gt;, where &lt;code class=&quot;inline&quot;&gt;env&lt;/code&gt; is an environment in which lambda-form was  evaluated. Lambda-function evaluates to itself. Its importance stems from its  application rule. To apply lambda-function &lt;code class=&quot;inline&quot;&gt;(ENV, ((P1 ... PM) E1 ... EN))&lt;/code&gt; to  the list of arguments &lt;code class=&quot;inline&quot;&gt;(A1 ... AK)&lt;/code&gt; do the following:if &lt;code class=&quot;inline&quot;&gt;K != M&lt;/code&gt; abort application;create new environment &lt;code class=&quot;inline&quot;&gt;ELOCAL&lt;/code&gt; extending &lt;code class=&quot;inline&quot;&gt;ENV&lt;/code&gt;;for each &lt;code class=&quot;inline&quot;&gt;i&lt;/code&gt;: &lt;code class=&quot;inline&quot;&gt;1 &amp;lt;= i &amp;lt;= M&lt;/code&gt;, bind &lt;code class=&quot;inline&quot;&gt;Pi&lt;/code&gt; to &lt;code class=&quot;inline&quot;&gt;Ai&lt;/code&gt; in &lt;code class=&quot;inline&quot;&gt;ELOCAL&lt;/code&gt;;for each &lt;code class=&quot;inline&quot;&gt;i&lt;/code&gt;: &lt;code class=&quot;inline&quot;&gt;1 &amp;lt;= i &amp;lt;= N&lt;/code&gt;, evaluate &lt;code class=&quot;inline&quot;&gt;Ei&lt;/code&gt; in &lt;code class=&quot;inline&quot;&gt;ELOCAL&lt;/code&gt;;result of application is the result of EN evaluation, or &lt;code class=&quot;inline&quot;&gt;NIL&lt;/code&gt; if body is empty.Again, this doesn&amp;#x27;t account for pathological cases where structure of lambda-form recorded in lambda-function changes during evaluation.As one can see lambda-functions allow programmer to construct objects with arbitrary application rules, and, therefore (through lists of the form &lt;code class=&quot;inline&quot;&gt;(lambda-function A1 ... AM)&lt;/code&gt;), objects with arbitrary evaluation rules. Lambda-functions are main computation-structuring mechanism in LISP.</content>
        </item>

        <item>
            <title>A Python: it is dictionaries all the way down.</title>
            <id>python-dict</id>
            <link>https://cofault.com/python-dict.html#python-dict</link>
            <pubDate>2022/10/07</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/python-dict.html#python-dict">
                     def drill():
    return defaultdict(drill)</content>
        </item>

        <item>
            <title>When people used to care about the quality of presentation</title>
            <id>qm</id>
            <link>https://cofault.com/qm.html#qm</link>
            <pubDate>2024/03/04</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/qm.html#qm">
                     From Errata to Dijsktra&amp;#x27;s &lt;a href=&quot;https://www.amazon.com/Primer-Algol-Programming-Studies-Processing/dp/0122162501&quot;&gt;A Primer of Algol 60 Programming&lt;/a&gt;.</content>
        </item>

        <item>
            <title>The Question of Life, The Universe, and Everything.</title>
            <id>question</id>
            <link>https://cofault.com/question.html#question</link>
            <pubDate>2005/07/31</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/question.html#question">
                     &amp;#x27;How old is that horse, my friend?&amp;#x27; inquired Mr. Pickwick,rubbing his nose with the shilling he had reserved for the fare.&amp;#x27;&lt;a href=&quot;http://en.wikipedia.org/wiki/The_Answer_to_Life%2C_the_Universe%2C_and_Everything&quot;&gt;Forty-two&lt;/a&gt;,&amp;#x27; replied the driver, eyeing him askant.</content>
        </item>

        <item>
            <title>reiser4: 1. internal tree</title>
            <id>reiser4-internal</id>
            <link>https://cofault.com/reiser4-internal.html#reiser4-internal</link>
            <pubDate>2006/03/26</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/reiser4-internal.html#reiser4-internal">
                     This continues previous entry: &lt;a href=&quot;reiser4-introduction.html#reiser4-introduction-start&quot;&gt;introduction&lt;/a&gt;0. B-trees overview&lt;a href=&quot;http://en.wikipedia.org/wiki/B-tree&quot;&gt;&lt;span class=&quot;linktarget&quot; data-uid=&quot;5&quot;&gt;&lt;span class=&quot;linktarget&quot; data-uid=&quot;0&quot;&gt;&lt;span class=&quot;linktarget&quot; data-uid=&quot;1&quot;&gt;B&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;-tree&lt;/a&gt; is am umbrella term for a variety of similar algorithms used to implement &lt;a href=&quot;http://en.wikipedia.org/wiki/Associative_array&quot;&gt;dictionary&lt;/a&gt; abstraction suitable in a form suitable for external storage. Reiser4 version of this algorithms, officially known as a &lt;a href=&quot;http://en.wikipedia.org/wiki/Dancing_tree&quot;&gt;dancing tree&lt;/a&gt; is closest to the &lt;a href=&quot;http://en.wikipedia.org/wiki/B%2B_tree&quot;&gt;B+-tree&lt;/a&gt;. Basically, in B+-tree user-supplied data records are stored in leaf nodes. Each leaf node keeps records from some particular key range (adjusted dynamically). Each leaf node is referenced from its parent: this reference is a pointer to the child (block number usually) and the smallest key in the key range covered by this leaf. Parent node contains multiple references to its children nodes, again from some particular key range. Parent node may have its own parent and so on until whole key space is covered.Compare this with B-trees proper, where data records are stored at the levels other than leaf one. Also compare this with &lt;a href=&quot;http://en.wikipedia.org/wiki/PATRICIA&quot;&gt;radix tree&lt;/a&gt; (aka PATRICIA) where key range covered by given node is uniquely determined by its level rather than adjusted dynamically as in B-trees.Contents of reiser4 internal tree are initially stored on the disk. As file system operations go on, some blocks from the tree are read into memory and cached there. When new node is added to the tree, it first exists as a block-size buffer in memory. Under some conditions portions of tree are written out from memory back to the stable storage. During write-out, nodes that were marked dirty (either as a result of a modification, or because they are newly created), are written to the appropriate disk block and marked clean. Clean nodes can be discarded from memory.1. lookup and modification&lt;span class=&quot;linktarget&quot; data-uid=&quot;3&quot;&gt;L&lt;/span&gt;ookup operation locates a record with a given key in a tree, or locates a place where such record will be inserted (this place is uniquely identified by a key) if it doesn&amp;#x27;t exist yet. All other tree operations start with lookup, because they have to find a place in a tree identified by given key.Roughly speaking, lookup starts from the top of the tree, searches through index node to find it which of its children given key falls, loads that child node and repeats until it gets to the leaf level. One can say that lookup is top-to-bottom tree operation.This poses two questions:What is the top of a tree and how to find it?How to find out which child node to proceed with?First question seems trivial, because every tree has a root node, right? The problem is that, as will be explained below, concurrent tree modification operation may grow the tree by adding new root to it (so that old root becomes child of a new one), or shrink it by killing existing root. To avoid this, reiser4 tree has special imaginary node, existing only in memory that logically hangs just above root node. First of all, lookup locks this node and learns location of root node from it. After this, it loads root node in memory and releases the lock. This imaginary node is called &lt;a href=&quot;http://en.wiktionary.org/wiki/%C3%BCber&quot;&gt;uber&lt;/a&gt;-node. Curiously enough, Sun ZFS uses exactly the same term for the very similar thing. They even have &lt;code class=&quot;inline&quot;&gt;0x00babl0c&lt;/code&gt; magic number in their disk format, that is supposed to be as close as possible to the pronunciation of &amp;quot;uber block&amp;quot; (even more funny, &amp;quot;bablo&amp;quot; is Russian slang word for money, bucks).To make search for a child node containing given key efficient, keys in the parent node are stored in an ordered array, so that binary search can be used. That binary search is (under many workloads) the single most critical CPU operation.Now we known enough to code reiser4 lookup algorithm (&lt;code class=&quot;inline&quot;&gt;search.c:traverse_tree()&lt;/code&gt;):traverse_tree(key) {
        node     *parent; /* parent node */
        node     *child;  /* child node */
        position  ptr;    /* position of record within node */

        child = ubernode;
        ptr   = ubernode.root; /* put root block number in ptr */

        while (!node_is_leaf(child)) {
                parent = child;
                /* load node, stored at the given block, into memory */
                child = node_at(ptr);
                lock(child);
                ptr = binary_search(child, key);
                unlock(parent);
        }
        return ptr;
}Few comments:&lt;code class=&quot;inline&quot;&gt;position&lt;/code&gt; identifies a record within node. For leaf level this is actual  record with user data, for non-leaf levels, record contains pointers to the  child node.note that lock on the child node is acquired before lock on the parent is  released, that is, two locks are held at some moment. This is traditional tree  traversal technique called lock coupling or lock crabbing.&lt;code class=&quot;inline&quot;&gt;traverse_tree()&lt;/code&gt; returns with ptr positioned at the record with required key  (or at the place where such record would be inserted) and with appropriate leaf  node locked.As was already mentioned above, tree lookup is comparatively expensive (computationally, if nothing more) operation. At the same time, almost everything in reiser4 uses it extensively. As a result, significant effort has been put into making tree lookup more efficient. Algorithm itself doesn&amp;#x27;t leave much to be desired: its core is binary search and it can be optimized only that far. Instead, multiple mechanisms were developed that allows to bypass full tree lookup under some conditions. These mechanisms are:&lt;a href=&quot;#reiser4-internal-seals&quot;&gt;seals&lt;/a&gt;&lt;a href=&quot;#reiser4-internal-vroot&quot;&gt;vroot&lt;/a&gt;&lt;a href=&quot;#reiser4-internal-look-aside-cache&quot;&gt;look-aside cache&lt;/a&gt; (cbk cache)1.1. seals&lt;span class=&quot;linktarget&quot; data-uid=&quot;3&quot;&gt;A&lt;/span&gt; seal is a weak pointer to a record in the tree. Every node in a tree maintains version counter, that is incremented on each node modification. After lookup for a given key was performed, seal can be created that remembers block number of found leaf node and its version counter at the moment of lookup. Seal verification process checks that node recorded in the seal is still in the tree and that its version counter is still the same as recorded. If both conditions are met, pointer to the record returned by lookup can still be used, and additional lookup for the same key can be avoided.1.2. vroot&lt;span class=&quot;linktarget&quot; data-uid=&quot;1&quot;&gt;H&lt;/span&gt;igher-level file system object such as regular files and directories is represented as a set of tree records. Keys of these records are usually confined in some key range, and, due to the nature of B-trees, are all stored in the nodes having common ancestor node that is not necessary root. That is, records constituting given object are located in some subtree of reiser4 internal tree. Idea of vroot (virtual root) optimization is to track root of that sub-tree and to start lookups for object records from vroot rather than from real tree root. vroot is updated lazily: when lookup finds that tree was modified so that object subtree is no longer rooted at vroot, tree traversal restarts from real tree root and vroot is determined during descent.Additional important advantage of vroot is that is decreases lock contention for the root node.1.3. look-aside cache&lt;span class=&quot;linktarget&quot; data-uid=&quot;4&quot;&gt;L&lt;/span&gt;ook-aside cache is simply a list of last N leaf nodes returned by tree lookup. This list is consulted before embarking into full-blown top-to-bottom traversal. This simple mechanism works due to &lt;a href=&quot;http://en.wikipedia.org/wiki/Locality_of_reference&quot;&gt;locality of reference&lt;/a&gt; for tree accesses.To be continued:2. concurrency control: lock ordering, hi-lo ordering 3. eottl 4. node format</content>
        </item>

        <item>
            <title>reiser4: 0. introduction</title>
            <id>reiser4-introduction</id>
            <link>https://cofault.com/reiser4-introduction.html#reiser4-introduction</link>
            <pubDate>2005/12/18</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/reiser4-introduction.html#reiser4-introduction">
                     &lt;span class=&quot;linktarget&quot; data-uid=&quot;2&quot;&gt;T&lt;/span&gt;his is an introduction to the series of entries I am going to write about reiser4 file system. The plan, for the time being, goes like this:0. introduction0. &lt;a href=&quot;#reiser4-introduction-trivia&quot;&gt;trivia&lt;/a&gt;1. &lt;a href=&quot;#reiser4-introduction-strong-points&quot;&gt;reiser4 strong points&lt;/a&gt;2. &lt;a href=&quot;#reiser4-introduction-architecture-overview&quot;&gt;architecture overview&lt;/a&gt;1. &lt;a href=&quot;reiser4-internal.html#reiser4-internal-start&quot;&gt;internal tree&lt;/a&gt;0. &lt;a href=&quot;reiser4-internal.html#reiser4-internal-start&quot;&gt;B-trees overview&lt;/a&gt;1. &lt;a href=&quot;reiser4-internal.html#reiser4-internal-lookup-and-modification&quot;&gt;lookup and modification&lt;/a&gt;2. concurrency control: lock ordering, hi-lo ordering3. eottl4. node format2. tree clients0. regular file1. tail to extent conversion3. transaction engine0. goals: atomicity, no isolation, durability1. log structure2. shadow updates4. directory code0. overview of hashed directories1. key structure and its motivation2. lookup readdir3. NFS?5. delayed allocation and the flush algorithm0. delayed allocation motivation1. flush algorithm2. overview of interaction with VM3. emergency flush6. round up0. trivia&lt;span class=&quot;linktarget&quot; data-uid=&quot;0&quot;&gt;&lt;a href=&quot;http://namesys.com/v4/v4.html&quot;&gt;R&lt;/span&gt;eiser4&lt;/a&gt; is a relatively new file system for Linux developed by &lt;a href=&quot;http://namesys.com&quot;&gt;namesys&lt;/a&gt;. Its development started early in 2001, and currently reiser4 is included into &lt;a href=&quot;ftp://ftp.kernel.org/pub/linux/kernel/people/akpm/patches/2.6&quot;&gt;&lt;code class=&quot;inline&quot;&gt;-mm&lt;/code&gt;&lt;/a&gt; patch series. &lt;a href=&quot;http://namesys.com/v4/v4.html&quot;&gt;Reiser4&lt;/a&gt; is a next version of well-known reiserfs v3 file system (also known as simply reiserfs) that was first and for a long time the only journalled file system for Linux. While reiser4 is based on the same basic architectural ideas as reiserfs v3 it was written completely from scratch and its on-disk format is not compatible with reiserfs. Note on naming: &lt;a href=&quot;http://namesys.com&quot;&gt;namesys&lt;/a&gt; insists that file system is referred to as reiser4 and not reiserfs v4, or reiser4fs, or reiserfs4, or r4fs. Development of reiser4 was sponsored by &lt;a href=&quot;http://darpa.mil&quot;&gt;DARPA&lt;/a&gt;, take a look at the &lt;a href=&quot;http://namesys.com&quot;&gt;namesys&lt;/a&gt; front page for a legal statement, and a list of other sponsors.Technically speaking reiser4 can be briefly discussed as a file system usingglobal shared balanced lazily compacted tree to store all data and meta-databitmaps for block allocationredo-only WAL (write ahead logging) with shadows updates (called &amp;quot;wandered logs&amp;quot; in reiser4)delayed allocation in parent-first tree orderingI shall (hopefully) describe these topics in more details in the future entries.One last trivia point: I was amongst reiser4 &lt;a href=&quot;http://namesys.com/devels.html&quot;&gt;developers&lt;/a&gt; from the very beginning of this project. At the mid-2004 I left namesys, at that point reiser4 was in more or less debugged state, and no significant design changes occurred since.1. reiser4 strong points&lt;span class=&quot;linktarget&quot; data-uid=&quot;3&quot;&gt;T&lt;/span&gt;ogether with the unique design, reiser4 inherited reiserfs&amp;#x27; strengths and weaknesses:efficient support for very small files: multiple small files can be stored in  the same disk block. This saves disk space, and &lt;i&gt;much more importantly&lt;/i&gt; IO  traffic between secondary and primary storage;support for very large directories: due to balanced tree (to be described  later), file system can handle directories with hundreds of million of  files. The utility of this (and small files support) is often questioned,  because &amp;quot;nobody uses file system in that way&amp;quot;. Reiser4 design is based on the  assumption, that cause-and-effect goes in the opposite direction here:  applications do not use large directories and small files precisely because  existing file system didn&amp;#x27;t provide efficient means for this. Instead,  application developers had to resort to various hacks from configuration files  (that have obvious hierarchical structure asking for being mapped onto file  system), to artificially splitting large directory into smaller ones (look at  &lt;a href=&quot;file:///usr/share/terminfo/&quot;&gt;&lt;code class=&quot;inline&quot;&gt;/usr/share/terminfo/&lt;/code&gt;&lt;/a&gt; directory as an example);no hard limit on the number of objects on the file system. Traditional UNIX  file systems (s5fs,ffs,ufs,ext2,ext3) fix total number of objects that can  exist on a file system during file system creation. Correct estimation of this  number is a tricky business. Reiser4, on the other hand, creates on-disk inodes  (called &amp;quot;stat data&amp;quot; for historical reasons) dynamically;previous item can be seen as a weakness, because it means that reiser4 on-disk  format is more complex than that of its brethren. Other advanced reiser4  features also come not without an increase of format complexity. As a result,  reiser4 can be corrupted in much more complicated ways than other file systems,  requiring quite sophisticated fsck.2. architecture overview&lt;span class=&quot;linktarget&quot; data-uid=&quot;4&quot;&gt;A&lt;/span&gt;s was already hinted above reiser4 is quite different from other file systems architecturally. The most important difference, perhaps, is that reiser4 introduces another layer (&amp;quot;storage layer&amp;quot;) between file system and block device. This layer provides an abstraction of persistent &amp;quot;container&amp;quot; into which pieces of data (called &amp;quot;units&amp;quot;) can be placed and later retrieved. Units are identified by &amp;quot;keys&amp;quot;: when unit is placed into container a key is given, and unit can later be retrieved by providing its key. Unit key is just a fixed-length sequence of bits.In reiser4 this container abstraction is implemented in a form of special flavor of &lt;a href=&quot;http://en.wikipedia.org/wiki/B_tree&quot;&gt;B-tree&lt;/a&gt;. There is one instance of such tree (referred to as &amp;quot;internal tree&amp;quot;) per file system.Entities from which file system is composed (regular files, directories, symlinks, on-disk inodes, &lt;i&gt;etc&lt;/i&gt;.) are stored in the internal tree as sequences of units.In addition to presenting container abstraction, storage layer is responsible for block allocation. That is, as units are inserted and deleted, tree grows and shrinks, taking blocks from block allocator and returning them back. Block allocation policy implemented by storage layer is very simple:units with close keys are kept as close on disk as possible, andunits should be placed in the disk blocks so that key ordering corresponds to  the block ordering on disk.This allows higher layers of the system to influence location of units on disk by selecting unit keys appropriately.While this doesn&amp;#x27;t sound especially exciting, key-based block allocation allows reiser4 to implement one extremely important feature: global block allocation policies. For example, by assigning to units of all objects in a given directory keys with the same prefix, higher layer code can assure that all objects located in this directory will be located close to each other on the disk. Moreover, by selecting next few bits of key based on --say-- file name it is possible to arrange all objects in the directory in the same order as readdir returns their names, so that commands like$ cp -a * /somewherewill not cause a single seek during read. More on this in the section on &amp;quot;delayed allocation and the flush algorithm&amp;quot;.So the highest layer in reiser4 implements file system semantics using storage layer as a container. Storage layer uses block allocator to manage disk space and transaction engine to keep file system consistent in case of a crash. Transaction layer talks to block device layer to send data to the storage.To Be Continued by: &lt;a href=&quot;reiser4-internal.html#reiser4-internal-start&quot;&gt;internal tree&lt;/a&gt;.</content>
        </item>

        <item>
            <title>Repaging in AIX VM</title>
            <id>repaging-aix</id>
            <link>https://cofault.com/repaging-aix.html#repaging-aix</link>
            <pubDate>2005/07/25</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/repaging-aix.html#repaging-aix">
                     &lt;a href=&quot;http://www.unet.univie.ac.at/aix/aixbman/prftungd/vmmov.htm&quot;&gt;&lt;i&gt;Repaging&lt;/i&gt;&lt;/a&gt; was mentioned to me by Rik van Riel long time ago. How this can be implemented in Linux? E.g., add &lt;code class=&quot;inline&quot;&gt;-&amp;gt;repage_tree&lt;/code&gt; radix-tree to &lt;code class=&quot;inline&quot;&gt;struct address_space&lt;/code&gt;. (We get 32 bits per-page this way, while we need only one!) Insert entry into this tree on each page fault. Do &lt;i&gt;not&lt;/i&gt; remove entry when page is reclaimed. As a result, &lt;code class=&quot;inline&quot;&gt;-&amp;gt;repage_tree&lt;/code&gt; keeps history of page faults. Check it on page fault. If there is an entry for page being faulted in---we have &amp;quot;repage&amp;quot;. Maintain global counter of elements in &lt;code class=&quot;inline&quot;&gt;-&amp;gt;repage_tree&lt;/code&gt;&amp;#x27;s. When it&amp;#x27;s higher than some threshold (AIX uses total number of frames in the primary storage), start removing &lt;code class=&quot;inline&quot;&gt;-&amp;gt;repage_tree&lt;/code&gt; elements on reclaim. Disadvantage: history is lost when &lt;code class=&quot;inline&quot;&gt;struct address_space&lt;/code&gt; is destroyed.</content>
        </item>

        <item>
            <title>Riemann hypothesis, DIY</title>
            <id>riemann</id>
            <link>https://cofault.com/riemann.html#riemann</link>
            <pubDate>2012/03/03</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/riemann.html#riemann">
                     Continuing with &lt;a href=&quot;exercise.html#exercise-start&quot;&gt;useless exercises&lt;/a&gt;, let&amp;#x27;s look at &lt;a href=&quot;http://en.wikipedia.org/wiki/Prime_number&quot;&gt;prime numbers&lt;/a&gt;. We shall use &lt;a href=&quot;http://en.wikipedia.org/wiki/Haskell_(programming_language)&quot;&gt;Haskell&lt;/a&gt; this time.-- prime numbers: [2,3,5,7,11,13,17,19, ...]
pr :: [Int]
pr = [p | p &amp;lt;- [2 .. ], maximum [d | d &amp;lt;- [1 .. p - 1], p `mod` d == 0] == 1]The first line, starting with &lt;code class=&quot;inline&quot;&gt;--&lt;/code&gt; is a comment. The second line declares &lt;code class=&quot;inline&quot;&gt;pr&lt;/code&gt; to have type &amp;quot;list of Int&amp;quot;. Typings are optional in Haskell. The last line, uses &amp;quot;&lt;a href=&quot;http://en.wikipedia.org/wiki/List_comprehension&quot;&gt;list comprehension&lt;/a&gt;&amp;quot; (yes, it is related to &amp;quot;&lt;a href=&quot;http://en.wikipedia.org/wiki/Set-builder_notation&quot;&gt;set comprehension&lt;/a&gt;&amp;quot; used in &lt;a href=&quot;unintentionally.html#unintentionally-start&quot;&gt;one of the recent posts&lt;/a&gt;) to define &amp;#x27;pr&amp;#x27; as those elements of the infinite list &lt;code class=&quot;inline&quot;&gt;[2, 3, 4, 5, ...]&lt;/code&gt; (denoted &lt;code class=&quot;inline&quot;&gt;[2 ...]&lt;/code&gt;), whose maximal proper divisor is &lt;code class=&quot;inline&quot;&gt;1&lt;/code&gt;. This is a very inefficient, quadratic way to build the list of all primes.In addition, define a list of all &lt;a href=&quot;http://en.wikipedia.org/wiki/Twin_prime&quot;&gt;twin primes&lt;/a&gt;:-- twin primes, primes whose difference is 2
twinp :: [Int]
twinp = [n | n &amp;lt;- pr, (n + 2) `elem` (take (n + 4) pr)]&lt;code class=&quot;inline&quot;&gt;elem&lt;/code&gt; is true &lt;a href=&quot;http://en.wikipedia.org/wiki/Iff&quot;&gt;iff&lt;/a&gt; &lt;code class=&quot;inline&quot;&gt;x&lt;/code&gt; is en element of list &lt;code class=&quot;inline&quot;&gt;s&lt;/code&gt;. Ugly &lt;code class=&quot;inline&quot;&gt;(take (n + 4) pr)&lt;/code&gt; is needed because for an infinite &lt;code class=&quot;inline&quot;&gt;s&lt;/code&gt;, &lt;code class=&quot;inline&quot;&gt;elem&lt;/code&gt; either returns &lt;code class=&quot;inline&quot;&gt;True&lt;/code&gt; or never returns: without some additional knowledge about the list, the only way to determine whether &lt;code class=&quot;inline&quot;&gt;x&lt;/code&gt; belongs to it is by linear search, which might never terminate. In our case, &lt;code class=&quot;inline&quot;&gt;pr&lt;/code&gt; is strictly ascending and hence the search can be limited to some finite prefix of the list (&lt;code class=&quot;inline&quot;&gt;(take n s)&lt;/code&gt; returns first n elements of s). Perhaps there is a way to specify list properties that &lt;code class=&quot;inline&quot;&gt;elem&lt;/code&gt; can rely on, I don&amp;#x27;t know, I opened &lt;a href=&quot;http://www.haskell.org/onlinereport/haskell2010/haskell.html#haskellpa1.html&quot;&gt;the Haskell specification&lt;/a&gt; an only hour ago.Let&amp;#x27;s do some &amp;quot;visualisation&amp;quot;:-- an (infinite) string containing a &amp;#x27;+&amp;#x27; for each element of s and &amp;#x27;.&amp;#x27; for each
-- element not in s, assuming that s is ascending and s !! n &amp;gt; n.
-- dot pr == &amp;quot;..++.+.+...+.+.. ...&amp;quot;
dot :: [Int] -&amp;gt; [Char]
dot s = [ if (x `elem` (take (x + 2) s)) then &amp;#x27;+&amp;#x27; else &amp;#x27;.&amp;#x27; | x &amp;lt;- [0 ..]]For example, &lt;code class=&quot;inline&quot;&gt;(dot pr)&lt;/code&gt; is an infinite string containing &lt;code class=&quot;inline&quot;&gt;+&lt;/code&gt; for each prime number and &lt;code class=&quot;inline&quot;&gt;.&lt;/code&gt; for each composite.By printing &lt;code class=&quot;inline&quot;&gt;(dot s)&lt;/code&gt; in rows, &lt;code class=&quot;inline&quot;&gt;k&lt;/code&gt; columns each, some hopefully interesting information about distribution of elements of s can be obtained. First, split &lt;code class=&quot;inline&quot;&gt;s&lt;/code&gt; into sub-lists of length &lt;code class=&quot;inline&quot;&gt;k&lt;/code&gt;:-- (dot s), sliced into sub-strings of length k, separated by newlines
sl :: [Int] -&amp;gt; Int -&amp;gt; [[Char]]
sl s k = [&amp;#x27;\n&amp;#x27; : [ (dot s) !! i | i &amp;lt;- [j*k .. (j+1)*k - 1]] | j &amp;lt;- [0 ..]]then, concatenate them all:-- concatenation of slices
outp :: [Int] -&amp;gt; Int -&amp;gt; [Char]
outp s k = concat (sl s k)A few examples:putStr (outp pr 6)

..++.+
.+...+
.+...+
.+...+
.....+
.+....
.+...+
.+...+
.....+
.....+
.+....
.+...+immediately one sees that, with the exception \(2\) and \(3\), prime numbers have remainder \(1\) or \(5\) when divided by \(6\). For \(7\), the picture isputStr (outp pr 7)

..++.+.
+...+.+
...+.+.
..+....
.+.+...
..+...+
.+...+.
....+..
...+.+.
....+..
.+.+...
..+...+
.....+.
......+
...+.+.
..+.+..
.+.....
.......
.+...+.
....+.+
.......
..+.+..
...+...
..+...+it&amp;#x27;s easy to see that &amp;quot;vertical&amp;quot; lines of &lt;code class=&quot;inline&quot;&gt;+&lt;/code&gt;, corresponding to a particular remainder are now (unsurprisingly) replaced with slopes. By changing the width of the picture, one can see how regular pattern changes its shape periodicallyputStr (outp pr 23)

..++.+.+...+.+...+.+...
+.....+.+.....+...+.+..
.+.....+.....+.+.....+.
..+.+.....+...+.....+..
.....+...+.+...+.+...+.
............+...+.....+
.+.........+.+.....+...
..+...+.....+.....+.+..
.......+.+...+.+.......
....+...........+...+.+
...+.....+.+.........+.
....+.....+.....+.+....
.+...+.+.........+.....
........+...+.+...+....
.........+.....+.......
..+.+...+.....+.......+
.....+.....+...+.....+.
......+...+.......+....
.....+.+.........+.+...
..+...+.....+.......+..
.+.+...+...........+...putStr (outp pr 24)

..++.+.+...+.+...+.+...+
.....+.+.....+...+.+...+
.....+.....+.+.....+...+
.+.....+...+.....+......
.+...+.+...+.+...+......
.......+...+.....+.+....
.....+.+.....+.....+...+
.....+.....+.+.........+
.+...+.+...........+....
.......+...+.+...+.....+
.+.........+.....+.....+
.....+.+.....+...+.+....
.....+.............+...+
.+...+.............+....
.+.........+.+...+.....+
.......+.....+.....+...+
.....+.......+...+......
.+.........+.+.........+
.+.....+...+.....+......
.+...+.+...+...........+
.......+...+.......+...+One of the more striking examples is with twin primes:putStr (outp twinp 6)

...+.+
.....+
.....+
......
.....+
......
.....+
......
......
.....+
......
.....+
......
......
......
......
.....+
.....+
......
......Every pair of twin primes except for \((3, 5)\) has a form \((6 \cdot n - 1,\; 6 \cdot n + 1)\).As Gauss reportedly quipped (when refusing to work on the last Fermat&amp;#x27;s theorem): &amp;quot;number theory is full of problems whose difficulty is only surpassed by their uselessness&amp;quot;.</content>
        </item>

        <item>
            <title>RSX</title>
            <id>rsx</id>
            <link>https://cofault.com/rsx.html#rsx</link>
            <pubDate>2005/03/24</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/rsx.html#rsx">
                     [expanded. 2004.03.25]Lately, I looked through sources of RSX &lt;i&gt;executive&lt;/i&gt; at &lt;a href=&quot;http://www.bitsavers.org&quot;&gt;bitsavers.org&lt;/a&gt;. RSX (which stands for Realtime System eXecutive or Resource Sharing eXecitive) is a collective name for the series of operating systems &lt;code class=&quot;inline&quot;&gt;DEC&lt;/code&gt; developed for its &lt;code class=&quot;inline&quot;&gt;PDP&lt;/code&gt; processors. Initial version was RSX-15 developed for PDP-15 processor (a member of 18b family of DEC processors---poorer and ultimately abandoned cousins of another branch that got us PDP-11) by Sam Reese, &lt;a href=&quot;http://www.demillar.com/RSX/&quot;&gt;Dan Brevik&lt;/a&gt;, Hank Krejci and Bernard LaCroute. See: &lt;a href=&quot;http://groups-beta.google.com/group/comp.os.vms/msg/51870e4fc2d88da5?output=gplain&quot;&gt;a bit of history&lt;/a&gt;, &lt;a href=&quot;http://www.demillar.com/RSX/RSXdocument.pdf&quot;&gt;original design&lt;/a&gt;, official DEC &lt;a href=&quot;http://www.bitsavers.org/pdf/dec/pdp15/DEC-15-GRQA-D_RSX15_1971.pdf&quot;&gt;reference manual&lt;/a&gt;. Later on, RSX was ported to PDP-11 (yes, version numbers can very well go down), resulting in succession of RSX-11A, RSX-11B, RSX-11C, and RSX-11D, the latter being full-blown operating system, multi-user and multi-tasking. You think it&amp;#x27;s quite an achievement for a platform with 32K bytes of primary storage? Obviously David Cutler wasn&amp;#x27;t impressed, as he re-wrote it from scratch to consume less resources giving birth to RSX-11M (and later to VAX/VMS, and Windows NT). Unfortunately, no RSX-11 kernel sources seem available (neither A-D, nor M and beyond versions), except for little witty pieces&lt;a href=&quot;http://article.gmane.org/gmane.os.netbsd.ports.vax/1479&quot;&gt; here&lt;/a&gt; and &lt;a href=&quot;http://www.omlettesoft.com/listquotes.php3?index=394&quot;&gt;there&lt;/a&gt; (bitsavers, however sports &lt;a href=&quot;http://www.bitsavers.org/pdf/dec/pdp11/rsx11/OS_internalsCourse_1983/&quot;&gt;materials&lt;/a&gt; from DEC&amp;#x27;s classes on RSX-11 internals). XVM/RSX-15 sources are available at bitsavers:Executive proper: &lt;a href=&quot;http://www.bitsavers.org/bits/DEC/pdp15/dectape/XVM_RSX/_textfiles/DEC-XV-IXRAA-A-UA4_02-28-77/RSX.P1_160.txt&quot;&gt;P1&lt;/a&gt; and &lt;a href=&quot;http://www.bitsavers.org/bits/DEC/pdp15/dectape/XVM_RSX/_textfiles/DEC-XV-IXRAA-A-UC1_02-28-77/RSX.P2_161.txt&quot;&gt;P2&lt;/a&gt;, and&lt;a href=&quot;http://www.bitsavers.org/bits/DEC/pdp15/dectape/XVM_RSX/_textfiles/DEC-XV-IXRAA-A-UA5_02-28-77/&quot;&gt;MCR&lt;/a&gt; (Monitor Console Routine)Why would one waste time looking through the obscure non-portable kernel that ran on a hardware decommissioned quarter of century ago? A lot of reasons:It is radically different from UNIX, which is, basically, the only publicly  available kernel source base to-day.It was written at the times when computing was still young and engineers didn&amp;#x27;t  take a lot of things for granted, so one can see how and why they come to their  designs.It&amp;#x27;s rather small by nowadays standards and easy to understand.It has surprisingly good comments.It was one of the first and probably (for quite a long time) largest  open-source projects: hundreds of megabytes of software for RSX were available  in the source form (&lt;a href=&quot;http://www.trailing-edge.com/~shoppa/freewareFAQ.html&quot;&gt;DECUS tapes&lt;/a&gt;)I agree with the sentiments R. Pike, &lt;i&gt;esq.&lt;/i&gt; expressed in Systems Software  Research is Irrelevant article (also see Rik van Riel&amp;#x27;s &lt;a href=&quot;http://surriel.com/research_wanted/&quot;&gt;note&lt;/a&gt;): modern operating  system research revolves around (or, rather, inside of) a cluster of well-known  old ideas. By looking at the roots of operating system development, one sees  that these ideas are but &lt;i&gt;choices&lt;/i&gt;.Nostalgia, of course. At the end of 80s I worked on some PDP &lt;a href=&quot;http://www.village.org/pdp-11/faq&quot;&gt;clones&lt;/a&gt;:  Электроника-100/25, СМ-4.At the center of RSX-15 is its executive, also known as monitor or kernel. This is small program written in PDP-15 assembly language, that maintains following abstractions:memory partitioningrudimentary memory management scheme. Memory is partitioned during system   generation into &lt;i&gt;partitions&lt;/i&gt; and &lt;i&gt;common blocks&lt;/i&gt;.task and scheduling.Task is a machine code that can be executed under control of executive. Task   is &lt;i&gt;installed&lt;/i&gt; when it is known to the executive (specifically, registered in   STL---global System Task List). Tasks are created by &lt;i&gt;task builder&lt;/i&gt;---special   task that builds task by linking relocatable code with libraries and storing   task on disk in the same format it will be stored in the primary storage   (&lt;i&gt;i.e.&lt;/i&gt;, task loading is just copying it from disk to the core, which is   important for &lt;i&gt;real-time&lt;/i&gt; operating system). Some tasks are resident, which   means they are always in core. Installed task may be requested for execution   (placed into ATL---Active Task List), and get its share of processor cycles   subject to priority and memory constraints. Simple fixed priority scheme is   used. Memory is managed on partition granularity: each task has a partition   assigned to it during build, and will be loaded into core when said partition   is free. Partition can be used for one task only.interrupt managementexecutive itself handles clock interrupt only. All other interrupts are   handled by special IO Handler Tasks (IOHTs), any installed task may become   IOHT by &lt;i&gt;connecting&lt;/i&gt; to interrupt line.device management.list of physical devices and mapping between physical and logical   units (LUNs). Per-device prioritized IO queues. Asynchronous IO as a default   mechanism. LUNs are global.interface to space management for disksbitmap of free blocks. Implemented by IO handler task, not executive.interface to simple flat file system.Implemented by IO handler task.&lt;b&gt;&lt;span class=&quot;align-centre&quot;&gt;To be continued...&lt;/span&gt;&lt;/b&gt;Here are some interesting features:usage of API (Automatic Priority Interrupts) to implement concurrency control.In RSX-11M this was replaced with FORK processing: interrupts never directly  access kernel tables, hence, no synchronization is required on the  uniprocessor. Similar to soft interrupts.separation of STL (system task list) and ATL (active task list)---a form of two    level scheduling: long level scheduling decisions are made by installing task    into STL, and assigning resources (devices and core partitions) to it. Short    term scheduling is done by scanning ATL which is sorted by task priority.interrupt is viewed (and used) more like asynchronous goto, rather than    asynchronous procedure call. For example, there is a procedure that scans ATL    (active task list, sorted by task priority). Interrupt may add task to the    ATL, and so scan has to be restarted if interrupt happens during it. To    achieve this, interrupt handlers do a jump to the address stored in L6TV    (&amp;quot;Level Six Transfer Vector&amp;quot;). When normal task runs, L6TV points to the    routine that saves registers in the task&amp;#x27;s &amp;quot;core partition&amp;quot;. When ATL scan is    started, L6TV is modified to point to the ATL scan procedure itself. As a    result, if interrupt happens, scan will be restarted automatically. Note,    that interrupt handlers do &lt;i&gt;not&lt;/i&gt; save registers in the stack (they do not    create stack frame).&amp;quot;pseudo partitions&amp;quot; that overlay IO memory used to control devices from    non-privileged tasks.RSX is a &lt;i&gt;radical&lt;/i&gt; micro-kernel: the only thing executive handles is processor    scheduling. Everything else (including processing of interrupts other than    clock) is handled by tasks. One consequence of this is that executive    interface is fundamentally asynchronous: most calls take &lt;i&gt;event variable&lt;/i&gt; as    an argument, and calling task may wait for call completion by doing    &lt;code class=&quot;inline&quot;&gt;WAITFOR eventvar&lt;/code&gt; This is impossible to do in UNIX where system calls are served on    the kernel stack permanently attached to the process. In UNIX, kernel is a    &lt;i&gt;library&lt;/i&gt; executing in protected mode, while RSX is a collection of    autonomous tasks each running with its own stack (this architecture, of    course, requires very fast context switches).file system as special device driver layered on top of driver for underlying    stable storage device: &lt;i&gt;file oriented device&lt;/i&gt;. Note, that this also unifies    the notion of file and device, but... other way around.&lt;code class=&quot;inline&quot;&gt;SEEK&lt;/code&gt; call is used to open particular file on a devcie. After that LUN is    effectively &lt;i&gt;narrowed&lt;/i&gt; (in EMACS sense) to mean opened file.all executables are known to the executive (listed in STL).system image can be stored on the permanent storage (by &lt;code class=&quot;inline&quot;&gt;SAVE&lt;/code&gt;) and booted from  (warm start), like in Smalltalk or LISP system.instead of having separate run-queues and wait-queues, tasks are kept in single  ATL. As the only synchronization mechanism available is event variable,  &amp;quot;scheduler&amp;quot; simply checks whether waiting tasks can be run while scanning  ATL.tasks are so light-weight that clock queue (&lt;i&gt;callouts&lt;/i&gt; in UNIX terms) is a list  of tasks rather than functions.each task provides its own procedure to save its context on preemptno security of any sort. Give them enough rope.</content>
        </item>

        <item>
            <title>Side with effete.</title>
            <id>side-effete</id>
            <link>https://cofault.com/side-effete.html#side-effete</link>
            <pubDate>2012/11/09</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/side-effete.html#side-effete">
                     More of „I know C better than you!“ stuff.I just discovered (the verb is deeply characteristic) how to write a &lt;code class=&quot;inline&quot;&gt;HAS_SIDE_EFFECTS(expr)&lt;/code&gt; macro that doesn&amp;#x27;t evaluate &lt;code class=&quot;inline&quot;&gt;expr&lt;/code&gt; and returns true iff expr has side-effects.The macro essentially depends on a GCC extension. It is useful, for example, as a sanity check in conditionally compiled code, &lt;i&gt;e.g.&lt;/i&gt;, in &lt;code class=&quot;inline&quot;&gt;assert(expr)&lt;/code&gt;.</content>
        </item>

        <item>
            <title>A curious case of stacks and queues.</title>
            <id>stack-queue</id>
            <link>https://cofault.com/stack-queue.html#stack-queue</link>
            <pubDate>2020/11/11</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/stack-queue.html#stack-queue">
                     When studying computing science we all learn how to convert an expression in the &amp;quot;normal&amp;quot; (&amp;quot;&lt;a href=&quot;https://en.wikipedia.org/wiki/Infix_notation&quot;&gt;infix&lt;/a&gt;&amp;quot;, &amp;quot;algebraic&amp;quot;) notation to &amp;quot;&lt;a href=&quot;https://en.wikipedia.org/wiki/Reverse_Polish_notation&quot;&gt;reverse Polish&lt;/a&gt;&amp;quot; notation. For example, an expression &lt;code class=&quot;inline&quot;&gt;a/b + c/d&lt;/code&gt; is converted to &lt;code class=&quot;inline&quot;&gt;b a / d c / +&lt;/code&gt;. An expression in Polish notation can be seen as a program for &lt;a href=&quot;https://en.wikipedia.org/wiki/Pushdown_automaton&quot;&gt;a stack automaton&lt;/a&gt;:PUSH b
PUSH a
DIV
PUSH d
PUSH c
DIV
ADDWhere &lt;code class=&quot;inline&quot;&gt;PUSH&lt;/code&gt; pushes its argument on the top of the (implicit) stack, while &lt;code class=&quot;inline&quot;&gt;ADD&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;DIV&lt;/code&gt; pop 2 top elements from the stack, perform the respective operation and push the result back.For reasons that will be clearer anon, let&amp;#x27;s re-write this program asContainer c;
c.put(b);
c.put(a);
c.put(c.get() / c.get())
c.put(d);
c.put(c);
c.put(c.get() / c.get())
c.put(c.get() + c.get())Where &lt;code class=&quot;inline&quot;&gt;Container&lt;/code&gt; is the type of stacks, &lt;code class=&quot;inline&quot;&gt;c.put()&lt;/code&gt; pushes the element on the top of the stack and &lt;code class=&quot;inline&quot;&gt;c.get()&lt;/code&gt; pops and returns the top of the stack. &lt;a href=&quot;https://en.wikipedia.org/wiki/LIFO&quot;&gt;LIFO&lt;/a&gt; discipline of stacks is so widely used (implemented natively on all modern processors, built in programming languages in the form of call-stack) that one never ask whether a different method of evaluating expressions is possible.Here is a problem: find a way to translate infix notation to a program for a queue automaton, that is, in a program like the one above, but where &lt;code class=&quot;inline&quot;&gt;Container&lt;/code&gt; is the type of &lt;a href=&quot;https://en.wikipedia.org/wiki/FIFO_(computing_and_electronics)&quot;&gt;FIFO&lt;/a&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Queue_(abstract_data_type)&quot;&gt;queues&lt;/a&gt; with &lt;code class=&quot;inline&quot;&gt;c.put()&lt;/code&gt; enqueuing an element at the rear of the queue and &lt;code class=&quot;inline&quot;&gt;c.get()&lt;/code&gt; dequeuing at the front. This problem was &lt;a href=&quot;https://www.cs.utexas.edu/users/EWD/ewd08xx/EWD887.PDF&quot;&gt;reportedly&lt;/a&gt; solved by &lt;a href=&quot;https://en.wikipedia.org/wiki/Jan_L._A._van_de_Snepscheut&quot;&gt;Jan L.A. van de Snepscheut&lt;/a&gt; sometime during spring 1984.While you are thinking about it, consider the following tree-traversal code (in some abstract imaginary language):walk(Treenode root) {
        Container todo;
        todo.put(root);
        while (!todo.is_empty()) {
                next = todo.get();
                visit(next);
                for (child in next.children) {
                        todo.put(child);
                }
        }
}Where &lt;code class=&quot;inline&quot;&gt;node.children&lt;/code&gt; is the list of node children suitable for iteration by &lt;code class=&quot;inline&quot;&gt;for&lt;/code&gt; loop.Convince yourself that if &lt;code class=&quot;inline&quot;&gt;Container&lt;/code&gt; is the type of stacks, tree-walk is depth-first. And if &lt;code class=&quot;inline&quot;&gt;Container&lt;/code&gt; is the type of queues, tree-walk is breadth-first. Then, convince yourself that a depth-first walk of the parse tree of an infix expression produces the expression in Polish notation (unreversed) and its breadth-first walk produces the expression in &amp;quot;queue notation&amp;quot; (that is, the desired program for a queue automaton). Isn&amp;#x27;t it marvelous that traversing a parse tree with a stack container gives you the program for stack-based execution and traversing the same tree with a queue container gives you the program for queue-based execution?I feel that there is something deep behind this. &lt;a href=&quot;https://en.wikipedia.org/wiki/Alexander_Stepanov&quot;&gt;A. Stepanov&lt;/a&gt; had an intuition (which cost him &lt;a href=&quot;http://www.stlport.org/resources/StepanovUSA.html&quot;&gt;dearly&lt;/a&gt;) that &lt;i&gt;algorithms are defined on algebraic structures&lt;/i&gt;. Elegant interconnection between queues and stacks on one hand and tree-walks and automaton programs on the other, tells us that the correspondence between algorithms and structures goes in both directions.</content>
        </item>

        <item>
            <title>Treadmill</title>
            <id>treadmill</id>
            <link>https://cofault.com/treadmill.html#treadmill</link>
            <pubDate>2022/07/25</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/treadmill.html#treadmill">
                     &lt;i&gt;Treadmill&lt;/i&gt; is a &amp;quot;real-time&amp;quot; in-place garbage collection algorithm (&lt;span class=&quot;linktarget&quot; data-uid=&quot;0&quot;&gt;&lt;a href=&quot;https://dl.acm.org/doi/pdf/10.1145/130854.130862&quot;&gt;PDF&lt;/a&gt;&lt;/span&gt;, &lt;span class=&quot;linktarget&quot; data-uid=&quot;1&quot;&gt;&lt;a href=&quot;https://www.plover.com/~mjd/misc/hbaker-archive/NoMotionGC.ps.Z&quot;&gt;Postscript&lt;/a&gt;&lt;/span&gt;) designed by H. Baker. It is simple, elegant, efficient and surprisingly little known. Speaking of which, Mr. Baker&amp;#x27;s Wikipedia &lt;a href=&quot;https://en.wikipedia.org/wiki/Henry_Baker_(computer_scientist)&quot;&gt;page&lt;/a&gt; rivals one for an obscure Roman decadent poet in scarcity of information.The general situation of garbage collection is that there is a program (called &lt;i&gt;a mutator&lt;/i&gt; in this case) that allocates &lt;i&gt;objects&lt;/i&gt; (that will also be called &lt;i&gt;nodes&lt;/i&gt;) in a &lt;i&gt;heap&lt;/i&gt;, which is a pool of memory managed by the garbage collector. The mutator can update objects to point to other earlier allocated objects so that objects form a graph, possibly with cycles. The mutator can store pointers to objects in some locations outside of the heap, for example in the stack or in the registers. These locations are called &lt;i&gt;roots&lt;/i&gt;.The mutator allocates objects, but does not frees them explicitly. It is the job of the garbage collector to return unreachable objects, that is, the objects that can not be reached by following pointers from the roots, back to the allocation pool.It is assumed that the collector, by looking at an object, can identify all pointers to the heap stored in the object and that the collector knows all the roots. If either of these assumptions does not hold, one needs a &lt;i&gt;conservative collector&lt;/i&gt; that can be implemented as a library for an uncooperative compiler and run-time (&lt;i&gt;e.g.&lt;/i&gt;, &lt;a href=&quot;https://en.wikipedia.org/wiki/Boehm_garbage_collector&quot;&gt;Boehm garbage collector&lt;/a&gt; for C and C++).The earliest garbage collectors were part of Lisp run-time. &lt;a href=&quot;https://en.wikipedia.org/wiki/Lisp_(programming_language)&quot;&gt;Lisp&lt;/a&gt; programs tend to allocate a large number of &lt;a href=&quot;https://en.wikipedia.org/wiki/Cons&quot;&gt;cons cells&lt;/a&gt; and organise them in complex structures with cycles and sub-structure sharing. In fact, some of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Lisp_machine&quot;&gt;Lisp Machines&lt;/a&gt; had garbage collection implemented in hardware and allocated everything including stack frames and binding environments in the heap. Even processor instructions were stored as &lt;a href=&quot;https://en.wikipedia.org/wiki/Cons&quot;&gt;cons cells&lt;/a&gt; in the heap.To allocate a new object, the mutator calls &lt;code class=&quot;inline&quot;&gt;alloc()&lt;/code&gt;. Treadmill is &amp;quot;real-time&amp;quot; because the cost of &lt;code class=&quot;inline&quot;&gt;alloc()&lt;/code&gt; in terms of processor cycles is independent of the number of allocated objects and the total size of the heap, in other words, &lt;code class=&quot;inline&quot;&gt;alloc()&lt;/code&gt; is O(1) and this constant cost is not high. This means garbage collection without &amp;quot;stop-the-world&amp;quot; pauses, at least as long as the mutator does not genuinely exhaust the heap with reachable objects.Treadmill is &amp;quot;in-place&amp;quot; because the address of an allocated object does not change. This is in contrast with &lt;i&gt;copying&lt;/i&gt; garbage collectors that can move an object to a new place as part of the collection process (that implies some mechanism of updating the pointers to the moved object).All existing garbage collection algorithms involve some form of scanning of allocated objects and this scanning is usually described in terms of colours assigned to objects. In the standard 3-colour scheme (introduced together with the term &amp;quot;mutator&amp;quot; in &lt;a href=&quot;https://lamport.azurewebsites.net/pubs/garbage.pdf&quot;&gt;&lt;span class=&quot;linktarget&quot; data-uid=&quot;3&quot;&gt;On-the-Fly Garbage Collection: An Exercise in Cooperation&lt;/span&gt;&lt;/a&gt;), &lt;b&gt;black&lt;/b&gt; objects have been completely scanned together with the objects they point to, &lt;b&gt;gray&lt;/b&gt; objects have been scanned, but the objects they point to are not guaranteed to be scanned and &lt;b&gt;white&lt;/b&gt; objects have not been scanned.For historical reasons, Baker&amp;#x27;s papers colour free (un-allocated) objects white and use black-gray-&lt;a href=&quot;https://en.wikipedia.org/wiki/Ecru&quot;&gt;ecru&lt;/a&gt; instead of black-gray-white. We stick with &lt;b&gt;ecru&lt;/b&gt;, at least to get a chance to learn a fancy word.Consider the simplest case first:the heap has a fixed size;the mutator is single-threaded;allocated objects all have the same size (like cons cells).(All these restrictions will be lifted eventually.)The main idea of treadmill is that all objects in the heap are organised in a cyclic double-linked list, divided by 4 pointers into 4 segments (Figure 0):Allocation of new objects happens at &lt;code class=&quot;inline&quot;&gt;free&lt;/code&gt; (clockwise), scan advances at &lt;code class=&quot;inline&quot;&gt;scan&lt;/code&gt; (counterclockwise), still non-scanned objects are between &lt;code class=&quot;inline&quot;&gt;bottom&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;top&lt;/code&gt; (the latter 2 terms, somewhat confusing for a cyclic list of objects, are re-used from an earlier &lt;a href=&quot;https://dspace.mit.edu/bitstream/handle/1721.1/41976/AI_WP_139.pdf&quot;&gt;&lt;span class=&quot;linktarget&quot; data-uid=&quot;4&quot;&gt;paper&lt;/span&gt;&lt;/a&gt;, where a copying real-time garbage collector was introduced).Remarkably, the entire description and the proof of correctness of Treadmill algorithm (and many other similar algorithms) depends on a single invariant:&lt;b&gt;Invariant&lt;/b&gt;: there are no pointers from black to ecru nodes.That is, a black node can contain a pointer to another black node or to a gray node. A non-black (that is, gray or ecru) node can point to any allocated node: black, gray or ecru. An ecru node can be reached from a black node only through at least one intermediate gray node.Let&amp;#x27;s for the time being postpone the explanation of why this invariant is important and instead discuss the usual 2 issues that any invariant introduces: how to establish it and how to maintain it.Establishing is easy:In the initial state, all objects are un-allocated (white), except for the roots that are gray. The invariant is satisfied trivially because there are no black objects.After some allocations by the mutator and scanning, the heap looks like the one in Figure 0. A call to &lt;code class=&quot;inline&quot;&gt;alloc()&lt;/code&gt; advances &lt;code class=&quot;inline&quot;&gt;free&lt;/code&gt; pointer clockwise, thus moving one object from &lt;code class=&quot;inline&quot;&gt;FREE&lt;/code&gt; to &lt;code class=&quot;inline&quot;&gt;SCANNED&lt;/code&gt; part of the heap. There is no need to update double-linked list pointers within the allocated object and, as we will see, there is no need to change the object colour. This makes the allocation fast path very quick: just a single pointer update: &lt;code class=&quot;inline&quot;&gt;free := free.next&lt;/code&gt;.Allocation cannot violate the invariant, because the newly allocated object does not point to anything. In addition to calls to &lt;code class=&quot;inline&quot;&gt;alloc()&lt;/code&gt; the mutator can read pointer fields from nodes it already reached and update fields of reachable nodes to point to other reachable nodes. There is no pointer arithmetic (otherwise a conservative collector is needed). A reachable node is either black, gray or ecru, so it seems, at the first sight, that the only way the mutator can violate the invariant is by setting a field in a black object to point to an ecru object. This is indeed the case with some collection algorithms (called &amp;quot;gray mutator algorithms&amp;quot; in &lt;span class=&quot;linktarget&quot; data-uid=&quot;1&quot;&gt;The Garbage Collection Handbook&lt;/span&gt;). Such algorithms use a &lt;i&gt;write barrier&lt;/i&gt;, which is a special code inserted by the compiler before (or instead of) updating a pointer field. The simplest write barrier prevents a violation of the 3-colour invariant by graying the ecru target object if necessary:writebarrier(obj, field, target) {
        obj.field := target;
        if black(obj) &amp;amp;&amp;amp; ecru(target) {
                darken(target);
        }
}
darken(obj) { /* Make an ecru object gray. */
        assert ecru(obj);
        unlink(obj); /* Remove the object from the treadmill list. */
        link(top, obj); /* Put it back at the tail of the gray list. */
}More sophisticated write barriers were studied that make use of the old value of &lt;code class=&quot;inline&quot;&gt;obj.field&lt;/code&gt; or are integrated with virtual memory sub-system, see &lt;a href=&quot;https://gchandbook.org/&quot;&gt;The Garbage Collection Handbook&lt;/a&gt; for details.In our case, however, when the mutator reads a pointer field of an object, it effectively stores the read value in a register (or in a stack frame slot) and in Treadmill, registers can be black (Treadmill is a &amp;quot;black mutator algorithm&amp;quot;). That is, the mutator can violate the invariant simply by reading the pointer to an ecru object in a black register. To prevent this a &lt;i&gt;read barrier&lt;/i&gt; is needed, executed on every read of a pointer field:readbarrier(obj, field) {
        if ecru(obj) {
                darken(obj);
        }
        return obj.field;
}When a black or gray object is read, the read barrier leaves it in place. When an ecru object is read, the barrier un-links the object from the treadmill list (effectively removing it from &lt;code class=&quot;inline&quot;&gt;TOSCAN&lt;/code&gt; section) and re-links it to the treadmill either at &lt;code class=&quot;inline&quot;&gt;top&lt;/code&gt; or at &lt;code class=&quot;inline&quot;&gt;scan&lt;/code&gt; thus making it gray. This barrier guarantees that the mutator cannot violate the invariant simply because the mutator never sees ecru objects (which are grayed by the barrier) and hence cannot store pointers to them anywhere. If the read barrier is present, the write barrier is not necessary.That&amp;#x27;s how the invariant is established and maintained by the mutator. We still haven&amp;#x27;t discussed how the collector works and where these mysterious ecru objects appear from. The collector is very simple: it has a single entry point:advance() { /* Scan the object pointed to by &amp;quot;scan&amp;quot;. */
        for field in pointers(scan) {
                if ecru(scan.field) {
                        darken(scan.field);
                }
        }
        scan := scan.prev; /* Make it black. */
}&lt;code class=&quot;inline&quot;&gt;advance()&lt;/code&gt; takes the gray object pointed to by &lt;code class=&quot;inline&quot;&gt;scan&lt;/code&gt;, which is the head of the &lt;code class=&quot;inline&quot;&gt;FRONT&lt;/code&gt; list, and grays all ecru objects that this object points to. After that, &lt;code class=&quot;inline&quot;&gt;scan&lt;/code&gt; is advanced (counterclockwise), effectively moving the scanned object into the &lt;code class=&quot;inline&quot;&gt;SCANNED&lt;/code&gt; section and making it black.It&amp;#x27;s not important for now how and when exactly &lt;code class=&quot;inline&quot;&gt;advance()&lt;/code&gt; is called. What matters is that it blackens an object while preserving the invariant.Now comes the crucial part. An allocated object only darkens: the mutator (&lt;code class=&quot;inline&quot;&gt;readbarrier()&lt;/code&gt;) and the collector (&lt;code class=&quot;inline&quot;&gt;advance()&lt;/code&gt;) can gray an ecru object and &lt;code class=&quot;inline&quot;&gt;advance()&lt;/code&gt; blackens a gray object. There is no way for a black object to turn gray or for a gray object to turn ecru. Hence, the total number of allocated non-black objects never increases. But &lt;code class=&quot;inline&quot;&gt;advance()&lt;/code&gt; always blackens one object, which means that after some number of calls (interspersed with arbitrary mutator activity), &lt;code class=&quot;inline&quot;&gt;advance()&lt;/code&gt; will run out of objects to process: the &lt;code class=&quot;inline&quot;&gt;FRONT&lt;/code&gt; section will be empty and there will be no gray objects anymore:All roots were originally gray and could only darken, so they are now black. And an ecru object is reachable from a black object only through a gray object, but there are no gray objects, so ecru objects are not reachable from roots—they are garbage. This completes the collection cycle and, in principle, it is possible to move all ecru objects to the &lt;code class=&quot;inline&quot;&gt;FREE&lt;/code&gt; list at that point and start the next collection cycle. But we can do better. Instead of replenishing the &lt;code class=&quot;inline&quot;&gt;FREE&lt;/code&gt; list, wait until all objects are allocated and the &lt;code class=&quot;inline&quot;&gt;FREE&lt;/code&gt; list is empty:Only black and ecru objects remain. &lt;i&gt;Flip&lt;/i&gt; them: swap &lt;code class=&quot;inline&quot;&gt;top&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;bottom&lt;/code&gt; pointers and redefine colours: the old black objects are now ecru and the old ecru objects (remember they are garbage) are now white:The next collection cycle starts: put the roots between &lt;code class=&quot;inline&quot;&gt;top&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;scan&lt;/code&gt; so that they are the new &lt;code class=&quot;inline&quot;&gt;FRONT&lt;/code&gt;:From this point &lt;code class=&quot;inline&quot;&gt;alloc()&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;advance()&lt;/code&gt; can continue as before.Note that &lt;code class=&quot;inline&quot;&gt;alloc()&lt;/code&gt;, &lt;code class=&quot;inline&quot;&gt;advance()&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;readbarrier()&lt;/code&gt; do not actually have to know object colour. They only should be able to tell an ecru (allocated) object from non-ecru, so 1 bit of information per object is required. By waiting until the &lt;code class=&quot;inline&quot;&gt;FREE&lt;/code&gt; list is empty and re-defining colours Treadmill avoids the need to scan the objects and change their colours at the end of a collection cycle: it is completely O(1).The last remaining bit of the puzzle is still lacking: how is it guaranteed that the collection is completed before the &lt;code class=&quot;inline&quot;&gt;FREE&lt;/code&gt; list is empty? If the mutator runs out of free objects before the collection cycle is completed, then the only option is to force the cycle to completion by calling &lt;code class=&quot;inline&quot;&gt;advance()&lt;/code&gt; repeatedly until there are no more gray objects and then flip, but that&amp;#x27;s a stop-the-world situation.The solution is to call &lt;code class=&quot;inline&quot;&gt;advance()&lt;/code&gt; from within &lt;code class=&quot;inline&quot;&gt;alloc()&lt;/code&gt; guaranteeing scan progress. Baker proved that if &lt;code class=&quot;inline&quot;&gt;advance()&lt;/code&gt; is called &lt;code class=&quot;inline&quot;&gt;k&lt;/code&gt; times for each &lt;code class=&quot;inline&quot;&gt;alloc()&lt;/code&gt; call, then the algorithm never runs out of free objects, provided that the total heap size is at least &lt;code class=&quot;inline&quot;&gt;R*(1 + 1/k)&lt;/code&gt; objects, where &lt;code class=&quot;inline&quot;&gt;R&lt;/code&gt; is the number of reachable objects.This completes the Treadmill description.The algorithm is very flexible. First, the restriction of a single-threaded mutator is not really important: as long as &lt;code class=&quot;inline&quot;&gt;alloc()&lt;/code&gt;, &lt;code class=&quot;inline&quot;&gt;advance()&lt;/code&gt;, &lt;code class=&quot;inline&quot;&gt;readbarrier()&lt;/code&gt; and flip are mutually exclusive, no further constraints on concurrency are necessary. The mutator can be multi-threaded. The collector can be multi-threaded. &lt;code class=&quot;inline&quot;&gt;advance()&lt;/code&gt; can be called &amp;quot;synchronously&amp;quot; (from &lt;code class=&quot;inline&quot;&gt;alloc()&lt;/code&gt;), explicitly from the mutator code or &amp;quot;asynchronously&amp;quot; from the dedicated collector threads. A feedback-based method can regulate the frequency of calls to &lt;code class=&quot;inline&quot;&gt;advance()&lt;/code&gt; depending on the amount of free and garbage objects. &lt;code class=&quot;inline&quot;&gt;alloc()&lt;/code&gt; can penalise heavy-allocating threads forcing them to do most of the scanning, &lt;i&gt;etc&lt;/i&gt;.Next, when an object is grayed by &lt;code class=&quot;inline&quot;&gt;darken()&lt;/code&gt;, all that matter is that the object is placed in the &lt;code class=&quot;inline&quot;&gt;FRONT&lt;/code&gt; section. If &lt;code class=&quot;inline&quot;&gt;darken()&lt;/code&gt; places the object next to &lt;code class=&quot;inline&quot;&gt;top&lt;/code&gt;, then &lt;code class=&quot;inline&quot;&gt;FRONT&lt;/code&gt; acts as a FIFO queue and the scan proceeds in the breadth-first order. If the object is placed next to &lt;code class=&quot;inline&quot;&gt;scan&lt;/code&gt; then the scan proceeds in the depth-first order, which might result in a better locality of reference and better performance of a heap in virtual memory. A multi-threaded collector can use multiple &lt;code class=&quot;inline&quot;&gt;FRONT&lt;/code&gt; lists, &lt;i&gt;e.g.&lt;/i&gt;, one per core and scan them concurrently.New objects can be added to the heap at any time, by atomically linking them somewhere in the &lt;code class=&quot;inline&quot;&gt;FREE&lt;/code&gt; list. Similarly, a bunch of objects can be at any moment atomically released from the &lt;code class=&quot;inline&quot;&gt;FREE&lt;/code&gt; list with the usual considerations of fragmentation-avoidance in the lower layer allocator.Support for variable-sized objects requires a separate cyclic list for each size (plus, perhaps an additional overflow list for very large objects). The &lt;code class=&quot;inline&quot;&gt;top&lt;/code&gt;, &lt;code class=&quot;inline&quot;&gt;bottom&lt;/code&gt;, &lt;code class=&quot;inline&quot;&gt;scan&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;free&lt;/code&gt; pointers become arrays of pointers with an element for each size. If arbitrarily large objects (&lt;i&gt;e.g.&lt;/i&gt;, arrays) are supported then atomicity of &lt;code class=&quot;inline&quot;&gt;advance()&lt;/code&gt; will require additional work: large objects need to be multi-coloured and will blacken gradually.Forward and backward links to the cyclic list can be embedded in the object header or they can be stored separately, the latter might improve cache utilisation by the scanner.</content>
        </item>

        <item>
            <title>Unintentionally yours.</title>
            <id>unintentionally</id>
            <link>https://cofault.com/unintentionally.html#unintentionally</link>
            <pubDate>2011/12/08</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/unintentionally.html#unintentionally">
                     &lt;span class=&quot;linktarget&quot; data-uid=&quot;3&quot;&gt;E&lt;/span&gt;xtension.This post is about &lt;a href=&quot;http://en.wikipedia.org/wiki/Set_theory&quot;&gt;set theory&lt;/a&gt;, which is a framework to reason about collections, elements and membership.We start with a informal and naïve outline, which is (very loosely) based on a &lt;a href=&quot;http://en.wikipedia.org/wiki/Von_Neumann-Bernays-G%C3%B6del_set_theory&quot;&gt;Godel-Bernays&lt;/a&gt; version of set theory. This theory is about sets (collections) which contain elements, which can in turn be sets. When a set \(X\) contains an element \(t\), it is written \(t\in X\).First, set equality has to be defined:E0 &lt;a href=&quot;http://en.wikipedia.org/wiki/Axiom_of_extensionality&quot;&gt;&lt;i&gt;Axiom of extensionality&lt;/i&gt;&lt;/a&gt;X = Y \equiv (t \in X \equiv t \in Y)(Here \(\equiv\) is a logical equivalence, pronounced &amp;quot;&lt;a href=&quot;http://en.wikipedia.org/wiki/Iff&quot;&gt;if and only if&lt;/a&gt;&amp;quot;.) This axiom means that sets are equal exactly when they have the same elements. (In this and following formulae, free variables are implicitly &lt;a href=&quot;http://en.wikipedia.org/wiki/Universal_quantification&quot;&gt;universally quantified&lt;/a&gt;.)Subsets are defined by \(X \subseteq Y \equiv (t\in X \Rightarrow t\in Y)\), that is, X is a subset of Y when every element of X is also an element of Y. It&amp;#x27;s easy to check that \(X = Y \equiv (X\subseteq Y \wedge Y\subseteq X)\), where \(\wedge\) means &amp;quot;and&amp;quot;.Next, a way to build new sets is needed:E1 &lt;a href=&quot;http://en.wikipedia.org/wiki/Set-builder_notation&quot;&gt;&lt;i&gt;Axiom of (extensional) comprehension&lt;/i&gt;&lt;/a&gt;t \in \{u \mid P(u)\} \equiv P(t)This axiom introduces a &amp;quot;set-builder notation&amp;quot; \(\{u \mid P(u) \}\) and states that \(\{u \mid P(u) \}\) is exactly the set of all \(t\) such that \(P(t)\) holds.Now, there is already enough machinery for two famous collections to be immediately constructed: &lt;a href=&quot;http://en.wikipedia.org/wiki/Empty_set&quot;&gt;&lt;i&gt;empty set&lt;/i&gt;&lt;/a&gt;, \(\varnothing = \{t \mid false \}\), which contains no elements, and &lt;a href=&quot;http://en.wikipedia.org/wiki/Universe_(mathematics)&quot;&gt;the collection of all sets&lt;/a&gt;: \(U = \{t \mid true \}\), which contains all possible elements.With these axioms, conventional set operations can be defined:&lt;a href=&quot;http://en.wikipedia.org/wiki/Singleton_(mathematics)&quot;&gt;singleton&lt;/a&gt;: \(\{t\} = \{u\mid u = t\}\), for each \(t\) a &lt;a href=&quot;http://en.wikipedia.org/wiki/Singleton_(mathematics)&quot;&gt;singleton&lt;/a&gt; set \(\{t\}\) can be constructed that contains \(t\) as its only element. Note that \(t\in\{t\}\)&lt;a href=&quot;http://en.wikipedia.org/wiki/Union_(set_theory)&quot;&gt;union&lt;/a&gt;: \(X\cup Y = \{t\mid t \in X \vee t \in Y\}\) (\(\vee\) means &amp;quot;or&amp;quot;)&lt;a href=&quot;http://en.wikipedia.org/wiki/Intersection_(set_theory)&quot;&gt;intersection&lt;/a&gt;: \(X\cap Y = \{t\mid t\in X \wedge t\in Y\}\)&lt;a href=&quot;http://en.wikipedia.org/wiki/Complement_(set_theory)&quot;&gt;complement&lt;/a&gt;: \(\complement X = \{t \mid t \notin X\}\)(unordered) &lt;a href=&quot;http://en.wikipedia.org/wiki/Unordered_pair&quot;&gt;pair&lt;/a&gt;: \(\{t,u\} = \{t\}\cup\{u\}\)&lt;a href=&quot;http://en.wikipedia.org/wiki/Ordered_pair&quot;&gt;ordered pair&lt;/a&gt;: \((t,u) = \{t, \{t, u\}\}\)&lt;a href=&quot;http://en.wikipedia.org/wiki/Power_set&quot;&gt;power set&lt;/a&gt;: \(\mathfrak{P}(X) = \{t \mid t \subseteq X\}\)From here, one can build hierarchical sets, representing all traditional mathematical structures, starting with natural numbers:0 = \varnothing,\quad 1 = \{0\},\quad 2 = \{0, 1\},\quad \ldots,\quad  n + 1 = \{0, \ldots, n\}, \quad \ldotsthen integers, rationals, reals, &lt;i&gt;&amp;amp;c.&lt;/i&gt;, adding more axioms (of &lt;a href=&quot;http://en.wikipedia.org/wiki/Axiom_of_infinity&quot;&gt;infinity&lt;/a&gt;, of &lt;a href=&quot;http://en.wikipedia.org/wiki/Axiom_of_regularity&quot;&gt;foundation&lt;/a&gt;, of &lt;a href=&quot;http://en.wikipedia.org/wiki/Axiom_schema_of_replacement&quot;&gt;replacement&lt;/a&gt;, &lt;i&gt;&amp;amp;c&lt;/i&gt;.) along the way.It was discovered quite early that this system is not entirely satisfactory. First defect is that it is impossible to have elements which are not sets themselves. For example, one would like to talk about a &amp;quot;set of all inhabited planets in the Solar system&amp;quot;. Elements of this set (planets) are not sets, they are called &lt;a href=&quot;http://en.wikipedia.org/wiki/Urelement&quot;&gt;&lt;i&gt;ur-elements&lt;/i&gt;&lt;/a&gt;. Unfortunately, the axiom of extensionality makes all &lt;a href=&quot;http://en.wikipedia.org/wiki/Urelement&quot;&gt;ur-elements&lt;/a&gt; equal to the empty set. Note, that this indicates that the axiom of extensionality doesn&amp;#x27;t work well with sets that have very few (none) elements. This was never considered a problem, because all sets of interest to mathematics can be constructed without &lt;a href=&quot;http://en.wikipedia.org/wiki/Urelement&quot;&gt;ur-elements&lt;/a&gt;.Another, more serious drawback, arises in the area of very large sets: existence of a set \(\{t\mid t\notin t\}\) directly leads to a contradiction known as &lt;a href=&quot;http://en.wikipedia.org/wiki/Russell&#x27;s_paradox&quot;&gt;Russel&amp;#x27;s paradox&lt;/a&gt;.Among several possible methods to deal with this, Godel-Bernays version is to separate sets into two types: &amp;quot;smaller&amp;quot; collections which are continued to be called &amp;quot;sets&amp;quot; and &amp;quot;proper classes&amp;quot;, which are collections so large that they cannot be a member of any collection. Axiom of comprehension is carefully modified so that set-builder never produces a collection having some class as its element. In this setup Russel&amp;#x27;s paradox becomes a theorem: \(\{t\mid t\notin t\}\) is a proper class.Intention.The axiom of extensionality states that sets are equal when they &lt;i&gt;contain&lt;/i&gt; the same elements. What would happen, if set theory were based on a dual notion of &lt;i&gt;intentional equality&lt;/i&gt; (which will be denoted by \(\sim\) to tell it from extensional one), where sets are equal when they are &lt;i&gt;contained&lt;/i&gt; in the same collections?I0 &lt;i&gt;Axiom of intensionality&lt;/i&gt;:X \sim Y \equiv (X \in t \equiv Y\in t)This looks bizarre: for any &amp;quot;normal&amp;quot; set \(X\) a collection of all sets containing \(X\) as element is unmanageably huge. But as a matter of fact, intentional equality is much older than extensional, it is variously known as &lt;i&gt;Leibniz&amp;#x27;s law&lt;/i&gt;, &lt;a href=&quot;http://en.wikipedia.org/wiki/Identity_of_indiscernibles&quot;&gt;identity of indiscernibles&lt;/a&gt; and, in less enlightened age, as &lt;a href=&quot;http://en.wikipedia.org/wiki/Duck_typing&quot;&gt;duck typing&lt;/a&gt;.There is a nice symmetry: while extensional equality myopically confuses small sets (ur-elements), intensional equality cannot tell very large collections (proper classes) from each other, because they are not members of anything and, therefore, intentionally equal.The whole extensional theory buildup can be mirrored easily by moving things around \(\in\) sign:Intensional subsets: \(X \unlhd Y \equiv (X\in t \Rightarrow Y\in t)\)I1 &lt;i&gt;Axiom of intensional comprehension (incomprehension)&lt;/i&gt;:[u \mid P(u)]\in t \equiv P(t)And associated operations:uniqum (or should it have been &amp;quot;s-ex-gleton?): \([t] = [u\mid u \sim t]\), note that \([t]\in t\).intentional union: \(X\triangledown Y = [t\mid X \in t \vee Y \in t]\)intentional intersection: \(X\triangle Y = [t\mid X \in t \wedge Y \in t]\)intentional complement: \(\Game X = [t \mid X \notin t]\)intentional pair: \([t,u] = [t]\triangledown [u]\)intentional ordered pair: \(&amp;lt;t,u&amp;gt; = [t, [t, u]]\)intentional power set: \(\mathfrak{J}(X) = [t \mid X \unlhd t\}\)What do all these things &lt;i&gt;mean&lt;/i&gt;? In extensional world, a set is a container, where elements are stored. In intensional world, a set is a &lt;i&gt;property&lt;/i&gt;, which other sets might or might not enjoy. If \(t\) has property \(P\), it is written as \(t\in P\). In the traditional notation, \(P\) is called a &lt;i&gt;predicate&lt;/i&gt; and \(t\in P\) is written as \(P(t)\). The axiom of intentional equality claims that sets are equal when they have exactly the same properties (quite natural, right?). \(X\) is an intentional subset of \(Y\) when \(Y\) has all properties of \(X\) and perhaps some more (this looks like a nice way to express &lt;a href=&quot;http://en.wikipedia.org/wiki/Liskov_substitution_principle&quot;&gt;LSP&lt;/a&gt;). Intentional comprehension \([u \mid P(u)]\) is a set having exactly all properties \(t\) for which \(P(t)\) holds and no other properties. Intentional union of two sets is a set having properties of either and their intentional intersection is a set having properties of both, &lt;i&gt;&amp;amp;c&lt;/i&gt;. Uniqum \([P]\) is &lt;i&gt;the&lt;/i&gt; set that has property \(P\) and no other properties.Because intensional theory is a perfect dual of extensional nothing interesting is obtained by repeating extensional construction, for example, by building &amp;quot;intensional natural numbers&amp;quot; as0&amp;#x27; = U, 1&amp;#x27; = [0&amp;#x27;], 2&amp;#x27; = [0&amp;#x27;, 1&amp;#x27;], \ldots (n + 1)&amp;#x27; = [0&amp;#x27;, \ldots, n&amp;#x27;], \ldotsWhat is more interesting, is how intensional and extensional twins meet. With some filial affection it seems:by uniqum property \([\varnothing] \in\varnothing\), which contradicts the definition of \(\varnothing\), alsoset \([t\mid false]\) is not a member of any set (perhaps it&amp;#x27;s a proper class) and set \([t\mid true]\) is a member of every set, which is strange;a set of which a singleton can be formed has very shallow intentional structure. Indeed:\begin{array}{r@{\;}l@{\quad}}
                 &amp;amp;    x \unlhd y \\
        \equiv   &amp;amp;    \text{ \{ definition of intensional subset \} } \\
                 &amp;amp;    x\in t \Rightarrow y\in t \\
   \Rightarrow   &amp;amp;    \text{ \{ substitute \(\{x\}\) for \(t\) \} } \\
                 &amp;amp;    x\in \{x\} \Rightarrow y\in \{x\} \\
        \equiv   &amp;amp;    \text{ \{ \(x\in \{x\}\) is true by the singleton property, modus ponens \} } \\
                 &amp;amp;    y\in \{x\} \\
        \equiv   &amp;amp;    \text{ \{ the singleton property, again \} } \\
                 &amp;amp;    x = y
\end{array}To get rid of contradictions and to allow intensional and extensional sets to co-exist peacefully, domains on which singleton and uniqum operations are defined &lt;span class=&quot;annotation&quot; data-uid=&quot;4&quot;&gt;must be narrowed&lt;/span&gt;. To be continued.</content>
        </item>

        <item>
            <title>usched and Algol-68: a connection</title>
            <id>usched.algol68</id>
            <link>https://cofault.com/usched.algol68.html#usched.algol68</link>
            <pubDate>2025/04/30</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/usched.algol68.html#usched.algol68">
                     &lt;a href=&quot;usched.html#usched-start&quot;&gt;usched&lt;/a&gt; is a light-weight cooperative-multitasking-coroutine library that I wrote (&lt;a href=&quot;https://github.com/nikitadanilov/usched&quot;&gt;github.com&lt;/a&gt;). To switch between threads, it copies the stack of the outgoing thread out to somewhere (&lt;i&gt;e.g.&lt;/i&gt;, the heap) and copies in the stack of the incoming thread, that was similarly copied out on the previous context switch.As usual, whatever you invent, eventually turns out to be known since long time ago. In this case, we are talking about something that happened at fabulous times, almost at the dawn of history, as far as computing technology is concerned: &lt;a href=&quot;https://en.wikipedia.org/wiki/ALGOL_68&quot;&gt;Algol-68&lt;/a&gt;. Dr. J.J.F.M. Schlichting&amp;#x27;s PhD. thesis &lt;a href=&quot;https://ir.cwi.nl/pub/27828/27828.pdf&quot;&gt;&lt;i&gt;Een Vroege Implementatie Van Herzien Algol 68&lt;/i&gt;&lt;/a&gt; (&lt;i&gt;An Early Implementation Of Revised Algol 68&lt;/i&gt;) describes in detail an implementation of that language by &lt;a href=&quot;https://en.wikipedia.org/wiki/Control_Data_Corporation&quot;&gt;Control Data B. Y.&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/University_of_Amsterdam&quot;&gt;the University of Amsterdam&lt;/a&gt; (among others).On p. 4-30 we find:The term &lt;i&gt;thread&lt;/i&gt; is not used (maybe not yet invented, definitely not current), but we see a sophisticated compiler-assisted cooperative multitasking with &lt;a href=&quot;https://en.wikipedia.org/wiki/Fork%E2%80%93join_model&quot;&gt;fork-join concurrency&lt;/a&gt; and &lt;a href=&quot;https://wiki.c2.com/?CactusStack&quot;&gt;cactus stacks&lt;/a&gt;:</content>
        </item>

        <item>
            <title>usched: stackswap coroutines, neither stackful nor stackless</title>
            <id>usched</id>
            <link>https://cofault.com/usched.html#usched</link>
            <pubDate>2022/10/06</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/usched.html#usched">
                     &lt;span class=&quot;linktarget&quot; data-uid=&quot;1&quot;&gt;&lt;span class=&quot;linktarget&quot; data-uid=&quot;2&quot;&gt;[&lt;/span&gt;&lt;/span&gt;Please read the &lt;a href=&quot;usched.update.html#usched.update-start&quot;&gt;&lt;i&gt;update&lt;/i&gt;&lt;/a&gt;.]This repository (&lt;a href=&quot;https://github.com/nikitadanilov/usched&quot;&gt;https://github.com/nikitadanilov/usched&lt;/a&gt;) contains a simple experimental implementation of &lt;a href=&quot;https://en.wikipedia.org/wiki/Coroutine&quot;&gt;coroutines&lt;/a&gt; alternative to well-known &amp;quot;stackless&amp;quot; and &amp;quot;stackful&amp;quot; methods.The term &amp;quot;coroutine&amp;quot; gradually grew to mean a mechanism where a computation, which in this context means a chain of nested function calls, can &amp;quot;block&amp;quot; or &amp;quot;yield&amp;quot; so that the top-most caller can proceed and the computation can later be resumed at the blocking point with the chain of intermediate function activation frames preserved.Prototypical uses of coroutines are lightweight support for potentially blocking operations (user interaction, IO, networking) and &lt;a href=&quot;https://en.wikipedia.org/wiki/Generator_(computer_programming)&quot;&gt;&lt;i&gt;generators&lt;/i&gt;&lt;/a&gt; which produce multiple values (see &lt;a href=&quot;https://wiki.c2.com/?SameFringeProblem&quot;&gt;same fringe problem&lt;/a&gt;).There are two common coroutine implementation methods:a &lt;i&gt;stackful&lt;/i&gt; coroutine runs on a separate stack. When a stackful coroutine  blocks, it performs a usual context switch. Historically &amp;quot;coroutines&amp;quot; meant  stackful coroutines. Stackful coroutines are basically little more than usual  threads, and so they can be &lt;i&gt;kernel&lt;/i&gt; (supported by the operating system)  or &lt;i&gt;user-space&lt;/i&gt; (implemented by a user-space library, also known as  &lt;i&gt;green threads&lt;/i&gt;), preemptive or cooperative.a &lt;i&gt;stackless&lt;/i&gt; coroutine does not use any stack when blocked. In a typical  implementation instead of using a normal function activation frame on the  stack, the coroutine uses a special activation frame allocated in the heap so  that it can outlive its caller. Using heap-allocated frame to store all local  variable lends itself naturally to compiler support, but some people are known  to implement stackless coroutines manually via a combination of pre-processing,  library and tricks much worse than &lt;a href=&quot;https://en.wikipedia.org/wiki/Protothread&quot;&gt;Duff&amp;#x27;s device&lt;/a&gt;.Stackful and stateless are by no means the only possibilities. One of the earliest languages to feature generators &lt;a href=&quot;https://en.wikipedia.org/wiki/CLU_(programming_language)&quot;&gt;CLU&lt;/a&gt; (&lt;a href=&quot;https://pmg.csail.mit.edu/ftp.lcs.mit.edu/pub/pclu/CLU/&quot;&gt;distribution&lt;/a&gt;) ran generators on the caller&amp;#x27;s stack.usched is in some sense intermediate between stackful and stackless: its coroutines do not use stack when blocked, nor do they allocate individual activation frames in the heap.The following is copied with some abbreviations from &lt;a href=&quot;https://github.com/nikitadanilov/usched/blob/master/usched.c&quot;&gt;usched.c&lt;/a&gt;.Overviewusched: A simple dispatcher for cooperative user-space threads.A typical implementation of user-space threads allocates a separate stack for each thread when the thread is created and then dispatches threads (as decided by the scheduler) through some context switching mechanism, for example, &lt;code class=&quot;inline&quot;&gt;longjmp()&lt;/code&gt;.In usched all threads (represented by struct ustack) are executed on the same &amp;quot;native&amp;quot; stack. When a thread is about to block (&lt;code class=&quot;inline&quot;&gt;usched_block()&lt;/code&gt;), a memory buffer for the stack used by this thread is allocated and the stack is copied to the buffer. After that the part of the stack used by the blocking thread is discarded (by &lt;code class=&quot;inline&quot;&gt;longjmp()&lt;/code&gt;-ing to the base of the stack) and a new thread is selected. The stack of the selected thread is restored from its buffer and the thread is resumed by &lt;code class=&quot;inline&quot;&gt;longjmp()&lt;/code&gt;-ing to the &lt;code class=&quot;inline&quot;&gt;usched_block()&lt;/code&gt; that blocked it.The focus of this implementation is simplicity: the total size of &lt;code class=&quot;inline&quot;&gt;usched.[ch]&lt;/code&gt; is less than 120LOC, as measured by SLOCCount.Advantages:no need to allocate maximal possible stack at thread initialisation: stack  buffer is allocated as needed. It is also possible to free the buffer when the  thread is resumed (not currently implemented);a thread that doesn&amp;#x27;t block has 0 overhead: it is executed as a native function  call (through a function pointer) without any context switching;because the threads are executed on the stack of the same native underlying  thread, native synchronisation primitives (mutices, &lt;i&gt;etc&lt;/i&gt;.)  work, although the  threads share underlying TLS. Of course one cannot use native primitives to  synchronise between usched threads running on the same native thread.Disadvantages:stack copying introduces overhead (&lt;code class=&quot;inline&quot;&gt;memcpy()&lt;/code&gt;) in each context  switch;because stacks are moved around, addresses on a thread stack are only valid  while the thread is running. This invalidates certain common programming  idioms: other threads and heap cannot store pointers to the stacks, at least to  the stacks of the blocked threads. Note that Go language, and probably other  run-times, maintains a similar invariant.Usageusched is only a dispatcher and not a scheduler: it blocks and resumes threads butit does not keep track of threads (specifically allocation and freeing of  struct ustack instances is done elsewhere),it implements no scheduling policies.These things are left to the user, together with stack buffers allocation and freeing. The user supplies 3 call-backs:&lt;code class=&quot;inline&quot;&gt;usched::s_next()&lt;/code&gt;: the scheduling function. This call-backs returns the next thread to execute. This can be either a new (never before executed) thread initialised with &lt;code class=&quot;inline&quot;&gt;ustack_init()&lt;/code&gt;, or it can be a blocked thread. The user must keep track of blocked and runnable threads, presumably by providing wrappers to &lt;code class=&quot;inline&quot;&gt;ustack_init()&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;ustack_block()&lt;/code&gt; that would record thread state changes. It is up to &lt;code class=&quot;inline&quot;&gt;usched::s_next()&lt;/code&gt; to block and wait for events if there are no runnable threads and all threads are waiting for something;&lt;code class=&quot;inline&quot;&gt;usched::s_alloc()&lt;/code&gt;: allocates new stack buffer of at least the specified size. The user have full control over stack buffer allocation. It is possible to pre-allocate the buffer when the thread is initialised (reducing the cost of &lt;code class=&quot;inline&quot;&gt;usched_block()&lt;/code&gt;), it is possible to cache buffers, &lt;i&gt;etc&lt;/i&gt;.;&lt;code class=&quot;inline&quot;&gt;usched::s_free()&lt;/code&gt;: frees the previously allocated stack buffer.&lt;a href=&quot;https://github.com/nikitadanilov/usched/blob/master/rr.h&quot;&gt;rr.h&lt;/a&gt; and &lt;a href=&quot;https://github.com/nikitadanilov/usched/blob/master/rr.c&quot;&gt;rr.c&lt;/a&gt; provide a simple &amp;quot;round-robin&amp;quot; scheduler implementing all the call-backs. Use it carefully, it was only tested with &lt;a href=&quot;https://github.com/nikitadanilov/usched/blob/master/rmain.c&quot;&gt;rmain.c&lt;/a&gt; benchmark.Pictures!The following diagrams show stack management by usched. The stack grows from right to left.At the entrance to the dispatcher loop. &lt;code class=&quot;inline&quot;&gt;usched_run(S)&lt;/code&gt;:                                                usched_run()
----------------------------------------------+--------------+-------+
                                              | buf | anchor |  ...  |
----------------------------------------------+--------------+-------+
                                              ^
                                              |
                                              sp = S-&amp;gt;s_buf`A new (never before executed) thread &lt;code class=&quot;inline&quot;&gt;U&lt;/code&gt; is selected by &lt;code class=&quot;inline&quot;&gt;S-&amp;gt;&lt;/code&gt;&lt;code class=&quot;inline&quot;&gt;s_next()&lt;/code&gt;, &lt;code class=&quot;inline&quot;&gt;launch()&lt;/code&gt; calls the thread startup function &lt;code class=&quot;inline&quot;&gt;U-&amp;gt;&lt;/code&gt;&lt;code class=&quot;inline&quot;&gt;u_f()&lt;/code&gt;:                               U-&amp;gt;u_f() launch() usched_run()
 -----------------------------+---------+-----+--------------+-------+
                              |         | pad | buf | anchor |  ...  |
 -----------------------------+---------+-----+--------------+-------+
                              ^         ^
                              |         |
                              sp        U-&amp;gt;u_bottom`The thread executes as usual on the stack, until it blocks by calling &lt;code class=&quot;inline&quot;&gt;usched_block()&lt;/code&gt;:    usched_block()       bar() U-&amp;gt;u_f() launch() usched_run()
 ----------+------+-----+-----+---------+-----+--------------+-------+
           | here | ... |     |         | pad | buf | anchor |  ...  |
 ----------+------+-----+-----+---------+-----+--------------+-------+
      ^    ^                            ^
      |    +-- sp = U-&amp;gt;u_cont           |
      |                                 U-&amp;gt;u_bottom
      U-&amp;gt;u_top`The stack from &lt;code class=&quot;inline&quot;&gt;U-&amp;gt;u_top&lt;/code&gt; to &lt;code class=&quot;inline&quot;&gt;U-&amp;gt;u_bottom&lt;/code&gt; is copied into the stack buffer &lt;code class=&quot;inline&quot;&gt;U-&amp;gt;u_stack&lt;/code&gt;, and control returns to &lt;code class=&quot;inline&quot;&gt;usched_run()&lt;/code&gt; by &lt;code class=&quot;inline&quot;&gt;longjmp(S-&amp;gt;s_buf)&lt;/code&gt;:                                                usched_run()
----------------------------------------------+--------------+-------+
                                              | buf | anchor |  ...  |
----------------------------------------------+--------------+-------+
                                              ^
                                              |
                                              sp = S-&amp;gt;s_buf`Next, suppose &lt;code class=&quot;inline&quot;&gt;S-&amp;gt;&lt;/code&gt;&lt;code class=&quot;inline&quot;&gt;s_next()&lt;/code&gt; selects a previously blocked thread &lt;code class=&quot;inline&quot;&gt;V&lt;/code&gt; ready to be resumed. &lt;code class=&quot;inline&quot;&gt;usched_run()&lt;/code&gt; calls &lt;code class=&quot;inline&quot;&gt;cont(V)&lt;/code&gt;.                                        cont()  usched_run()
----------------------------------------+-----+--------------+-------+
                                        |     | buf | anchor |  ...  |
----------------------------------------+-----+--------------+-------+
                                        ^
                                        |
                                        sp`&lt;code class=&quot;inline&quot;&gt;cont()&lt;/code&gt; copies the stack from the buffer to [&lt;code class=&quot;inline&quot;&gt;V-&amp;gt;u_top&lt;/code&gt;, &lt;code class=&quot;inline&quot;&gt;V-&amp;gt;u_bottom&lt;/code&gt;] range. It&amp;#x27;s important that this &lt;code class=&quot;inline&quot;&gt;memcpy()&lt;/code&gt; operation does not overwrite &lt;code class=&quot;inline&quot;&gt;cont()&lt;/code&gt;&amp;#x27;s own stack frame, this is why &lt;code class=&quot;inline&quot;&gt;pad[]&lt;/code&gt; array is needed in &lt;code class=&quot;inline&quot;&gt;launch()&lt;/code&gt;: it advances &lt;code class=&quot;inline&quot;&gt;V-&amp;gt;u_bottom&lt;/code&gt; and gives &lt;code class=&quot;inline&quot;&gt;cont()&lt;/code&gt; some space to operate.  usched_block()       foo() V-&amp;gt;u_f()   cont()  usched_run()
---------+------+-----+-----+--------+--+-----+--------------+-------+
         | here | ... |     |        |  |     | buf | anchor |  ...  |
---------+------+-----+-----+--------+--+-----+--------------+-------+
    ^    ^                           ^  ^
    |    +-- V-&amp;gt;u_cont               |  +-- sp
    |                                |
    V-&amp;gt;u_top                         V-&amp;gt;u_bottom`Then &lt;code class=&quot;inline&quot;&gt;cont()&lt;/code&gt; &lt;code class=&quot;inline&quot;&gt;longjmp()&lt;/code&gt;-s to &lt;code class=&quot;inline&quot;&gt;V-&amp;gt;&lt;/code&gt;u_cont, restoring &lt;code class=&quot;inline&quot;&gt;V&lt;/code&gt; execution context:  usched_block()       foo() V-&amp;gt;u_f()   cont()  usched_run()
---------+------+-----+-----+--------+--+-----+--------------+-------+
         | here | ... |     |        |  |     | buf | anchor |  ...  |
---------+------+-----+-----+--------+--+-----+--------------+-------+
         ^
         +-- sp = V-&amp;gt;u_cont`&lt;code class=&quot;inline&quot;&gt;V&lt;/code&gt; continues its execution as if it returned from &lt;code class=&quot;inline&quot;&gt;usched_block()&lt;/code&gt;.MultiprocessingBy design, a single instance of &lt;code class=&quot;inline&quot;&gt;struct usched&lt;/code&gt; cannot take advantage of multiple processors, because all its threads are executing within a single native thread. Multiple instances of &lt;code class=&quot;inline&quot;&gt;struct usched&lt;/code&gt; can co-exist within a single process address space, but a ustack thread created for one instance cannot be migrated to another. One possible strategy to add support for multiple processors is to create multiple instances of struct usched and schedule them (that is, schedule the threads running respective &lt;code class=&quot;inline&quot;&gt;usched_run()&lt;/code&gt;-s) to processors via &lt;code class=&quot;inline&quot;&gt;pthread_setaffinity_np()&lt;/code&gt; or similar. See &lt;a href=&quot;https://github.com/nikitadanilov/usched/blob/master/rr.c&quot;&gt;rr.c&lt;/a&gt; for a simplistic implementation.Current limitationsthe stack is assumed to grow toward lower addresses. This is easy to fix, if necessary;the implementation is not signal-safe. Fixing this can be as easy as replacing &lt;code class=&quot;inline&quot;&gt;{set,long}&lt;/code&gt;&lt;code class=&quot;inline&quot;&gt;jmp()&lt;/code&gt; calls with their &lt;code class=&quot;inline&quot;&gt;sig{set,long}&lt;/code&gt;&lt;code class=&quot;inline&quot;&gt;jmp()&lt;/code&gt; counterparts. At the moment signal-based code, like gperf &lt;code class=&quot;inline&quot;&gt;-lprofiler&lt;/code&gt; library, would most likely crash usched;&lt;code class=&quot;inline&quot;&gt;usched.c&lt;/code&gt; must be compiled without optimisations and with &lt;code class=&quot;inline&quot;&gt;-fno-stack-protector&lt;/code&gt; option (gcc);usched threads are cooperative: a thread will continue to run until it completes of blocks. Adding preemption (via signal-based timers) is relatively easy, the actual preemption decision will be relegated to the external &amp;quot;scheduler&amp;quot; via a new &lt;code class=&quot;inline&quot;&gt;usched::s_preempt()&lt;/code&gt; call-back invoked from a signal handler.Notes&lt;a href=&quot;https://joeduffyblog.com/2015/11/19/asynchronous-everything/&quot;&gt;Midori&lt;/a&gt; seems to use a similar method: a coroutine (called &lt;i&gt;activity&lt;/i&gt; there) starts on the native stack. If it needs to block, frames are allocated in the heap (this requires compiler support) and filled in from the stack, the coroutine runs in these heap-allocated frames when resumed.Benchmarksusched was benchmarked against a few stackful (go, pthreads) and stackless (rust, c++ coroutines) implementations. A couple of caveats:all benchmarking in general is subject to the reservations voiced by  Hippocrates and usually translated (with the complete reversal of the meaning)  as &lt;i&gt;ars longa, vita brevis&lt;/i&gt;, which means: &amp;quot;the &lt;i&gt;art&lt;/i&gt; [of doctor or tester]  takes &lt;i&gt;long&lt;/i&gt; time to learn, but the &lt;i&gt;life&lt;/i&gt; of a student is &lt;i&gt;brief&lt;/i&gt;, symptoms  are vague, chances of success are doubtful&amp;quot;;the author is much less than fluent with all the languages and frameworks used  in the benchmarking. It is possible that some of the benchmarking code is  inefficient or just outright wrong. Any comments are appreciated.The benchmark tries to measure the efficiency of coroutine switching. It creates &lt;code class=&quot;inline&quot;&gt;R&lt;/code&gt; &lt;i&gt;cycles&lt;/i&gt;, &lt;code class=&quot;inline&quot;&gt;N&lt;/code&gt; coroutines each. Each cycle performs &lt;code class=&quot;inline&quot;&gt;M&lt;/code&gt; &lt;i&gt;rounds&lt;/i&gt;, where each round consists of sending a message across the cycle: a particular coroutine (selected depending on the round number) sends the message to its right neighbour, all other coroutines relay the message received from the left to the right, the round completes when the originator receives the message after it passed through the entire cycle.If &lt;code class=&quot;inline&quot;&gt;N == 2&lt;/code&gt;, the benchmark is &lt;code class=&quot;inline&quot;&gt;R&lt;/code&gt; pairs of processes, ping-ponging &lt;code class=&quot;inline&quot;&gt;M&lt;/code&gt; messages within each pair.Some benchmarks support two additional parameters: &lt;code class=&quot;inline&quot;&gt;D&lt;/code&gt; (additional space in bytes, artificially consumed by each coroutine in its frame) and &lt;code class=&quot;inline&quot;&gt;P&lt;/code&gt; (the number of native threads used to schedule the coroutines.The benchmark creates &lt;code class=&quot;inline&quot;&gt;N*R&lt;/code&gt; coroutines and sends a total of &lt;code class=&quot;inline&quot;&gt;N*R*M&lt;/code&gt; messages, the latter being proportional to the number of coroutine switches.&lt;a href=&quot;https://github.com/nikitadanilov/usched/blob/master/bench.sh&quot;&gt;bench.sh&lt;/a&gt; runs all implementations with the same &lt;code class=&quot;inline&quot;&gt;N&lt;/code&gt;, &lt;code class=&quot;inline&quot;&gt;R&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;M&lt;/code&gt; parameters. &lt;a href=&quot;https://github.com/nikitadanilov/usched/blob/master/graph.py&quot;&gt;graph.py&lt;/a&gt; plots the results.POSIX. Source: &lt;a href=&quot;https://github.com/nikitadanilov/usched/blob/master/pmain.c&quot;&gt;pmain.c&lt;/a&gt;, binary: pmain. Pthreads-based stackful implementation  in C. Uses default thread attributes. &lt;a href=&quot;https://github.com/nikitadanilov/usched/blob/master/pmain.c&quot;&gt;pmain.c&lt;/a&gt; also contains emulation of  unnamed POSIX semaphores for Darwin. Plot label: &amp;quot;P&amp;quot;. This benchmarks crashes  with &amp;quot;pmain: pthread_create: Resource temporarily unavailable&amp;quot; for large values  of &lt;code class=&quot;inline&quot;&gt;N*R&lt;/code&gt;.Go. Source: &lt;a href=&quot;https://github.com/nikitadanilov/usched/blob/master/gmain.go&quot;&gt;gmain.go&lt;/a&gt;, binary: gmain. The code is straightforward (it was a pleasure to write). &lt;code class=&quot;inline&quot;&gt;P&lt;/code&gt; is supported via &lt;code class=&quot;inline&quot;&gt;runtime.GOMAXPROCS()&lt;/code&gt;. &amp;quot;GO1T&amp;quot; are the results for a single native thread, &amp;quot;GO&amp;quot; are the results without the restriction on the number of threads.Rust. Source: &lt;a href=&quot;https://github.com/nikitadanilov/usched/blob/master/cycle/src/main.rs&quot;&gt;cycle/src/main.rs&lt;/a&gt;, binary: cycle/target/release/cycle. Stackless  implementation using Rust builtin &lt;a href=&quot;https://rust-lang.github.io/async-book/&quot;&gt;&lt;code class=&quot;inline&quot;&gt;async/.await&lt;/code&gt;&lt;/a&gt;. Label: &amp;quot;R&amp;quot;. It is  single-threaded (I haven&amp;#x27;t figured out how to distribute coroutines to multiple  executors), so should be compared with GO1T, C++1T and U1T. Instead of fighting  with the Rust borrow checker, I used &amp;quot;unsafe&amp;quot; and shared data-structures  between multiple coroutines much like other benchmarks do.C++. Source: &lt;a href=&quot;https://github.com/nikitadanilov/usched/blob/master/c%2B%2Bmain.cpp&quot;&gt;c++main.cpp&lt;/a&gt;, binary: c++main. The current state of coroutine  support in C++ is unclear. Is everybody supposed to directly use &lt;code class=&quot;inline&quot;&gt;&amp;lt;coroutine&amp;gt;&lt;/code&gt;  interfaces or one of the mutually incompatible libraries that provide easier to  use interfaces on top of &lt;code class=&quot;inline&quot;&gt;&amp;lt;coroutine&amp;gt;&lt;/code&gt;? This benchmark uses &lt;a href=&quot;https://lewissbaker.github.io/&quot;&gt;Lewis Baker&lt;/a&gt;&amp;#x27;s  &lt;a href=&quot;https://github.com/lewissbaker/cppcoro&quot;&gt;cppcoro&lt;/a&gt;, (&lt;a href=&quot;https://www.andreasbuhr.de/&quot;&gt;Andreas Buhr&lt;/a&gt;&amp;#x27;s &lt;a href=&quot;https://github.com/andreasbuhr/cppcoro&quot;&gt;fork&lt;/a&gt;). Labels: &amp;quot;C++&amp;quot; and &amp;quot;C++1T&amp;quot; (for single-threaded  results).usched. Source: &lt;a href=&quot;https://github.com/nikitadanilov/usched/blob/master/rmain.c&quot;&gt;rmain.c&lt;/a&gt;, binary: rmain. Based on &lt;code class=&quot;inline&quot;&gt;usched.[ch]&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;rr.[ch]&lt;/code&gt;  This is our main interest, so we test a few combinations of parameters.Label: &amp;quot;U&amp;quot;: the default configuration, round-robin scheduler over 16 native threads,&amp;quot;U1K&amp;quot;: 1000 bytes of additional stack space for each coroutine&amp;quot;U10K&amp;quot;: 10000 bytes,&amp;quot;U1T&amp;quot;: round-robin over 1 native thread,&amp;quot;U1TS&amp;quot;: round-robin over 1 native thread with pthread locking in &lt;a href=&quot;https://github.com/nikitadanilov/usched/blob/master/rr.c&quot;&gt;rr.c&lt;/a&gt; compiled   out (&lt;code class=&quot;inline&quot;&gt;-DSINGLE_THREAD&lt;/code&gt; compilation option, a separate binary rmain.1t).&lt;i&gt;Update&lt;/i&gt; &amp;quot;UL&amp;quot;: uses &amp;quot;local&amp;quot; scheduler &lt;a href=&quot;https://github.com/nikitadanilov/usched/blob/master/ll.c&quot;&gt;ll.c&lt;/a&gt;. All coroutines within a cycle are assigned to the same native thread so that scheduling between them require no locking. This demonstrates very high throughput (comparable to C++), but unfortunately I do not have time right now to re-do all the measurements consistently. Binary: lmain.&lt;a href=&quot;https://github.com/nikitadanilov/usched/blob/master/bench.sh&quot;&gt;bench.sh&lt;/a&gt; runs all benchmarks with &lt;code class=&quot;inline&quot;&gt;N == 2&lt;/code&gt; (message ping-pong) and &lt;code class=&quot;inline&quot;&gt;N == 8&lt;/code&gt;. Raw results are in &lt;a href=&quot;https://github.com/nikitadanilov/usched/blob/master/results.linux&quot;&gt;results.linux&lt;/a&gt;. In the graphs, the horizontal axis is the number of coroutines (&lt;code class=&quot;inline&quot;&gt;N*R&lt;/code&gt;, logarithmic) and the vertical axis is the operations (&lt;code class=&quot;inline&quot;&gt;N*R*M&lt;/code&gt;) per second.Environment: Linux VM, 16 processors, 16GB of memory. Kernel: 4.18.0 (Rocky Linux).\begin{array}{|l|r|r|r|r|r|r|r|r|r|}
  \hline
             &amp;amp; 16    &amp;amp;  32    &amp;amp;  64    &amp;amp;  400    &amp;amp;  800    &amp;amp;  4000    &amp;amp;  8000    &amp;amp;  40000    &amp;amp;  80000    &amp;amp;  400000    &amp;amp;  800000    &amp;amp;  4000000    &amp;amp;  8000000\\ \hline
    \text{posix}   &amp;amp;  1.76    &amp;amp;  3.46    &amp;amp;  6.39    &amp;amp;  14.58    &amp;amp;  14.85    &amp;amp;  14.70    &amp;amp;  13.63    &amp;amp;  9.87    &amp;amp;  8.02    &amp;amp;  0.00    &amp;amp;  0.00    &amp;amp;  0.00    &amp;amp;  0.01\\ \hline
    \text{go}   &amp;amp;  4.14    &amp;amp;  5.62    &amp;amp;  7.77    &amp;amp;  36.74    &amp;amp;  41.64    &amp;amp;  49.72    &amp;amp;  48.24    &amp;amp;  37.24    &amp;amp;  43.06    &amp;amp;  46.31    &amp;amp;  46.22    &amp;amp;  46.09    &amp;amp;  45.95\\ \hline
    \text{go1t}   &amp;amp;  4.38    &amp;amp;  4.30    &amp;amp;  4.27    &amp;amp;  4.11    &amp;amp;  3.81    &amp;amp;  3.53    &amp;amp;  3.40    &amp;amp;  3.33    &amp;amp;  3.43    &amp;amp;  3.99    &amp;amp;  3.98    &amp;amp;  3.95    &amp;amp;  3.86\\ \hline
    \text{rust}   &amp;amp;  9.48    &amp;amp;  8.71    &amp;amp;  8.69    &amp;amp;  8.64    &amp;amp;  8.53    &amp;amp;  7.85    &amp;amp;  6.59    &amp;amp;  4.32    &amp;amp;  3.80    &amp;amp;  3.63    &amp;amp;  3.63    &amp;amp;  3.83    &amp;amp;  3.90\\ \hline
    \text{u}   &amp;amp;  17.24    &amp;amp;  17.27    &amp;amp;  17.30    &amp;amp;  25.77    &amp;amp;  29.99    &amp;amp;  71.68    &amp;amp;  77.32    &amp;amp;  78.92    &amp;amp;  77.98    &amp;amp;  80.88    &amp;amp;  82.09    &amp;amp;  83.66    &amp;amp;  82.15\\ \hline
    \text{u1k}   &amp;amp;  16.21    &amp;amp;  16.29    &amp;amp;  16.35    &amp;amp;  25.38    &amp;amp;  28.41    &amp;amp;  69.92    &amp;amp;  75.76    &amp;amp;  74.31    &amp;amp;  73.65    &amp;amp;  76.69    &amp;amp;  76.75    &amp;amp;  75.84    &amp;amp;  76.56\\ \hline
    \text{u10k}   &amp;amp;  9.04    &amp;amp;  8.96    &amp;amp;  9.09    &amp;amp;  20.38    &amp;amp;  21.69    &amp;amp;  58.13    &amp;amp;  60.95    &amp;amp;  59.66    &amp;amp;  60.50    &amp;amp;  61.32    &amp;amp;  61.71    &amp;amp;  62.06    &amp;amp;  62.72\\ \hline
    \text{u1t}   &amp;amp;  17.37    &amp;amp;  17.31    &amp;amp;  17.35    &amp;amp;  17.35    &amp;amp;  17.36    &amp;amp;  17.27    &amp;amp;  17.29    &amp;amp;  17.14    &amp;amp;  17.06    &amp;amp;  16.91    &amp;amp;  16.91    &amp;amp;  16.91    &amp;amp;  16.87\\ \hline
    \text{c++}   &amp;amp;  49.87    &amp;amp;  67.85    &amp;amp;  74.94    &amp;amp;  73.91    &amp;amp;  73.04    &amp;amp;  62.48    &amp;amp;  59.15    &amp;amp;  57.23    &amp;amp;  56.48    &amp;amp;  55.35    &amp;amp;  55.44    &amp;amp;  54.02    &amp;amp;  53.61\\ \hline
    \text{c++1t}   &amp;amp;  97.03    &amp;amp;  97.38    &amp;amp;  96.82    &amp;amp;  96.06    &amp;amp;  96.58    &amp;amp;  95.78    &amp;amp;  94.83    &amp;amp;  89.83    &amp;amp;  86.09    &amp;amp;  80.48    &amp;amp;  79.37    &amp;amp;  77.04    &amp;amp;  77.48\\ \hline
    \text{u1ts}   &amp;amp;  49.53    &amp;amp;  49.76    &amp;amp;  49.83    &amp;amp;  50.16    &amp;amp;  49.93    &amp;amp;  48.88    &amp;amp;  49.75    &amp;amp;  48.75    &amp;amp;  47.99    &amp;amp;  46.48    &amp;amp;  46.25    &amp;amp;  45.99    &amp;amp;  46.12\\ \hline
    \text{ul}   &amp;amp;  76.03    &amp;amp;  116.63    &amp;amp;  160.72    &amp;amp;  169.74    &amp;amp;  169.99    &amp;amp;  171.57    &amp;amp;  170.32    &amp;amp;  165.82    &amp;amp;  169.43    &amp;amp;  174.32    &amp;amp;  171.55    &amp;amp;  169.48    &amp;amp;  170.04\\ \hline
\end{array}&lt;code class=&quot;inline&quot;&gt;(N == 8)&lt;/code&gt; A few notes:As mentioned above, pthreads-based solution crashes with around 50K threads.Most single-threaded versions (&amp;quot;GO1T&amp;quot;, &amp;quot;R&amp;quot; and &amp;quot;U1T&amp;quot;) are stable as corpse&amp;#x27;s  body temperature. Rust cools off completely at about 500K  coroutines. Single-threaded C++ (&amp;quot;C++1T&amp;quot;) on the other hand is the most  performant solution for almost the entire range of measurement, it is only for  coroutine counts higher than 500K when &amp;quot;U&amp;quot; overtakes it.It is interesting that a very simple and unoptimised usched fares so well  against heavily optimized C++ and Go run-times. (Again, see the reservations  about the benchmarking.)Rust is disappointing: one would hope to get better results from a rich type  system combined with compiler support.\begin{array}{|l|r|r|r|r|r|r|r|r|r|}
  \hline
        &amp;amp;  4    &amp;amp;  8    &amp;amp;  16    &amp;amp;  100    &amp;amp;  200    &amp;amp;  1000    &amp;amp;  2000    &amp;amp;  10000    &amp;amp;  20000    &amp;amp;  100000    &amp;amp;  200000    &amp;amp;  1000000    &amp;amp;  2000000\\ \hline
    \text{posix}   &amp;amp;  0.56    &amp;amp;  0.97    &amp;amp;  1.84    &amp;amp;  6.36    &amp;amp;  6.88    &amp;amp;  7.78    &amp;amp;  7.82    &amp;amp;  7.58    &amp;amp;  7.15    &amp;amp;  5.34    &amp;amp;  0.00    &amp;amp;  0.00    &amp;amp;  0.00\\ \hline
    \text{go}   &amp;amp;  7.40    &amp;amp;  11.03    &amp;amp;  19.23    &amp;amp;  40.44    &amp;amp;  45.79    &amp;amp;  51.81    &amp;amp;  52.87    &amp;amp;  52.77    &amp;amp;  53.15    &amp;amp;  53.62    &amp;amp;  53.22    &amp;amp;  55.77    &amp;amp;  56.82\\ \hline
    \text{go1t}   &amp;amp;  4.54    &amp;amp;  4.55    &amp;amp;  4.53    &amp;amp;  4.53    &amp;amp;  4.53    &amp;amp;  4.52    &amp;amp;  4.52    &amp;amp;  4.50    &amp;amp;  4.47    &amp;amp;  4.36    &amp;amp;  4.31    &amp;amp;  4.26    &amp;amp;  4.26\\ \hline
    \text{rust}   &amp;amp;  5.68    &amp;amp;  5.75    &amp;amp;  5.75    &amp;amp;  4.74    &amp;amp;  4.74    &amp;amp;  4.62    &amp;amp;  4.46    &amp;amp;  4.13    &amp;amp;  3.70    &amp;amp;  2.81    &amp;amp;  2.77    &amp;amp;  2.76    &amp;amp;  2.73\\ \hline
    \text{u}   &amp;amp;  11.22    &amp;amp;  11.27    &amp;amp;  11.26    &amp;amp;  11.30    &amp;amp;  7.91    &amp;amp;  24.66    &amp;amp;  38.72    &amp;amp;  35.67    &amp;amp;  40.60    &amp;amp;  41.18    &amp;amp;  42.06    &amp;amp;  42.96    &amp;amp;  42.74\\ \hline
    \text{u1k}   &amp;amp;  9.64    &amp;amp;  9.62    &amp;amp;  9.65    &amp;amp;  9.67    &amp;amp;  7.61    &amp;amp;  22.14    &amp;amp;  34.38    &amp;amp;  31.70    &amp;amp;  34.54    &amp;amp;  34.56    &amp;amp;  34.59    &amp;amp;  35.47    &amp;amp;  35.56\\ \hline
    \text{u10k}   &amp;amp;  4.43    &amp;amp;  4.62    &amp;amp;  4.50    &amp;amp;  4.25    &amp;amp;  5.02    &amp;amp;  15.79    &amp;amp;  26.18    &amp;amp;  25.33    &amp;amp;  27.60    &amp;amp;  27.62    &amp;amp;  27.63    &amp;amp;  27.72    &amp;amp;  28.16\\ \hline
    \text{u1t}   &amp;amp;  11.24    &amp;amp;  11.29    &amp;amp;  11.34    &amp;amp;  11.26    &amp;amp;  11.32    &amp;amp;  11.30    &amp;amp;  11.28    &amp;amp;  11.28    &amp;amp;  11.22    &amp;amp;  11.19    &amp;amp;  11.15    &amp;amp;  11.13    &amp;amp;  11.15\\ \hline
    \text{c++}   &amp;amp;  46.33    &amp;amp;  46.30    &amp;amp;  63.38    &amp;amp;  114.30    &amp;amp;  117.05    &amp;amp;  114.12    &amp;amp;  111.36    &amp;amp;  101.32    &amp;amp;  100.13    &amp;amp;  84.30    &amp;amp;  78.53    &amp;amp;  72.77    &amp;amp;  71.00\\ \hline
    \text{c++1t}   &amp;amp;  96.56    &amp;amp;  96.03    &amp;amp;  96.37    &amp;amp;  95.97    &amp;amp;  95.49    &amp;amp;  95.68    &amp;amp;  94.94    &amp;amp;  92.95    &amp;amp;  91.23    &amp;amp;  83.55    &amp;amp;  80.33    &amp;amp;  77.22    &amp;amp;  76.22\\ \hline
    \text{u1ts}   &amp;amp;  19.59    &amp;amp;  19.66    &amp;amp;  19.80    &amp;amp;  19.87    &amp;amp;  19.89    &amp;amp;  19.86    &amp;amp;  19.82    &amp;amp;  19.72    &amp;amp;  19.66    &amp;amp;  19.51    &amp;amp;  19.45    &amp;amp;  19.33    &amp;amp;  19.37\\ \hline
    \text{ul}   &amp;amp;  12.19    &amp;amp;  23.48    &amp;amp;  50.39    &amp;amp;  65.71    &amp;amp;  67.22    &amp;amp;  69.17    &amp;amp;  70.01    &amp;amp;  70.09    &amp;amp;  69.36    &amp;amp;  69.28    &amp;amp;  69.43    &amp;amp;  68.83    &amp;amp;  68.00\\ \hline
\end{array}&lt;code class=&quot;inline&quot;&gt;(N == 2)&lt;/code&gt;First, note that the scale is different on the vertical axis.Single-threaded benchmarks display roughly the same behaviour (exactly the same  in &amp;quot;C++1T&amp;quot; case) as with &lt;code class=&quot;inline&quot;&gt;N == 8&lt;/code&gt;.Go is somewhat better. Perhaps its scheduler is optimised for message ping-pong  usual in channel-based concurrency models?usched variants are much worse (50% worse for &amp;quot;U&amp;quot;) than &lt;code class=&quot;inline&quot;&gt;N == 8&lt;/code&gt;.Rust is disappointing.To reproduce:$ # install libraries and everything, then...
$ make
$ while : ;do ./bench.sh | tee -a results; sleep 5 ;done # collect enough results, this might take long...
^C
$ grep -h &amp;#x27;^ *[2N],&amp;#x27; results | python3 graph.py c2.svg &amp;gt; c2-table.md # create plot for N == 2
$ grep -h &amp;#x27;^ *[8N],&amp;#x27; results | python3 graph.py c8.svg &amp;gt; c8-table.md # create plot for N == 8ConclusionOverall, the results are surprisingly good. The difference between &amp;quot;U1T&amp;quot; and &amp;quot;U1TS&amp;quot; indicates that the locking in &lt;a href=&quot;https://github.com/nikitadanilov/usched/blob/master/rr.c&quot;&gt;rr.c&lt;/a&gt; affects performance significantly, and affects it even more with multiple native threads, when locks are contended across processors. I&amp;#x27;ll try to produce a more efficient (perhaps lockless) version of a scheduler as the next step.</content>
        </item>

        <item>
            <title>usched: update</title>
            <id>usched.update</id>
            <link>https://cofault.com/usched.update.html#usched.update</link>
            <pubDate>2022/10/11</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/usched.update.html#usched.update">
                     &lt;span class=&quot;linktarget&quot; data-uid=&quot;2&quot;&gt;&lt;/span&gt;&lt;i&gt;Update&lt;/i&gt; for &lt;a href=&quot;usched.html#usched-start&quot;&gt;the previous post&lt;/a&gt; about stackswap coroutine implementation &lt;a href=&quot;https://github.com/nikitadanilov/usched&quot;&gt;usched&lt;/a&gt;.To recap, usched is an experimental (and &lt;i&gt;very&lt;/i&gt; simple, 120LOC) coroutine implementation different from stackful and stackless models: coroutines are executed on the native stack of the caller and when the coroutine is about to block its stack is copied into a separately allocated (&lt;i&gt;e.g.&lt;/i&gt;, in the heap) buffer. The buffer is copied back onto the native stack when the coroutine is ready to resume.I added a new scheduler &lt;a href=&quot;https://github.com/nikitadanilov/usched/blob/master/ll.c&quot;&gt;ll.c&lt;/a&gt; that distributes coroutines across multiple native threads and then does lockless scheduling within each thread. In the benchmark (the same as in the previous post), each coroutine in the communicating &lt;i&gt;cycle&lt;/i&gt; belongs to the same thread.Results are amazing: usched actually beats compiler-assisted C++ coroutines by a large margin. The horizontal axis is the number of coroutines in the test (logarithmic) and the vertical axis is coroutine wakeup-wait operations per second (1 == 1e8 op/sec).\begin{array}{|l|r|r|r|r|r|r|r|r|r|r|r|r|r|}
  \hline
           &amp;amp;    16 &amp;amp; 32 &amp;amp; 64 &amp;amp; 400 &amp;amp; 800 &amp;amp; 4000 &amp;amp; 8000 &amp;amp; 40000 &amp;amp; 80000 &amp;amp; 400000 &amp;amp; 800000 &amp;amp; 4M &amp;amp; 8M \\ \hline
\text{GO}  &amp;amp; 0.077 &amp;amp; 0.127 &amp;amp; 0.199 &amp;amp; 0.326 &amp;amp; 0.323 &amp;amp; 0.285 &amp;amp; 0.228 &amp;amp; 0.142 &amp;amp; 0.199 &amp;amp; 0.305 &amp;amp; 0.303 &amp;amp; 0.286 &amp;amp; 0.268  \\ \hline
\text{C++} &amp;amp; 1.089 &amp;amp; 1.234 &amp;amp; 1.344 &amp;amp; 1.262 &amp;amp; 1.201 &amp;amp; 1.159 &amp;amp; 1.141 &amp;amp; 1.135 &amp;amp; 1.163 &amp;amp; 1.168 &amp;amp; 1.138 &amp;amp; 1.076 &amp;amp; 1.051 \\ \hline
\text{UL}  &amp;amp; 0.560 &amp;amp; 0.955 &amp;amp; 1.515 &amp;amp; 2.047 &amp;amp; 2.095 &amp;amp; 2.127 &amp;amp; 2.148 &amp;amp; 2.160 &amp;amp; 2.154 &amp;amp; 2.020 &amp;amp; 1.932 &amp;amp; 1.819 &amp;amp; 1.811 \\ \hline
\end{array}I only kept the most efficient implementation from every competing class: C++ for stackless, GO for stackful and usched for stackswap. See the full results in &lt;a href=&quot;https://github.com/nikitadanilov/usched/blob/master/results.darwin&quot;&gt;results.darwin&lt;/a&gt;</content>
        </item>

        <item>
            <title>Vale of tears.</title>
            <id>vale</id>
            <link>https://cofault.com/vale.html#vale</link>
            <pubDate>2013/01/17</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/vale.html#vale">
                     Consider a system describing possible computations (&lt;i&gt;e.g.&lt;/i&gt;, a programming language or a state machine formalism) including interactions with the external world, that is, input and output facilities.A pair of dual sub-classes of computational elements (values, objects, functions, &lt;i&gt;&amp;amp;c&lt;/i&gt;.) can be defined:&lt;i&gt;finitary&lt;/i&gt; elements that are known to not depend on input and&lt;i&gt;ideal&lt;/i&gt; elements that output is known to not depend on.The rest of elements may depend on input and may affect output. Let&amp;#x27;s call such elements &lt;i&gt;laic&lt;/i&gt; (&amp;quot;temporal&amp;quot; might be a better word).The class of finitary elements is well-known: because they can be computed without input, they can be computed before the program starts, &lt;i&gt;i.e.&lt;/i&gt;, they correspond to various constants, including static entities like types (in statically typed languages), classes, function bodies and so on. Some languages have powerful finitary computations, for example, C++ template specialisation is Turing complete.Laic elements are the most usual things like variables and objects.Ideal elements are less known. They have a long history of use in the area of formal program verification where they are called &lt;a href=&quot;http://www-sop.inria.fr/everest/personnel/Mariela.Pavlova/ghost.pdf&quot;&gt;&lt;i&gt;ghost&lt;/i&gt;&lt;/a&gt; or &lt;i&gt;auxiliary&lt;/i&gt; variables.There is an obvious restriction of data and control flow between various types of elements:finitary element may depend only on finitary elements;laic element may depend on laic and finitary elements (&lt;i&gt;e.g.&lt;/i&gt;, normal function  can take a constant as a parameter, but constant cannot be initialised with the  value of a variable or function call);ideal element may depend on any element (&lt;i&gt;e.g.&lt;/i&gt;, ideal variable can be assigned  the value of a laic variable, but not other way around).The most important property of ideal elements is that, because they don&amp;#x27;t affect observable program behaviour, there is no need to actually compute them! Yet, they are useful exactly because of this property: ideal elements are not computed and, hence, are not constrained by the limitations of actual computational environments. For example, an ideal variable can represent an infinite (even uncountable) collection or a real number (real real number, not approximation); an ideal function can be defined by the transfinite induction or by a formula involving quantifiers.To use ideal elements, one assumes that they follow normal rules of the language (for example, axiomatic or denotational &lt;a href=&quot;&lt;a href=&quot;http://en.wikipedia.org/wiki/Semantics_(computer_science)&quot;&gt;semantics&lt;/a&gt;). This assumption doesn&amp;#x27;t burden the implementors of the language precisely because the ideal elements are not computed. Under that assumption, one can reason about properties of ideal elements.As a simplest example, an ideal variable can be used to record the sequence of calls to a certain function:ideal f_seq = {};
function f(arg) {
        f_seq := f_seq ++ arg;
        ...
};and then reason about &lt;code class=&quot;inline&quot;&gt;f_seq&lt;/code&gt; using whatever method is used to reason about laic elements (&lt;i&gt;e.g.&lt;/i&gt;, &lt;a href=&quot;http://en.wikipedia.org/wiki/Predicate_transformer_semantics&quot;&gt;weakest preconditions&lt;/a&gt;, &lt;a href=&quot;http://en.wikipedia.org/wiki/Hoare_triple&quot;&gt;Hoare triples&lt;/a&gt; or usual hand-waving), for example, to prove that messages delivered to a receiver were sent by the sender (that is, &lt;code class=&quot;inline&quot;&gt;deliver_seq&lt;/code&gt; is a sub-sequence of &lt;code class=&quot;inline&quot;&gt;send_seq&lt;/code&gt;).It is interesting that both finitary elements (specifically, static types) and ideal elements help to reason about the behaviour of the laic world sandwiched between them.Nothing in this short article is new, except for the (obvious) duality between ideal and finitary elements.&lt;i&gt;Exercise&lt;/i&gt; 0: implement &lt;a href=&quot;http://en.wikipedia.org/wiki/Substructural_type_system#Linear_type_systems&quot;&gt;linear types&lt;/a&gt; by casting laic elements to ideal.&lt;i&gt;Exercise&lt;/i&gt; 1: implement garbage collection similarly.</content>
        </item>

        <item>
            <title>Conatus trimetro iambico.</title>
            <id>3-iamb</id>
            <link>https://cofault.com/3-iamb.html#3-iamb</link>
            <pubDate>2017/12/18</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/3-iamb.html#3-iamb">
                     &lt;i&gt;Aloof as stardust rains&lt;/i&gt;&lt;i&gt;Are memory dim prints&lt;/i&gt;&lt;i&gt;Eliding tensed face&lt;/i&gt;&lt;i&gt;By shadows within of&lt;/i&gt;&lt;i&gt;All conquering space that&lt;/i&gt;&lt;i&gt;Inly trusts each friend&lt;/i&gt;&lt;i&gt;Of madness—whose embrace&lt;/i&gt;&lt;i&gt;Accept with no delays&lt;/i&gt;&lt;i&gt;To take one final look&lt;/i&gt;&lt;i&gt;Before you turn Rose ways&lt;/i&gt;.A rather rare meter in English, but much easier once you let enjambments in.</content>
        </item>

        <item>
            <title>A voice of the reason from the distant past</title>
            <id>voice</id>
            <link>https://cofault.com/voice.html#voice</link>
            <pubDate>2006/07/22</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/voice.html#voice">
                     Dedicated to VM and file system developers and researches...It is immediately apparent from these figures that moving-arm disks should  never be used, neither for paging applications nor for any other heavy-traffic  auxiliary memory applications.&lt;span class=&quot;align-right&quot;&gt;Peter J. Denning -- &lt;a href=&quot;http://portal.acm.org/ft_gateway.cfm?id=356573&amp;type=pdf&amp;coll=portal&amp;dl=ACM&amp;CFID=15151515&amp;CFTOKEN=6184618&quot;&gt;Virtual Memory&lt;/a&gt;.&lt;/span&gt;</content>
        </item>

        <item>
            <title>Wikipedia</title>
            <id>wikipedia</id>
            <link>https://cofault.com/wikipedia.html#wikipedia</link>
            <pubDate>2005/07/31</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/wikipedia.html#wikipedia">
                     I added a bit of material to the Wikipedia entry on &lt;a href=&quot;http://en.wikipedia.org/wiki/Page_replacement_algorithms&quot;&gt;Page replacement algorithms&lt;/a&gt;: a bit of history, precleaning, global &lt;i&gt;vs&lt;/i&gt;. local replacement, description of LRU degradation for cyclic access patterns, random replacement, links to the modern algorithms, unification of VM with file system cache, &lt;i&gt;etc&lt;/i&gt;. Original entry was more or less re-hash of a section from Tannenbaum&amp;#x27;s &amp;quot;Operating Systems&amp;quot;.</content>
        </item>

        <item>
            <title>Why windows will collapse ultimately</title>
            <id>windows-collapse</id>
            <link>https://cofault.com/windows-collapse.html#windows-collapse</link>
            <pubDate>2006/03/03</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/windows-collapse.html#windows-collapse">
                     &lt;code class=&quot;inline&quot;&gt;Subject: [ntdev] WdfUsbTargetDeviceSendControlTransferSynchronously and timeouts&lt;/code&gt;&lt;i&gt;update&lt;/i&gt;: Like this wasn&amp;#x27;t enough.Below are excerpts fromfind . -name \*dll |\
        xargs strings -- |\
        grep -i &amp;#x27;^[a-z0-9_]*$&amp;#x27; |\
        awk &amp;#x27;{ print length($1) &amp;quot;\t&amp;quot; $1 }&amp;#x27; |\
        sort -noutput (executed in WinXP system directory):50      ZwAccessCheckByTypeResultListAndAuditAlarmByHandle
51      Java_NPDS_npDSJavaPeer_SetSendMouseClickEvents_stub
51      Java_NPDS_npDSJavaPeer_SetShowPositionControls_stub
51      JET_errDistributedTransactionNotYetPreparedToCommit
52      ACTIVATION_CONTEXT_SECTION_COM_INTERFACE_REDIRECTION
52      ConvertSecurityDescriptorToStringSecurityDescriptorA
52      ConvertSecurityDescriptorToStringSecurityDescriptorW
53      ACTIVATION_CONTEXT_SECTION_GLOBAL_OBJECT_RENAME_TABLE
55      ACTIVATION_CONTEXT_SECTION_COM_TYPE_LIBRARY_REDIRECTION
55      SxspComProgIdRedirectionStringSectionGenerationCallback
56      Java_NPDS_npDSJavaPeer_GetSendOpenStateChangeEvents_stub
56      Java_NPDS_npDSJavaPeer_GetSendPlayStateChangeEvents_stub
56      SxspComTypeLibRedirectionStringSectionGenerationCallback
57      SxspComputeInternalAssemblyIdentityAttributeBytesRequired
57      SxspWindowClassRedirectionStringSectionGenerationCallback
62      SxspComputeInternalAssemblyIdentityAttributeEncodedTextualSize
62      SxspGenerateTextuallyEncodedPolicyIdentityFromAssemblyIdentity
64      RtlpQueryAssemblyInformationActivationContextDetailedInformation
71      &lt;a href=&quot;http://www.openrce.org/reference_library/win32_call_chains/XPSP2/NTDLL/RtlpQueryFilesInAssemblyInformationActivationContextDetailedInformation&quot;&gt;RtlpQueryFilesInAssemblyInformationActivationContextDetailedInformation&lt;/a&gt;which probably gives us the champion.As a comparison, for linux-2.6.15find . -type f -follow -name &amp;#x27;*.[chS]&amp;#x27; |\
        xargs grep -hi &amp;#x27;[a-z0-9_]\{70,\}&amp;#x27; -- /dev/nullgives:70 ZORRO_PROD_PHASE5_BLIZZARD_1230_II_FASTLANE_Z3_CYBERSCSI_CYBERSTORM060So windows is one character closer to hell than linux.</content>
        </item>

        <item>
            <title>working set is not relevant</title>
            <id>working-set</id>
            <link>https://cofault.com/working-set.html#working-set</link>
            <pubDate>2005/07/23</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/working-set.html#working-set">
                     [Updated: 2005.07.24]The key point of working set algorithm is not &lt;i&gt;virtual time&lt;/i&gt; relative to which recently used pages are defined. Virtual time is a problem rather than a solution. At the time when working set algorithm was designed, there was one to one mapping between address spaces and threads. In such setup virtual time based scanning ties memory scheduling and processor scheduling and, hence, avoids thrashing, which is a situation when one resource (processor) is scheduled to achieve its maximal utilization, ignoring constraints imposed by other resource (memory) (See Dijkstra papers &lt;a href=&quot;http://www.cs.utexas.edu/users/EWD/ewd04xx/EWD408.PDF&quot;&gt;EWD408&lt;/a&gt; and &lt;a href=&quot;http://www.cs.utexas.edu/users/EWD/ewd04xx/EWD462.PDF&quot;&gt;EWD462&lt;/a&gt; for as always lucid an explanation).In modern systems there is no such one to one mapping anymore. There are multiple threads executing within the same address space. There are memory consumers that are not readily identifiable with any execution context at all: file system cache (which is merged with VM in any self-respecting kernel), general in-kernel memory allocator, &lt;i&gt;etc&lt;/i&gt;. It means that:there is no relevant notion of virtual time to be used during scanning;working set control fails to bind memory and processor scheduling together,  which will decrease its effectiveness.One extreme case is to consider whole system as one entity. Then virtual time degenerates into physical one, and working set algorithm into active/inactive queue.Moreover, working set is not &lt;i&gt;page&lt;/i&gt; replacement algorithms at all. That is, it doesn&amp;#x27;t answer to the question &amp;quot;System is low on memory, what page should be reclaimed?&amp;quot;; Instead it vaguely points to some address space and proposes to reclaim some unknown page from it. This made sense for the time-shared server running large number of tasks with disjoint address spaces, but for the modern system working set algorithm will be most likely finger-pointing to the Mozilla (or OpenOffice, or...) on the client and Apache (or Oracle, or...) on the server. Which is completely useless, because we still don&amp;#x27;t know &lt;i&gt;what&lt;/i&gt; page is to be reclaimed.</content>
        </item>

        <item>
            <title>XNU VM</title>
            <id>xnu-vm</id>
            <link>https://cofault.com/xnu-vm.html#xnu-vm</link>
            <pubDate>2005/07/25</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/xnu-vm.html#xnu-vm">
                     XNU (OSX kernel) VM scanner marks vnodes as &lt;code class=&quot;inline&quot;&gt;(vp-&amp;gt;v_flag &amp;amp; VHASBEENPAGED)&lt;/code&gt;. &lt;code class=&quot;inline&quot;&gt;write(2)&lt;/code&gt; path checks for this and sends all dirty pages for this vnode down the pipe if this flags is set. Reason:/*
 * this vnode had pages cleaned to it by
 * the pager which indicates that either
 * it&amp;#x27;s not very &amp;#x27;hot&amp;#x27;, or the system is
 * being overwhelmed by a lot of dirty
 * data being delayed in the VM cache...
 * in either event, we&amp;#x27;ll push our remaining
 * delayed data at this point...  this will
 * be more efficient than paging out 1 page at
 * a time, and will also act as a throttle
 * by delaying this client from writing any
 * more data until all his delayed data has
 * at least been queued to the uderlying driver.
 */</content>
        </item>

        <item>
            <title>Zero-cost statics in C++</title>
            <id>zero-cost-static</id>
            <link>https://cofault.com/zero-cost-static.html#zero-cost-static</link>
            <pubDate>2025/07/13</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/zero-cost-static.html#zero-cost-static">
                     &lt;span class=&quot;align-right&quot;&gt; &amp;quot;&lt;i&gt;Усердие все превозмогает!&lt;/i&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;align-right&quot;&gt; К. Прутков, &lt;a href=&quot;https://ru.wikisource.org/wiki/%D0%9C%D1%8B%D1%81%D0%BB%D0%B8_%D0%B8_%D0%B0%D1%84%D0%BE%D1%80%D0%B8%D0%B7%D0%BC%D1%8B_I_(%D0%9F%D1%80%D1%83%D1%82%D0%BA%D0%BE%D0%B2)&quot;&gt;Мысли и афоризмы, I&lt;/a&gt;, 84&lt;/span&gt;In C and C++ a static variable can be defined in a function scope:int foo() {
        static int counter = 1;
        printf(&amp;quot;foo() has been called %i times.\n&amp;quot;, counter++);
        ...
}Technically, this defines &lt;code class=&quot;inline&quot;&gt;counter&lt;/code&gt; as an object of &lt;a href=&quot;https://en.cppreference.com/w/cpp/language/storage_duration.html&quot;&gt;static storage duration&lt;/a&gt; that is allocated not within the function activation frame (which is typically on the stack, but can be on the heap for a &lt;a href=&quot;https://en.cppreference.com/w/cpp/language/coroutines.html&quot;&gt;coroutine&lt;/a&gt;), but as a global object. This is often used to shift computational cost out of the hot path, by precomputing some state and storing it in a static object.When exactly a static object is initialised?For C this question is vacuous, because the initialiser must be a &lt;a href=&quot;https://en.cppreference.com/w/c/language/initialization.html&quot;&gt;compile-time constant&lt;/a&gt;, so the actual value of the static object is embedded in the compiled binary and is always valid.C++ has a bizarrely complicated taxonomy of &lt;a href=&quot;https://en.cppreference.com/w/cpp/language/initialization.html&quot;&gt;initialisations&lt;/a&gt;. There is &lt;a href=&quot;https://timsong-cpp.github.io/cppwp/n4861/basic.start.static&quot;&gt;static&lt;/a&gt; initialisation, which roughly corresponds to C initialisation, subdivided into constant-initialisation and zero-initialisation. Then there is &lt;a href=&quot;https://timsong-cpp.github.io/cppwp/n4861/basic.start.dynamic&quot;&gt;dynamic&lt;/a&gt; initialisation, further divided into unordered, partially-ordered and ordered categories. None of these, however, captures our case: for block-local variables, the Standard has a special sub-section in &amp;quot;Declaration statement&amp;quot; [&lt;a href=&quot;https://timsong-cpp.github.io/cppwp/n4861/stmt.dcl#4&quot;&gt;stmt.dcl.4&lt;/a&gt;]:Dynamic initialization of a block-scope variable with static storage duration  or thread storage duration is performed the first time control passes through  its declaration; such a variable is considered initialized upon the completion  of its initialization. If the initialization exits by throwing an exception,  the initialization is not complete, so it will be tried again the next time  control enters the declaration. If control enters the declaration concurrently  while the variable is being initialized, the concurrent execution shall wait  for completion of the initialization. If control re-enters the declaration  recursively while the variable is being initialized, the behavior is  undefined.For example instruct Bar {
        Bar() : var(1) {}
        int var;
};

int foo(int x) {
        static Bar b{};
        return b.var + 1;
}the constructor for &lt;code class=&quot;inline&quot;&gt;b&lt;/code&gt; should be called exactly once when &lt;code class=&quot;inline&quot;&gt;foo()&lt;/code&gt; is called the first time. This initialisation semantics is very close (sans the exceptions part) to &lt;a href=&quot;https://pubs.opengroup.org/onlinepubs/7908799/xsh/pthread_once.html&quot;&gt;&lt;code class=&quot;inline&quot;&gt;pthread_once&lt;/a&gt;()&lt;/code&gt;. It is clear that the compiler must add some sort of an internal flag to check whether the initialisation has already been performed and some synchronisation object to serialise concurrent calls to &lt;code class=&quot;inline&quot;&gt;foo()&lt;/code&gt; [&lt;a href=&quot;https://gcc.godbolt.org/z/3xKea3MW4&quot;&gt;godbolt&lt;/a&gt;]:foo(int):
        push    rbp
        mov     rbp, rsp
        sub     rsp, 16
        mov     DWORD PTR [rbp-4], edi
        movzx   eax, BYTE PTR guard variable for foo(int)::b[rip]
        test    al, al
        sete    al
        test    al, al
        je      .L3
        mov     edi, OFFSET FLAT:guard variable for foo(int)::b
        call    __cxa_guard_acquire
        test    eax, eax
        setne   al
        test    al, al
        je      .L3
        mov     edi, OFFSET FLAT:foo(int)::b
        call    Bar::Bar() [complete object constructor]
        mov     edi, OFFSET FLAT:guard variable for foo(int)::b
        call    __cxa_guard_release
.L3:
        mov     eax, DWORD PTR foo(int)::b[rip]
        add     eax, 1
        leave
        retThis corresponds roughly to the following code:int foo(int x) {
        static Bar b{};
        static std::atomic&amp;lt;int&amp;gt; __b_guard = 0;
        if (__cxa_guard_acquire(&amp;amp;__b_guard) != 0) {
                new (&amp;amp;b) Bar{}; /* Construct b in-place. */
                __cxa_guard_release(&amp;amp;__b_guard)
        }
        return b.var + 1;
}Here &lt;code class=&quot;inline&quot;&gt;__b_guard&lt;/code&gt; (&lt;code class=&quot;inline&quot;&gt;guard variable for foo(int)::b&lt;/code&gt; in assembly) is the flag variable added by the compiler. &lt;a href=&quot;https://github.com/gcc-mirror/gcc/blob/master/libstdc%2B%2B-v3/libsupc%2B%2B/guard.cc#L272&quot;&gt;&lt;code class=&quot;inline&quot;&gt;__cxa_guard_acquire&lt;/a&gt;()&lt;/code&gt; is a suprisingly complex function, which includes its own synchronisation mechanism implemented directly on top of the raw Linux &lt;a href=&quot;https://man7.org/linux/man-pages/man2/futex.2.html&quot;&gt;futex syscall&lt;/a&gt;.Even after the static variable has been initialised, the overhead of accessing it is still considerable: a function call to &lt;code class=&quot;inline&quot;&gt;__cxa_guard_acquire()&lt;/code&gt;, plus &lt;code class=&quot;inline&quot;&gt;atomic_load_explicit(&amp;amp;__b_guard, memory_order::acquire)&lt;/code&gt; in &lt;code class=&quot;inline&quot;&gt;__cxa_guard_acquire()&lt;/code&gt;. On ARM, such atomic load incurs a memory barrier---a fairly expensive operation.Can this additional cost be reduced? Yes, in fact it can be completely eliminated, making block-level static variables exactly as efficient as file-level ones. For this we need a certain old, but little-known feature of UNIX linkers. From GNU binutils &lt;a href=&quot;https://sourceware.org/binutils/docs/ld.html#Input-Section-Example&quot;&gt;documentation&lt;/a&gt; (beware than in the old versions the terminating symbol is mistakenly referred to as &lt;code class=&quot;inline&quot;&gt;__end_SECNAME&lt;/code&gt;):If an output section’s name is the same as the input section’s name and is representable as a C identifier, then the linker will automatically &lt;code class=&quot;inline&quot;&gt;PROVIDE&lt;/code&gt; two symbols: &lt;code class=&quot;inline&quot;&gt;__start_SECNAME&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;__stop_SECNAME&lt;/code&gt;, where &lt;code class=&quot;inline&quot;&gt;SECNAME&lt;/code&gt; is the name of the section. These indicate the start address and end address of the output section respectively. Note: most section names are not representable as C identifiers because they contain a ‘.’ character.(Solaris linker calls them &amp;quot;Encapsulation Symbols&amp;quot;, see &lt;a href=&quot;https://docs.oracle.com/en/operating-systems/solaris/oracle-solaris/11.4/linkers-libraries/oracle-solaris-11.4-linkers-and-libraries-guide.pdf&quot;&gt;here&lt;/a&gt;.)The idea is the following: instead of defining a block-level static instance of &lt;code class=&quot;inline&quot;&gt;Bar&lt;/code&gt;, define a trivially-initialisable object of a size sufficient to hold an instance of &lt;code class=&quot;inline&quot;&gt;Bar&lt;/code&gt; in a dedicated section &lt;code class=&quot;inline&quot;&gt;STATIC_Bar&lt;/code&gt;, via (more or less portable) &lt;a href=&quot;https://gcc.gnu.org/onlinedocs/gcc-4.8.5/gcc/Variable-Attributes.html&quot;&gt;&lt;code class=&quot;inline&quot;&gt;__attribute__((section))&lt;/code&gt;&lt;/a&gt;. Only such place-holder objects and nothing else are placed in this section. Then, during global static initialisation, scan the resulting array of place-holder objects from &lt;code class=&quot;inline&quot;&gt;__start_STATIC_Bar&lt;/code&gt; to &lt;code class=&quot;inline&quot;&gt;__stop_STATIC_Bar&lt;/code&gt; and initialise Bar instances in-place. Assuming that functions where static &lt;code class=&quot;inline&quot;&gt;Bar&lt;/code&gt;s are defined are not themselves called during global static initialisation, this would initialise everything correctly: by the time &lt;code class=&quot;inline&quot;&gt;foo()&lt;/code&gt; is called, its &lt;code class=&quot;inline&quot;&gt;b&lt;/code&gt; has already been initialised.Something like this:#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;new&amp;gt; /* For placement new. */

#define FAST_STATIC(T)                                                                    \
*({                                                                                       \
        struct placeholder {                                                              \
            alignas(T) char buf[sizeof(T)];                                               \
        };                                                                                \
        static constinit placeholder ph __attribute__((section (&amp;quot;STATIC_&amp;quot; #T))) {{}};     \
        reinterpret_cast&amp;lt;T *&amp;gt;(ph.buf);                                                    \
})

template &amp;lt;typename T&amp;gt; static int section_init(T *start, T *stop)
{
        for (T *s = start; s &amp;lt; stop; ++s)
            new (s) T; /* Construct in-place. */
        return 0;
}

#define FAST_STATIC_INIT(T)                                     \
extern &amp;quot;C&amp;quot; T __start_STATIC_ ## T;                              \
extern &amp;quot;C&amp;quot; T __stop_STATIC_ ## T;                               \
static int _init_ ## T = section_init&amp;lt;T&amp;gt;(&amp;amp;__start_STATIC_ ## T, \
                                         &amp;amp;__stop_STATIC_ ## T);

struct Bar {
        Bar() : var(1) {}
        int var;
};

int foo(int x) {
        Bar &amp;amp;b0 = FAST_STATIC(Bar);
        Bar &amp;amp;b1 = FAST_STATIC(Bar);
        return b0.var + b1.var + 1;
}

FAST_STATIC_INIT(Bar);

int main(int argc, char **argv) {
        return printf(&amp;quot;%i\n&amp;quot;, foo(argc)); /* Prints &amp;quot;3&amp;quot;. */
}Check the resulting assembly [&lt;a href=&quot;https://gcc.godbolt.org/z/bf3h7hzcz&quot;&gt;godbolt&lt;/a&gt;]:foo(int)::ph:
        .zero   4
foo(int)::ph:
        .zero   4
foo(int):
        push    rbp
        mov     rbp, rsp
        mov     DWORD PTR [rbp-20], edi
        mov     QWORD PTR [rbp-8], OFFSET FLAT:foo(int)::ph
        mov     QWORD PTR [rbp-16], OFFSET FLAT:foo(int)::ph
        mov     rax, QWORD PTR [rbp-8]
        mov     edx, DWORD PTR [rax]
        mov     rax, QWORD PTR [rbp-16]
        mov     eax, DWORD PTR [rax]
        add     eax, edx
        add     eax, 1
        pop     rbp
        ret&lt;i&gt;Voilà&lt;/i&gt;! The calls to &lt;code class=&quot;inline&quot;&gt;__cxa_guard_acquire()&lt;/code&gt; are gone, yet &lt;code class=&quot;inline&quot;&gt;b0&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;b1&lt;/code&gt; are initialised before &lt;code class=&quot;inline&quot;&gt;foo()&lt;/code&gt; is called, just as we want. &lt;i&gt;But not so fast&lt;/i&gt;, it&amp;#x27;s C++.Let&amp;#x27;s add another static Bar instance, this time in an inline function:int inline baz(int x) {
        Bar &amp;amp;b = FAST_STATIC(Bar);
        return b.var * x;
}GCC reports [&lt;a href=&quot;https://gcc.godbolt.org/z/Th1ece58b&quot;&gt;godbolt&lt;/a&gt;]:&amp;lt;source&amp;gt;:9:38: error: &amp;#x27;ph&amp;#x27; causes a section type conflict with &amp;#x27;ph&amp;#x27; in section &amp;#x27;STATIC_Bar&amp;#x27;(clang works fine [&lt;a href=&quot;https://gcc.godbolt.org/z/YT9bdG5Ke&quot;&gt;godbolt&lt;/a&gt;], by the way.)The problem is that in addition to name, sections output by the compiler also have attributes. The compiler selects the attributes based on the properties of the scope where the symbol (to which &lt;code class=&quot;inline&quot;&gt;__attribute__((section))&lt;/code&gt; is applied) is defined. Inline functions force a different attribute selection (similarly do template members), and the linker ends up with multiple sections with the same name, but conflicting attributes. See &lt;a href=&quot;https://stackoverflow.com/questions/35091862/inline-static-data-causes-a-section-type-conflict&quot;&gt;stackoverflow&lt;/a&gt; for details.As it is, &lt;code class=&quot;inline&quot;&gt;FAST_STATIC()&lt;/code&gt; is usable, but section attribute conflicts put awkward resrictions on its applicability. Is this the best we can do? For some time I thought that it is, but then I realised that there is another way to specify the section in which the variable is located: the &lt;a href=&quot;https://sourceware.org/binutils/docs/as/PushSection.html&quot;&gt;&lt;code class=&quot;inline&quot;&gt;.pushsection&lt;/code&gt;&lt;/a&gt; directive of the embedded assembler (do not be afraid, we will use only portable part).If you do something like__asm__(&amp;quot;.pushsection STATIC_Bar,\&amp;quot;aw\&amp;quot;,@progbits\n&amp;quot; \
        &amp;quot;.quad &amp;quot; symbol &amp;quot;\n&amp;quot;                         \
        &amp;quot;.popsection\n&amp;quot;)then the address of the &lt;code class=&quot;inline&quot;&gt;symbol&lt;/code&gt; is placed in &lt;code class=&quot;inline&quot;&gt;STATIC_Bar&lt;/code&gt; section with the specified &lt;a href=&quot;https://ftp.gnu.org/old-gnu/Manuals/gas-2.9.1/html_node/as_117.html&quot;&gt;attributes&lt;/a&gt;.All we need is something like#define FAST_STATIC(T)                                          \
*({                                                             \
        struct placeholder {                                    \
            alignas(T) char buf[sizeof(T)];                     \
        };                                                      \
        static constinit placeholder ph {{}};                   \
        __asm__(&amp;quot;.pushsection STATIC_&amp;quot; #T &amp;quot;,\&amp;quot;aw\&amp;quot;,@progbits\n&amp;quot; \
                &amp;quot;.quad ph\n&amp;quot;                                    \
                &amp;quot;.popsection\n&amp;quot;);                               \
        reinterpret_cast&amp;lt;T *&amp;gt;(ph.buf);                          \
})and we are good (&lt;code class=&quot;inline&quot;&gt;section_init()&lt;/code&gt; needs to be fixed a bit, because &lt;code class=&quot;inline&quot;&gt;STATIC_Bar&lt;/code&gt; now contains pointers, not instances). &lt;i&gt;But not so fast&lt;/i&gt;, it&amp;#x27;s C++. This does not even compile [&lt;a href=&quot;https://gcc.godbolt.org/z/b49974Wfr&quot;&gt;godbolt&lt;/a&gt;]:ld: /tmp/ccZRzXXj.o:(STATIC_Bar+0x0): undefined reference to `ph&amp;#x27;
ld: /tmp/ccZRzXXj.o:(STATIC_Bar+0x8): undefined reference to `ph&amp;#x27;
ld: /tmp/ccZRzXXj.o:(STATIC_Bar+0x10): undefined reference to `ph&amp;#x27;
collect2: error: ld returned 1 exit status
Execution build compiler returned: 1When you define &lt;code class=&quot;inline&quot;&gt;static constinit placeholder ph&lt;/code&gt;, the actual name the compiler uses for the symbol is not &lt;code class=&quot;inline&quot;&gt;ph&lt;/code&gt; it is the mangled version of something like &lt;code class=&quot;inline&quot;&gt;foo(int)::ph&lt;/code&gt; that we saw in the assembly listing above. There is no &lt;code class=&quot;inline&quot;&gt;ph&lt;/code&gt; for &lt;code class=&quot;inline&quot;&gt;.quad ph&lt;/code&gt; to resolve to.OK. Are we stuck &lt;i&gt;now&lt;/i&gt;? In fact not. You can &lt;a href=&quot;https://gcc.gnu.org/onlinedocs/gcc/Asm-Labels.html&quot;&gt;instruct the compiler&lt;/a&gt; to use a particular symbol name, instead of the mangled one. With        int foo asm (&amp;quot;bar&amp;quot;) = 2;the compiler will use &amp;quot;bar&amp;quot; as the symbol name for &lt;code class=&quot;inline&quot;&gt;foo&lt;/code&gt; (both gcc and clang support this).Of course if we just do        static constinit placeholder ph asm(&amp;quot;ph&amp;quot;) {{}};we fall in the opposite trap of having multiple definitions for &amp;quot;ph&amp;quot;. We need to define unique names for our symbols, but there is more or less standard trick for this, based on &lt;a href=&quot;https://www.open-std.org/JTC1/sc22/wg14/www/docs/n3457.htm&quot;&gt;&lt;code class=&quot;inline&quot;&gt;__COUNTER__&lt;/code&gt;&lt;/a&gt; macro. We also need a couple of, again standard, macros for concatenation and stringification. The final version looks like this:#define CAT0(a, b) a ## b
#define CAT(a, b) CAT0(a, b)

#define STR0(x) # x
#define STR(x) STR0(x)

#define FAST_STATIC_DO(T, id)                                   \
*({                                                             \
        struct placeholder {                                    \
            alignas(T) char buf[sizeof(T)];                     \
        };                                                      \
        static constinit placeholder id asm(STR(id)) {{}};      \
        __asm__(&amp;quot;.pushsection STATIC_&amp;quot; #T &amp;quot;,\&amp;quot;aw\&amp;quot;,@progbits\n&amp;quot; \
                &amp;quot;.quad &amp;quot; STR(id) &amp;quot;\n&amp;quot;                           \
                &amp;quot;.popsection\n&amp;quot;);                               \
        reinterpret_cast&amp;lt;T *&amp;gt;(id.buf);                          \
})

#define FAST_STATIC(T) FAST_STATIC_DO(T, CAT(ph_, __COUNTER__))

template &amp;lt;typename T&amp;gt; static int section_init(T **start, T **stop)
{
        for (T **s = start; s &amp;lt; stop; ++s)
                new (*s) T; /* Construct in-place. */
        return 0;
}

#define FAST_STATIC_INIT(T)                                      \
extern &amp;quot;C&amp;quot; T *__start_STATIC_ ## T;                              \
extern &amp;quot;C&amp;quot; T *__stop_STATIC_ ## T;                               \
static int _init_ ## T = section_init&amp;lt;T&amp;gt;(&amp;amp;__start_STATIC_ ## T,  \
                                         &amp;amp;__stop_STATIC_ ## T);The resulting assembly for &lt;code class=&quot;inline&quot;&gt;foo()&lt;/code&gt; and &lt;code class=&quot;inline&quot;&gt;foo_init()&lt;/code&gt; [&lt;a href=&quot;https://gcc.godbolt.org/z/89xrYWhMh&quot;&gt;godbolt&lt;/a&gt;] accesses statics directly:foo(int):
        push    rbp
        mov     rbp, rsp
        mov     DWORD PTR [rbp-20], edi
        mov     QWORD PTR [rbp-8], OFFSET FLAT:ph_0
        mov     QWORD PTR [rbp-16], OFFSET FLAT:ph_1
        mov     rax, QWORD PTR [rbp-8]
        mov     edx, DWORD PTR [rax]
        mov     rax, QWORD PTR [rbp-16]
        mov     eax, DWORD PTR [rax]
        add     eax, edx
        add     eax, 1
        pop     rbp
        ret
foo_inline(int):
        push    rbp
        mov     rbp, rsp
        mov     DWORD PTR [rbp-20], edi
        mov     QWORD PTR [rbp-8], OFFSET FLAT:ph_2
        mov     rax, QWORD PTR [rbp-8]
        mov     eax, DWORD PTR [rax]
        imul    eax, DWORD PTR [rbp-20]
        pop     rbp
        retFinally we won!&lt;span class=&quot;align-right&quot;&gt; &amp;quot;&lt;i&gt;Бывает, что усердие превозмогает и рассудок&lt;/i&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;align-right&quot;&gt; К. Прутков, &lt;a href=&quot;https://ru.wikisource.org/wiki/%D0%9C%D1%8B%D1%81%D0%BB%D0%B8_%D0%B8_%D0%B0%D1%84%D0%BE%D1%80%D0%B8%D0%B7%D0%BC%D1%8B_II_(%D0%9F%D1%80%D1%83%D1%82%D0%BA%D0%BE%D0%B2)&quot;&gt;Мысли и афоризмы, II&lt;/a&gt;, 27&lt;/span&gt;P.S. The actual implementation requires more bells and whistles. Parameters need to be passed to constructors, they can be stored within the placeholder. Typenames are not necessarily valid identifiers (think &lt;code class=&quot;inline&quot;&gt;A::B::foo&amp;lt;T&amp;gt;&lt;/code&gt;), so the section name needs to be a separate parameter, &lt;i&gt;etc&lt;/i&gt;., but the basic idea should be clear.P.P.S. I have a similar story about optimising access to thread-local variables, involving C++20 &lt;a href=&quot;https://en.cppreference.com/w/cpp/language/constinit.html&quot;&gt;&lt;code class=&quot;inline&quot;&gt;constinit&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://www.ibm.com/docs/en/xl-c-and-cpp-aix/16.1.0?topic=attributes-tls-model-attribute&quot;&gt;&lt;code class=&quot;inline&quot;&gt;__attribute__((tls_model(&amp;quot;initial-exec&amp;quot;)))&lt;/code&gt;&lt;/a&gt;.</content>
        </item>

        <item>
            <title>Zero is overrated</title>
            <id>zero-overrated</id>
            <link>https://cofault.com/zero-overrated.html#zero-overrated</link>
            <pubDate>2012/11/03</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/zero-overrated.html#zero-overrated">
                     Define a sequence of functions \(P_i:\mathbb{R}^+\rightarrow\mathbb{R}\), \(i\in\mathbb{N}\)P_0(x) = \ln(x)P_{n+1}(x) = \int P_{n}(x)\cdot dxI found a beautiful closed formula for \(P_i\), that I haven&amp;#x27;t seen before.Integrating by parts, it&amp;#x27;s easy to calculate first few \(P_i\):\begin{array}{r@{\;}c@{\;}l@{\quad}}
P_1(x) &amp;amp;\;=\;&amp;amp; x\cdot\ln x - x \\
P_2(x) &amp;amp;\;=\;&amp;amp; \frac{x^2}{2}\cdot\ln x - \frac{3}{4}\cdot x^2 \\
P_3(x) &amp;amp;\;=\;&amp;amp; \frac{x^6}{6}\cdot\ln x - \frac{11}{36}\cdot x^3
\end{array}which leads to a hypothesis, thatP_n = \frac{x^n}{n!}\cdot\ln x - K_n\cdot x^nfor certain constants \(K_i\), \(K_1 = 1\).Again integrating by parts, obtain:K_{n+1} = \frac{1}{n+1}\cdot\Bigg(K_n + \frac{1}{(n+1)!}\Bigg)from where\begin{array}{r@{\;}c@{\;}l@{\quad}}
K_n &amp;amp;\;=\;&amp;amp;  \frac{1}{n}\cdot\Bigg(K_{n-1} + \frac{1}{n!}\Bigg) \\
    &amp;amp;\;=\;&amp;amp;  \frac{1}{n}\cdot\Bigg(\frac{1}{n!} + \frac{1}{n-1}\cdot\big(K_{n-2} + \frac{1}{(n-1)!}\big)\Bigg) \\
    &amp;amp;\;=\;&amp;amp;  \frac{1}{n!}\cdot\Bigg(\frac{1}{n} + \frac{1}{n-1}\Bigg) + \frac{1}{n\cdot(n - 1)}\cdot K_{n-2} \\
    &amp;amp;\;=\;&amp;amp;  \frac{1}{n!}\cdot\Bigg(\frac{1}{n} + \frac{1}{n - 1} + \frac{1}{n - 2}\Bigg) + \frac{1}{n\cdot(n-1)\cdot(n - 2)}\cdot K_{n-3} \\
    &amp;amp;\;=\;&amp;amp;  \cdots \\
    &amp;amp;\;=\;&amp;amp;  \frac{1}{n!}\cdot\Bigg(\frac{1}{n} + \frac{1}{n - 1} + \cdots +\frac{1}{n - p + 1}\Bigg) + \frac{1}{n\cdot(n-1)\cdot\cdots\cdot(n - p +1)}\cdot K_{n-p}
\end{array}Substitute \(p = n - 1\):K_n = \frac{1}{n!}\cdot\Bigg(1 + \frac{1}{2} + \cdots + \frac{1}{n}\Bigg)Substitute this in the hypothesis:P_n = \frac{x^n}{n!}\cdot\Bigg(\ln x - \big(1 + \frac{1}{2} + \cdots + \frac{1}{n}\big)\Bigg)This nicely contains fragments of exponent, nth-&lt;a href=&quot;http://en.wikipedia.org/wiki/Harmonic_number&quot;&gt;harmonic number&lt;/a&gt; and, after a diagonalisation, the &lt;a href=&quot;http://en.wikipedia.org/wiki/Euler%E2%80%93Mascheroni_constant&quot;&gt;Euler constant&lt;/a&gt;:\lim_{n\to +\infty}\frac{n!}{n^n}\cdot P_n(n) = -\gammaWhy \(P_i\) are interesting at all? Because if one completes them for negative indices asP_n = (-1)^{n-1}\cdot(-n-1)!\cdot x^nthen mth-derivative of \(P_n\) is \(P_{n-m}\) for all non-negative \(m\):(\forall n\in\mathbb{Z})(\forall m\in\mathbb{N})\partial^m P_n = P_{n - m}and similarly(\forall n\in\mathbb{Z})(\forall m\in\mathbb{N})\int_m P_n\cdot dx = P_{n + m}where \(\int_m\) is &lt;a href=&quot;http://mathworld.wolfram.com/RepeatedIntegral.html&quot;&gt;repeated integral&lt;/a&gt;.This is in contrast with powers \(x^n\), \(n \ge 0\), which, under repeated derivation, eventually pathetically collapse to a constant and then to 0, so that negative powers are not reachable from positive and other way around.It&amp;#x27;s interesting, which other families \((\phi_i)_{i\in\mathbb{Z}}\) are there such that(\forall m\in\mathbb{N})\partial^m\phi_n = \phi_{n - m}(\forall m\in\mathbb{N})\int_m \phi_n\cdot dx = \phi_{n + m}and(\forall n\neq m)\phi_n \neq const\cdot\phi_m(the latter condition is to avoid degenerate cases)?</content>
        </item>

        <item>
            <title>Zero everywhere.</title>
            <id>zero</id>
            <link>https://cofault.com/zero.html#zero</link>
            <pubDate>2014/12/13</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/zero.html#zero">
                     (&lt;a href=&quot;https://vk.com/doc177654709_349274647&quot;&gt;студенческая олимпиада МФТИ по математике&lt;/a&gt;, 2013, задача 3)Предположим, что \(\forall x\in\mathbb{R}\to f(x) \neq 0\). Возьмем произвольный интервал \([a, b] \subset \mathbb{R}\), \(a \lt b\) и докажем, что на этом интервале есть точка \(x_0\) такая, что \(\lim \limits_{x\to x_0} f(x) \neq 0\).Пусть \(T_n = |f|^{-1}([\frac{1}{n}, +\infty)) \cap [a, b]\), т.е. \(x \in T_n \equiv |f(x)| \ge \frac{1}{n} \wedge x\in[a, b]\), для \(n &amp;gt; 0\).Если каждое \(T_n\) нигде неплотно, нигде неплотно и их объединение, (т.к. \([a, b]\) — &lt;a href=&quot;http://en.wikipedia.org/wiki/Baire_space&quot;&gt;бэровское пространство&lt;/a&gt;), но их объединение это весь интервал \([a, b]\) — противоречие. Следовательно, некоторое \(T_n\) имеет внутреннюю точку, \(x_0 \in T_n\), тогда \(T_n\) содержит \(x_0\) вместе с неким открытым интервалом на котором, таким образом, \(|f(x)| ≥ \frac{1}{n}\), и, следовательно, \(|\lim \limits_{x\to x_0} f(x)| \ge \frac{1}{n} \gt 0\).Заметим, что мы доказали больше, чем требовалось, а именно, что множество нулей всюду плотно. Или, что функция всюду сходящаяся к непрерывной, почти всюду непрерывна (замените \(0\) на произвольную непрерывную \(g:\mathbb{R}\to\mathbb{R}\)).(2014.12.15) Обобщение.Let \(X\) be a Baire space, \(Y\)—a second-countable Urysohn space and \(f,g : X \to Y\)—arbitrary maps. If \((\forall x\in X)(\lim\limits_{t\to x}f(t) = \lim\limits_{t\to x}g(t))\) then \(f = g\) on a dense subset.&lt;i&gt;Proof&lt;/i&gt; (by contraposition). Suppose that there is an open \(A \subseteq X\), such that \((\forall x\in A)(f(x)\neq g(x))\). Let \(B\) be a countable base of \(Y\).Define a countable family of subsets of \(A\): \(T_{U,V} = f^{-1}(U) \cap  g^{-1}(V) \cap A\), where \(U, V \in B\) (that is, \(U\) and \(V\) are open  subsets of \(Y\)). For any \(x\in A\), \(f(x)\neq g(x)\), and because \(Y\)  is Urysohn, there are \(U, V\in B, cl(U)\cap cl(V) = \varnothing,  f(x)\in U, g(x)\in V\), that is, \(x\in T_{U,V}\) that is,\bigcup\limits_{cl(U)\cap cl(V) = \varnothing} T_{U,V} = ABecause \(X\) and hence \(A\) are Baire spaces, one of \(T_{U,V}\) in the union  above, say \(T_{U_0, V_0}\) is not nowhere dense. That is, there is an open set  \(G\subseteq A\) such that for any \(x_0\in G\), and any open neighbourhood  \(S, x_0\in S\), \(S \cap T_{U_0,V_0}\neq\varnothing\), that is there exists a  \(x&amp;#x27;\in S\) such that \(f(x&amp;#x27;) \in U_0\) and \(g(x&amp;#x27;)\in V_0\).Suppose that \(\lim\limits_{t\to x_0}f(t) = \lim\limits_{t\to x_0}g(t) = y\in  Y\). This means that every open neighbourhood of \(y\) intersects with \(U_0\),  hence \(y\in cl(U_0)\). Similarly \(y\in cl(V_0)\), contradiction with  \(cl(U_0)\cap cl(V_0) = \varnothing\). &lt;i&gt;End of proof&lt;/i&gt;.PS: для задачи 2, ответ \(k = 2\cdot n - 2\).</content>
        </item>

        <item>
            <title>Если бы я знал, что такое электричество...</title>
            <id>электричество</id>
            <link>https://cofault.com/электричество.html#электричество</link>
            <pubDate>2005/05/26</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/электричество.html#электричество">
                     (Posted at &lt;a href=&quot;http://www.livejournal.com/community/borisborisovich/96495.html&quot;&gt;Борис Борисович&lt;/a&gt;™ LJ community)Одним душным предгрозовым вечером &lt;span class=&quot;annotation&quot; data-uid=&quot;4&quot;&gt;24-го мая&lt;/span&gt; Борис Борисович™ прогуливался по  Капотне. Наскучив разглядыванием индустриальных пейзажей, он решительно  направился к белевшему в сумраке зданию, позади которого проглядывали  электрического вида конструкции. Сотрудники подстанции выглядели озабоченными и  внимания на Бориса Борисовича™ не обращали. Лишь один из них, страшно  возбуждённый, спросил: „Кто клал этот кабель?!“. „Я не знаю“ --- пожал плечами  Борис Борисович™ и, пройдя дальше, очутился в коротком, тускло освещенном  тупичке. На дальней стене виднелся пыльный рубильник, рядом надпись:  „Проверено. Гаврилов, 1964.“. Положив на рубильник руку, и ощутив холод  металла, Борис Борисович™ прошептал: „Если бы я знал, что такое  электричество...“, решительно дернул вниз, развернулся на левом каблуке, сделал  шаг и вышел на улицу.Порывшись в карманах он нашёл телефон, поморщил лоб, вспоминая номер и, не  обращая внимания на раздавшийся позади шум, набрал: 2-12-85-06. Телефон молчал.</content>
        </item>

        <item>
            <title>Грозный</title>
            <id>грозный</id>
            <link>https://cofault.com/грозный.html#грозный</link>
            <pubDate>2005/10/16</pubDate>
            <content type="html"
                     xml:base="https://cofault.com/грозный.html#грозный">
                     &amp;quot;Чешский археолог Бедржих Грозный (1879--1952), который в 1915 г. расшифровал  хеттскую клинопись, и именем которого был назван город в южной России.&amp;quot;</content>
        </item>

</channel></rss>